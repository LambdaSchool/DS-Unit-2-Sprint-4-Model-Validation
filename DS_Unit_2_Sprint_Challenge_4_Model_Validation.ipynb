{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PC9RfopIWrc9"
   },
   "source": [
    " # Data Science Unit 2 Sprint Challenge 4 — Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UV7ArLFQN84W"
   },
   "source": [
    "Follow the instructions for each numbered part to earn a score of 2. See the bottom of the notebook for a list of ways you can earn a score of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAZcbTtiUlkI"
   },
   "source": [
    "## Predicting Blood Donations\n",
    "\n",
    "Our dataset is from a mobile blood donation vehicle in Taiwan. The Blood Transfusion Service Center drives to different universities and collects blood as part of a blood drive.\n",
    "\n",
    "**The goal is to predict the last column, whether the donor made a donation in March 2007**, using information about each donor's history. We'll measure success **using recall score** as the model evaluation metric.\n",
    "\n",
    "Good data-driven systems for tracking and predicting donations and supply needs can improve the entire supply chain, making sure that more patients get the blood transfusions they need.\n",
    "\n",
    "#### Run this cell to load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WHY4eFBp4B5k"
   },
   "outputs": [],
   "source": [
    "#!pip install seaborn --upgrade\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvV9VORbxyvu"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data')\n",
    "\n",
    "df = df.rename(columns={\n",
    "    'Recency (months)': 'months_since_last_donation', \n",
    "    'Frequency (times)': 'number_of_donations', \n",
    "    'Monetary (c.c. blood)': 'total_volume_donated', \n",
    "    'Time (months)': 'months_since_first_donation', \n",
    "    'whether he/she donated blood in March 2007': 'made_donation_in_march_2007'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "LRnIuYlm2o-K",
    "outputId": "4a6cc7ee-6718-4a79-ab9b-479b6079b96a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_since_last_donation</th>\n",
       "      <th>number_of_donations</th>\n",
       "      <th>total_volume_donated</th>\n",
       "      <th>months_since_first_donation</th>\n",
       "      <th>made_donation_in_march_2007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>12500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3250</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4000</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>5000</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6000</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_since_last_donation  number_of_donations  total_volume_donated  \\\n",
       "0                           2                   50                 12500   \n",
       "1                           0                   13                  3250   \n",
       "2                           1                   16                  4000   \n",
       "3                           2                   20                  5000   \n",
       "4                           1                   24                  6000   \n",
       "\n",
       "   months_since_first_donation  made_donation_in_march_2007  \n",
       "0                           98                            1  \n",
       "1                           28                            1  \n",
       "2                           35                            1  \n",
       "3                           45                            1  \n",
       "4                           77                            0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wETIyhc33JUL",
    "outputId": "8e4b7686-a468-4330-8818-61a6555ec668"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kysY3HHI_oc7"
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns='made_donation_in_march_2007')\n",
    "y = df.made_donation_in_march_2007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxKfgx4ycb3c"
   },
   "source": [
    "## Part 1.1 — Begin with baselines\n",
    "\n",
    "What **accuracy score** would you get here with a **\"majority class baseline\"?** \n",
    " \n",
    "(You don't need to split the data into train and test sets yet. You can answer this question either with a scikit-learn function or with a pandas function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VePhwhCi9-xR",
    "outputId": "1ef9c777-a1d0-47a8-d23c-e8b578cbd2bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy 0.7620320855614974\n"
     ]
    }
   ],
   "source": [
    "# Finding Baseline Accuracy using Sklearn\n",
    "import numpy as np\n",
    "y_pred = np.full(shape=y.shape, fill_value=y.mode())# TODO\n",
    "baseline_accuracy = accuracy_score(y, y_pred)\n",
    "print ('Baseline Accuracy',baseline_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "3oo31Remcq-x",
    "outputId": "19aeb551-8f92-4245-fc6f-f6dc11fa69c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\n",
      "0\n",
      "Dummy Classification Score (Accuracy): 0.7620320855614974\n"
     ]
    }
   ],
   "source": [
    "# Finding Baseline Accuracy using Dummy Classifier\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    DummyClassifier(strategy='most_frequent',random_state=42))\n",
    "\n",
    "pipe.fit(X, y)\n",
    "\n",
    "# Get the scores with the appropriate score function\n",
    "# Predict with X features and Compare predictions to y labels\n",
    "y_pred = pipe.predict(X)\n",
    "dummy_score = accuracy_score(y, y_pred)\n",
    "print(y.sum())\n",
    "print(y_pred.sum())\n",
    "print('Dummy Classification Score (Accuracy):', dummy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_KdxE1TrcriI"
   },
   "source": [
    "What **recall score** would you get here with a **majority class baseline?**\n",
    "\n",
    "(You can answer this question either with a scikit-learn function or with no code, just your understanding of recall.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "pLAy7cFh8EVf",
    "outputId": "4eb127b4-7c3d-4c22-bb3e-acb8a7042ef2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets Check the value counts so we'll know what our majority class is:\n",
      "0    570\n",
      "1    178\n",
      "Name: made_donation_in_march_2007, dtype: int64\n",
      "\n",
      "Because our mode is zero and we don't have any false positives on the baseline our recall is zero true postives / (zero true positives + zero false positives))\n",
      "Baseline Recall 0.0\n"
     ]
    }
   ],
   "source": [
    "# This question is tricky because using a baseline there would be no false negatives\n",
    "print(f\"Lets Check the value counts so we'll know what our majority class is:\\n{y.value_counts()}\\n\")\n",
    "print(f\"Because our mode is zero and we don't have any false positives on the baseline our recall is zero true postives / (zero true positives + zero false positives))\")\n",
    "\n",
    "# Finding Baseline Recall using Sklearn\n",
    "import numpy as np\n",
    "y_pred = np.full(shape=y.shape, fill_value=y.mode())# TODO\n",
    "baseline_recall = recall_score(y, y_pred)\n",
    "print ('Baseline Recall',baseline_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "ILS0fN0Cctyc",
    "outputId": "c26ee041-60af-4fba-a5d7-92decca640f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classification Score (recall): 0.0\n"
     ]
    }
   ],
   "source": [
    "# Finding Baseline Recall Using Dummy Classifier\n",
    "\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    DummyClassifier(strategy='most_frequent',random_state=42))\n",
    "\n",
    "pipe.fit(X, y)\n",
    "\n",
    "# Get the scores with the appropriate score function\n",
    "# Predict with X features and Compare predictions to y labels\n",
    "y_pred = pipe.predict(X)\n",
    "dummy_score = recall_score(y, y_pred)\n",
    "print('Dummy Classification Score (recall):', dummy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqYNDtwKYhji"
   },
   "source": [
    "## Part 1.2 — Split data\n",
    "\n",
    "In this Sprint Challenge, you will use \"Cross-Validation with Independent Test Set\" for your model evaluation protocol.\n",
    "\n",
    "First, **split the data into `X_train, X_test, y_train, y_test`**, with random shuffle. (You can include 75% of the data in the train set, and hold out 25% for the test set.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "mPKf86yDYf0t",
    "outputId": "7013045a-f6e9-4949-affd-bf0d7b672632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took this data...\n",
      "X Shape: (748, 4)\n",
      "Y Shape: (748,)\n",
      "\n",
      "\n",
      "And split it into this data... \n",
      "X_train Shape: (561, 4),\n",
      "X_test Shape: (187, 4),\n",
      "y_train Shape: (561,),\n",
      "y_test Shape: (187,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split(X_values, y_values):\n",
    "    # Hold out an \"out-of-time\" test set, from the last 100 days of data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_values, y_values, test_size=0.25, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "  \n",
    "X_train, X_test, y_train, y_test = split(X,y)\n",
    "print (\"Took this data...\")\n",
    "print (f'X Shape: {X.shape}\\nY Shape: {y.shape}\\n\\n')\n",
    "print (\"And split it into this data... \")\n",
    "print (f'X_train Shape: {X_train.shape},\\nX_test Shape: {X_test.shape},\\ny_train Shape: {y_train.shape},\\ny_test Shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E_ATNJdqTCuZ"
   },
   "source": [
    "## Part 2.1 — Make a pipeline\n",
    "\n",
    "Make a **pipeline** which includes:\n",
    "- Preprocessing with any scikit-learn [**Scaler**](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)\n",
    "- Feature selection with **[`SelectKBest`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)([`f_classif`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html))**\n",
    "- Classification with [**`LogisticRegression`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "8DRrVU5n5_Jw",
    "outputId": "e8af4ec5-d0ae-4da7-a9b9-dbeecf6d2f06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipe = make_pipeline(\n",
    "    RobustScaler(), \n",
    "    SelectKBest(f_classif), \n",
    "    LogisticRegression())\n",
    "\n",
    "print(\"Pipeline Created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5vRkQHatglMG"
   },
   "source": [
    "## Part 2.2 — Do Grid Search Cross-Validation\n",
    "\n",
    "Do [**GridSearchCV**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) with your pipeline. Use **5 folds** and **recall score**.\n",
    "\n",
    "Include these **parameters for your grid:**\n",
    "\n",
    "#### `SelectKBest`\n",
    "- `k : 1, 2, 3, 4`\n",
    "\n",
    "#### `LogisticRegression`\n",
    "- `class_weight : None, 'balanced'`\n",
    "- `C : .0001, .001, .01, .1, 1.0, 10.0, 100.00, 1000.0, 10000.0`\n",
    "\n",
    "\n",
    "**Fit** on the appropriate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "wgN8kG0ogBMH",
    "outputId": "5870e1a2-f3b2-4d67-dcc7-6a3577fbb3a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Cross Validation now running...\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search CV complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:    2.4s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\n",
    "    'selectkbest__k': [1,2,3,4], \n",
    "    'logisticregression__class_weight' : [None, 'balanced'],\n",
    "    'logisticregression__C' : [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.00, 1000.0, 10000.0]\n",
    "}\n",
    "\n",
    "# Fit on the train set, with grid search cross-validation\n",
    "gs = GridSearchCV(pipe, param_grid=param_grid, cv=5, \n",
    "                  scoring='recall_weighted', \n",
    "                  verbose=1)\n",
    "print(\"Grid Search Cross Validation now running...\")\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"Grid Search CV complete...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "urY_Wp3AiF83"
   },
   "source": [
    "## Part 3 — Show best score and parameters\n",
    "\n",
    "Display your **best cross-validation score**, and the **best parameters** (the values of `k, class_weight, C`) from the grid search.\n",
    "\n",
    "(You're not evaluated here on how good your score is, or which parameters you find. You're only evaluated on being able to display the information. There are several ways you can get the information, and any way is acceptable.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "colab_type": "code",
    "id": "qAxxkjG7gACP",
    "outputId": "8d58eee2-273f-4b67-c39b-406c62e10254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Grid Search Scores *****\n",
      "\n",
      "Best Cross-Validation Score: 0.7807486631016043\n",
      "Best parameters: {'logisticregression__C': 1.0, 'logisticregression__class_weight': None, 'selectkbest__k': 4} \n",
      "\n",
      "\n",
      "***** A few more stats just for me *****\n",
      "Train Score (Accuracy): 0.7789661319073083\n",
      "Test Score (Accuracy): 0.7540106951871658\n",
      "\n",
      "Train Score (\"Recall\"):  0.7789661319073083\n",
      "Test Score (\"Recall\"):  0.7540106951871658\n",
      "\n",
      "Best estimator:\n",
      " Pipeline(memory=None,\n",
      "     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "       with_scaling=True)), ('selectkbest', SelectKBest(k=4, score_func=<function f_classif at 0x7fe5d18f2158>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False))])\n",
      "\n",
      "Generated Results with Shape: (72, 23)\n"
     ]
    }
   ],
   "source": [
    "# Scores for the Question's Answer\n",
    "validation_score = gs.best_score_\n",
    "print('***** Grid Search Scores *****')\n",
    "print('\\nBest Cross-Validation Score:', validation_score)\n",
    "print('Best parameters:', gs.best_params_ ,'\\n')\n",
    "\n",
    "# Scores for me. \n",
    "print(\"\\n***** A few more stats just for me *****\")\n",
    "\n",
    "# Predict with X_test features and compare to actual.\n",
    "y_pred_train = gs.predict(X_train)\n",
    "train_score_A = accuracy_score(y_train, y_pred_train)\n",
    "print('Train Score (Accuracy):', train_score_A)\n",
    "y_pred_test = gs.predict(X_test)\n",
    "test_score_A = accuracy_score(y_test, y_pred_test)\n",
    "print('Test Score (Accuracy):', test_score_A)\n",
    "\n",
    "train_score_B = gs.score(X_train, y_train)\n",
    "print('\\nTrain Score (\"Recall\"): ', train_score_B)\n",
    "test_score_B = gs.score(X_test, y_test)\n",
    "print('Test Score (\"Recall\"): ', test_score_B)\n",
    "print('\\nBest estimator:\\n', gs.best_estimator_)\n",
    "cvresults = pd.DataFrame(gs.cv_results_)\n",
    "print('\\nGenerated Results with Shape:', cvresults.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jkyHoRIbEgRR"
   },
   "source": [
    "## Part 4 — Calculate classification metrics from a confusion matrix\n",
    "\n",
    "Suppose this is the confusion matrix for your binary classification model:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th colspan=\"2\" rowspan=\"2\"></th>\n",
    "    <th colspan=\"2\">Predicted</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Negative</th>\n",
    "    <th>Positive</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th rowspan=\"2\">Actual</th>\n",
    "    <th>Negative</th>\n",
    "    <td>85</td>\n",
    "    <td>58</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Positive</th>\n",
    "    <td>8</td>\n",
    "    <td>36</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Npu-IpcUMf3x"
   },
   "outputs": [],
   "source": [
    "true_negative = 85\n",
    "true_positive = 36\n",
    "false_negative = 8\n",
    "false_positive = 58"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LhyMM5H-JpVB"
   },
   "source": [
    "Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TZPwqdh2KUcB",
    "outputId": "71452d23-132a-4f77-bdeb-9f0c59042575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6470588235294118\n"
     ]
    }
   ],
   "source": [
    "accuracy = (true_negative + true_positive) / (true_negative + true_positive + false_negative + false_positive)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BRWLfGcGKeQw"
   },
   "source": [
    "Calculate precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A-FEZ4i_Kf_n",
    "outputId": "b51f829e-08e6-442d-a3d9-3441ce7275d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3829787234042553\n"
     ]
    }
   ],
   "source": [
    "precision = true_positive / (true_positive + false_positive)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h_mH2NYDKi2C"
   },
   "source": [
    "Calculate recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U4_wJGyjKkXJ",
    "outputId": "5156b333-1d53-40dc-c06b-f90c33ec5e3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "recall = true_positive / (true_positive + false_negative)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KEaWsk5Kk9W"
   },
   "source": [
    "## BONUS — How you can earn a score of 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nd1EeA8uT5EZ"
   },
   "source": [
    "### Part 1\n",
    "Do feature engineering, to try improving your cross-validation score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QsVrYUwQUBf0"
   },
   "outputs": [],
   "source": [
    "df[\"new_variable\"] = (df[\"months_since_first_donation\"] - df[\"months_since_last_donation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "colab_type": "code",
    "id": "OXsWEFLeUanC",
    "outputId": "4b3d293b-75ad-4fe4-8319-a5c8ba17e668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took this data...\n",
      "X Shape: (748, 5)\n",
      "Y Shape: (748,)\n",
      "\n",
      "\n",
      "And split it into this data... \n",
      "X_train Shape: (561, 5),\n",
      "X_test Shape: (187, 5),\n",
      "y_train Shape: (561,),\n",
      "y_test Shape: (187,)\n",
      "\n",
      "Pipeline Created\n",
      "\n",
      "Grid Search Cross Validation now running...\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search CV complete...\n",
      "\n",
      "***** Grid Search Scores *****\n",
      "New Cross-Validation Score: 0.7807486631016043\n",
      "Previous Cross-Validation Score 0.7807486631016043\n",
      "Best parameters: {'logisticregression__C': 1.0, 'logisticregression__class_weight': None, 'selectkbest__k': 4} \n",
      "\n",
      "\n",
      "***** A few more stats just for me *****\n",
      "Train Score (Accuracy): 0.7807486631016043\n",
      "Test Score (Accuracy): 0.7540106951871658\n",
      "\n",
      "Train Score (\"Recall\"):  0.7807486631016043\n",
      "Test Score (\"Recall\"):  0.7540106951871658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:    2.4s finished\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns='made_donation_in_march_2007')\n",
    "y = df.made_donation_in_march_2007\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = split(X,y)\n",
    "print (\"Took this data...\")\n",
    "print (f'X Shape: {X.shape}\\nY Shape: {y.shape}\\n\\n')\n",
    "print (\"And split it into this data... \")\n",
    "print (f'X_train Shape: {X_train.shape},\\nX_test Shape: {X_test.shape},\\ny_train Shape: {y_train.shape},\\ny_test Shape: {y_test.shape}')\n",
    "\n",
    "# Make Pipeline\n",
    "pipe = make_pipeline(\n",
    "    RobustScaler(), \n",
    "    SelectKBest(f_classif), \n",
    "    LogisticRegression())\n",
    "\n",
    "print(\"\\nPipeline Created\")\n",
    "\n",
    "# GridSearch CV\n",
    "param_grid = {\n",
    "    'selectkbest__k': [1,2,3,4], \n",
    "    'logisticregression__class_weight' : [None, 'balanced'],\n",
    "    'logisticregression__C' : [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.00, 1000.0, 10000.0]\n",
    "}\n",
    "\n",
    "# Fit on the train set, with grid search cross-validation\n",
    "gs = GridSearchCV(pipe, param_grid=param_grid, cv=5, \n",
    "                  scoring='recall_weighted', \n",
    "                  verbose=1)\n",
    "print(\"\\nGrid Search Cross Validation now running...\")\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"Grid Search CV complete...\")\n",
    "\n",
    "# Check out the scores\n",
    "new_validation_score = gs.best_score_\n",
    "print('\\n***** Grid Search Scores *****')\n",
    "print('New Cross-Validation Score:', new_validation_score)\n",
    "print('Previous Cross-Validation Score', validation_score)\n",
    "print('Best parameters:', gs.best_params_ ,'\\n')\n",
    "\n",
    "# Scores for me. \n",
    "print(\"\\n***** A few more stats just for me *****\")\n",
    "\n",
    "# Predict with X_test features and compare to actual.\n",
    "y_pred_train = gs.predict(X_train)\n",
    "train_score_C = accuracy_score(y_train, y_pred_train)\n",
    "print('Train Score (Accuracy):', train_score_C)\n",
    "y_pred_test = gs.predict(X_test)\n",
    "test_score_C = accuracy_score(y_test, y_pred_test)\n",
    "print('Test Score (Accuracy):', test_score_C)\n",
    "\n",
    "train_score_D = gs.score(X_train, y_train)\n",
    "print('\\nTrain Score (\"Recall\"): ', train_score_D)\n",
    "test_score_D = gs.score(X_test, y_test)\n",
    "print('Test Score (\"Recall\"): ', test_score_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vQCjItwWT6ks"
   },
   "source": [
    "### Part 2\n",
    "Add transformations in your pipeline and parameters in your grid, to try improving your cross-validation score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "hAXH5DU7UA4s",
    "outputId": "2e02afc7-05a1-4249-932a-1af3044a410b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pipeline Created\n",
      "\n",
      "Grid Search Cross Validation now running...\n",
      "Fitting 10 folds for each of 576 candidates, totalling 5760 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed:   41.3s\n",
      "[Parallel(n_jobs=10)]: Done 1230 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=10)]: Done 1780 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=10)]: Done 2430 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=10)]: Done 3180 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=10)]: Done 4030 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=10)]: Done 4980 tasks      | elapsed:  4.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search CV complete...\n",
      "\n",
      "***** Grid Search Scores *****\n",
      "New Cross-Validation Score: 0.8003565062388592\n",
      "Previous Cross-Validation Score 0.7807486631016043\n",
      "Best parameters: {'randomforestclassifier__bootstrap': False, 'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__max_depth': 80, 'randomforestclassifier__min_samples_leaf': 4, 'randomforestclassifier__min_samples_split': 10, 'randomforestclassifier__n_estimators': 200, 'selectkbest__k': 4} \n",
      "\n",
      "Best score: 0.8003565062388592\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "       with_scaling=True)), ('selectkbest', SelectKBest(k=4, score_func=<function f_classif at 0x7fe5d18f2158>)), ('randomforestclassifier', RandomForestClassifier(bootstrap=False, class_weight=None, cr...obs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done 5760 out of 5760 | elapsed:  5.2min finished\n"
     ]
    }
   ],
   "source": [
    "# I'm going to try a slightly different one this time. I want to try random forest classifier. \n",
    "\n",
    "# Make Pipeline\n",
    "pipe = make_pipeline(\n",
    "    RobustScaler(), \n",
    "    SelectKBest(f_classif), \n",
    "    RandomForestClassifier())\n",
    "\n",
    "print(\"\\nPipeline Created\")\n",
    "\n",
    "# GridSearch CV\n",
    "param_grid = {\n",
    "    'selectkbest__k': [1,2,3,4], \n",
    "    \"randomforestclassifier__max_depth\": [80, 90, 100, 110],\n",
    "#    \"randomforestclassifier__max_features\": [2, 3],\n",
    "    \"randomforestclassifier__min_samples_split\": [8, 10, 12],\n",
    "    \"randomforestclassifier__min_samples_leaf\": [3, 4, 5],\n",
    "    \"randomforestclassifier__bootstrap\": [False],\n",
    "    \"randomforestclassifier__n_estimators\" :[100, 200, 300, 1000],\n",
    "    \"randomforestclassifier__criterion\": [\"gini\"]}\n",
    "\n",
    "\n",
    "# Fit on the train set, with grid search cross-validation\n",
    "gs = GridSearchCV(pipe, param_grid=param_grid, cv=10, \n",
    "                  scoring='recall_weighted', \n",
    "                  verbose=1, n_jobs=10)\n",
    "\n",
    "print(\"\\nGrid Search Cross Validation now running...\")\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"Grid Search CV complete...\")\n",
    "\n",
    "# Check out the scores\n",
    "new_validation_score = gs.best_score_\n",
    "print('\\n***** Grid Search Scores *****')\n",
    "print('New Cross-Validation Score:', new_validation_score)\n",
    "print('Previous Cross-Validation Score', validation_score)\n",
    "print('Best parameters:', gs.best_params_ ,'\\n')\n",
    "print('Best score:', gs.best_score_)\n",
    "print('Best estimator:', gs.best_estimator_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets see how it's test stats turned out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier - Train Score (Accuracy): 0.8645276292335116\n",
      "Random Forest Classifier - Test Score (Accuracy): 0.7379679144385026\n",
      "\n",
      "Random Forest Classifier - Train Score (\"Recall\"):  0.8645276292335116\n",
      "Random Forest Classifier - Test Score (\"Recall\"):  0.7379679144385026\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = gs.predict(X_train)\n",
    "train_score_C = accuracy_score(y_train, y_pred_train)\n",
    "print('Random Forest Classifier - Train Score (Accuracy):', train_score_C)\n",
    "y_pred_test = gs.predict(X_test)\n",
    "test_score_C = accuracy_score(y_test, y_pred_test)\n",
    "print('Random Forest Classifier - Test Score (Accuracy):', test_score_C)\n",
    "\n",
    "train_score_D = gs.score(X_train, y_train)\n",
    "print('\\nRandom Forest Classifier - Train Score (\"Recall\"): ', train_score_D)\n",
    "test_score_D = gs.score(X_test, y_test)\n",
    "print('Random Forest Classifier - Test Score (\"Recall\"): ', test_score_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uHQGZ8pJT9Gl"
   },
   "source": [
    "### Part 3\n",
    "Show names of selected features. Then do a final evaluation on the test set — what is the test score?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErfSIVPGT-5U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected:\n",
      "months_since_last_donation\n",
      "number_of_donations\n",
      "total_volume_donated\n",
      "new_variable\n",
      "\n",
      "Features not selected:\n",
      "months_since_first_donation\n"
     ]
    }
   ],
   "source": [
    "# Which features were selected?\n",
    "# 'selectkbest' is the autogenerated name of the SelectKBest() function in the pipeline\n",
    "selector = gs.best_estimator_.named_steps['selectkbest']\n",
    "all_names = X_train.columns\n",
    "\n",
    "# get_support returns a mask of the columns in True / False\n",
    "selected_mask = selector.get_support()\n",
    "# Passing the boolean list as the column names creates a \n",
    "selected_names = all_names[selected_mask]\n",
    "unselected_names = all_names[~selected_mask]\n",
    "\n",
    "print('Features selected:')\n",
    "for name in selected_names:\n",
    "    print(name)\n",
    "\n",
    "print()\n",
    "print('Features not selected:')\n",
    "for name in unselected_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2bN-OzZT_We"
   },
   "source": [
    "\n",
    "### Part 4\n",
    "Calculate F1 score and False Positive Rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2bIQrqcuT_wU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier - F1 Train Score: 0.6576576576576576\n",
      "Random Forest Classifier - F1 Test Score: 0.3466666666666667\n",
      "Random Forest Classifier - Train False Positive Rate: 0.20652173913043478\n",
      "Random Forest Classifier - Test False Positive Rate: 0.5185185185185185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred_train = gs.predict(X_train)\n",
    "train_score_F1 = f1_score(y_train, y_pred_train)\n",
    "print('Random Forest Classifier - F1 Train Score:', train_score_F1)\n",
    "y_pred_test = gs.predict(X_test)\n",
    "test_score_F1 = f1_score(y_test, y_pred_test)\n",
    "print('Random Forest Classifier - F1 Test Score:', test_score_F1)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_train).ravel()\n",
    "print(f'Random Forest Classifier - Train False Positive Rate: {fp / (fp + tp)}')\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "print(f'Random Forest Classifier - Test False Positive Rate: {fp / (fp + tp)}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS_Unit_2_Sprint_Challenge_4_Model_Validation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
