{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PC9RfopIWrc9"
   },
   "source": [
    " # Data Science Unit 2 Sprint Challenge 4 — Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UV7ArLFQN84W"
   },
   "source": [
    "Follow the instructions for each numbered part to earn a score of 2. See the bottom of the notebook for a list of ways you can earn a score of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAZcbTtiUlkI"
   },
   "source": [
    "## Predicting Blood Donations\n",
    "\n",
    "Our dataset is from a mobile blood donation vehicle in Taiwan. The Blood Transfusion Service Center drives to different universities and collects blood as part of a blood drive.\n",
    "\n",
    "The **goal** is to predict the **last column** = whether the donor made a **donation in March 2007**, using information about each donor's history. We'll measure success using **_recall score_ as the model evaluation metric**.\n",
    "\n",
    "Good data-driven systems for tracking and predicting donations and supply needs can improve the entire supply chain, making sure that more patients get the blood transfusions they need.\n",
    "\n",
    "#### Run this cell to load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvV9VORbxyvu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data')\n",
    "\n",
    "df = df.rename(columns={\n",
    "    'Recency (months)': 'months_since_last_donation', \n",
    "    'Frequency (times)': 'number_of_donations', \n",
    "    'Monetary (c.c. blood)': 'total_volume_donated', \n",
    "    'Time (months)': 'months_since_first_donation', \n",
    "    'whether he/she donated blood in March 2007': 'made_donation_in_march_2007'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxKfgx4ycb3c"
   },
   "source": [
    "## Part 1.1 — Begin with baselines\n",
    "\n",
    "What **accuracy score** would you get here with a **\"majority class baseline\"?** \n",
    " \n",
    "(You don't need to split the data into train and test sets yet. You can answer this question either with a scikit-learn function or with a pandas function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3oo31Remcq-x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_KdxE1TrcriI"
   },
   "source": [
    "What **recall score** would you get here with a **majority class baseline?**\n",
    "\n",
    "(You can answer this question either with a scikit-learn function or with no code, just your understanding of recall.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILS0fN0Cctyc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqYNDtwKYhji"
   },
   "source": [
    "## Part 1.2 — Split data\n",
    "\n",
    "In this Sprint Challenge, you will use \"Cross-Validation with Independent Test Set\" for your model evaluation protocol.\n",
    "\n",
    "First, **split the data into `X_train, X_test, y_train, y_test`**, with random shuffle. (You can include 75% of the data in the train set, and hold out 25% for the test set.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPKf86yDYf0t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E_ATNJdqTCuZ"
   },
   "source": [
    "## Part 2.1 — Make a pipeline\n",
    "\n",
    "Make a **pipeline** which includes:\n",
    "- Preprocessing with any scikit-learn [**Scaler**](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)\n",
    "- Feature selection with **[`SelectKBest`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)([`f_classif`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html))**\n",
    "- Classification with [**`LogisticRegression`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8DRrVU5n5_Jw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5vRkQHatglMG"
   },
   "source": [
    "## Part 2.2 — Do Grid Search Cross-Validation\n",
    "\n",
    "Do [**GridSearchCV**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) with your pipeline. Use **5 folds** and **recall score**.\n",
    "\n",
    "Include these **parameters for your grid:**\n",
    "\n",
    "#### `SelectKBest`\n",
    "- `k : 1, 2, 3, 4`\n",
    "\n",
    "#### `LogisticRegression`\n",
    "- `class_weight : None, 'balanced'`\n",
    "- `C : .0001, .001, .01, .1, 1.0, 10.0, 100.00, 1000.0, 10000.0`\n",
    "\n",
    "\n",
    "**Fit** on the appropriate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgN8kG0ogBMH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "urY_Wp3AiF83"
   },
   "source": [
    "## Part 3 — Show best score and parameters\n",
    "\n",
    "Display your **best cross-validation score**, and the **best parameters** (the values of `k, class_weight, C`) from the grid search.\n",
    "\n",
    "(You're not evaluated here on how good your score is, or which parameters you find. You're only evaluated on being able to display the information. There are several ways you can get the information, and any way is acceptable.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qAxxkjG7gACP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jkyHoRIbEgRR"
   },
   "source": [
    "## Part 4 — Calculate classification metrics from a confusion matrix\n",
    "\n",
    "Suppose this is the confusion matrix for your binary classification model:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th colspan=\"2\" rowspan=\"2\"></th>\n",
    "    <th colspan=\"2\">Predicted</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Negative</th>\n",
    "    <th>Positive</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th rowspan=\"2\">Actual</th>\n",
    "    <th>Negative</th>\n",
    "    <td>85</td>\n",
    "    <td>58</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Positive</th>\n",
    "    <td>8</td>\n",
    "    <td>36</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LhyMM5H-JpVB"
   },
   "source": [
    "Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZPwqdh2KUcB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BRWLfGcGKeQw"
   },
   "source": [
    "Calculate precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-FEZ4i_Kf_n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h_mH2NYDKi2C"
   },
   "source": [
    "Calculate recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U4_wJGyjKkXJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KEaWsk5Kk9W"
   },
   "source": [
    "## BONUS — How you can earn a score of 3\n",
    "\n",
    "### Part 1\n",
    "Do feature engineering, to try improving your cross-validation score.\n",
    "\n",
    "### Part 2\n",
    "Add transformations in your pipeline and parameters in your grid, to try improving your cross-validation score.\n",
    "\n",
    "### Part 3\n",
    "Show names of selected features. Then do a final evaluation on the test set — what is the test score?\n",
    "\n",
    "### Part 4\n",
    "Calculate F1 score and False Positive Rate. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS_Unit_2_Sprint_Challenge_4_Model_Validation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
