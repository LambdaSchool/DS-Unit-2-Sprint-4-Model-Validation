{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PC9RfopIWrc9"
   },
   "source": [
    " # Data Science Unit 2 Sprint Challenge 4 â€” Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UV7ArLFQN84W"
   },
   "source": [
    "Follow the instructions for each numbered part to earn a score of 2. See the bottom of the notebook for a list of ways you can earn a score of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAZcbTtiUlkI"
   },
   "source": [
    "## Predicting Blood Donations\n",
    "\n",
    "Our dataset is from a mobile blood donation vehicle in Taiwan. The Blood Transfusion Service Center drives to different universities and collects blood as part of a blood drive.\n",
    "\n",
    "The goal is to predict the last column, whether the donor made a donation in March 2007, using information about each donor's history. We'll measure success using recall score as the model evaluation metric.\n",
    "\n",
    "Good data-driven systems for tracking and predicting donations and supply needs can improve the entire supply chain, making sure that more patients get the blood transfusions they need.\n",
    "\n",
    "#### Run this cell to load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvV9VORbxyvu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 0     1     2     3     4\n",
      "months_since_last_donation       2     0     1     2     1\n",
      "number_of_donations             50    13    16    20    24\n",
      "total_volume_donated         12500  3250  4000  5000  6000\n",
      "months_since_first_donation     98    28    35    45    77\n",
      "made_donation_in_march_2007      1     1     1     1     0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "months_since_last_donation\n",
      "Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 35, 38, 39, 40, 72, 74], dtype='int64')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "number_of_donations\n",
      "Int64Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 33, 34, 38, 41, 43, 44, 46, 50], dtype='int64')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "total_volume_donated\n",
      "Int64Index([250, 500, 750, 1000, 1250, 1500, 1750, 2000, 2250, 2500, 2750, 3000, 3250, 3500, 3750, 4000, 4250, 4500, 4750, 5000, 5250, 5500, 5750, 6000, 6500, 8250, 8500, 9500, 10250, 10750, 11000, 11500, 12500], dtype='int64')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "months_since_first_donation\n",
      "Int64Index([2, 3, 4, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 86, 87, 88, 89, 93, 95, 98], dtype='int64')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "made_donation_in_march_2007\n",
      "Int64Index([0, 1], dtype='int64')\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data')\n",
    "\n",
    "df = df.rename(columns={\n",
    "    'Recency (months)': 'months_since_last_donation', \n",
    "    'Frequency (times)': 'number_of_donations', \n",
    "    'Monetary (c.c. blood)': 'total_volume_donated', \n",
    "    'Time (months)': 'months_since_first_donation', \n",
    "    'whether he/she donated blood in March 2007': 'made_donation_in_march_2007'\n",
    "})\n",
    "\n",
    "def ini_preview(df):\n",
    "  print(df.head().T)\n",
    "  print(\"-\"*100)\n",
    "  for i in df.columns:\n",
    "    print(i)\n",
    "    print(df[i].value_counts().index.sort_values())  \n",
    "    print(\"-\"*100)\n",
    "ini_preview(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape:\n",
      "(748, 5)\n",
      "------------------------------------------------------------\n",
      "df columns:\n",
      "Index(['months_since_last_donation', 'number_of_donations', 'total_volume_donated', 'months_since_first_donation', 'made_donation_in_march_2007'], dtype='object')\n",
      "------------------------------------------------------------\n",
      "df select_dtypes(include=[np.number]).columns.values:\n",
      "['months_since_last_donation' 'number_of_donations' 'total_volume_donated'\n",
      " 'months_since_first_donation' 'made_donation_in_march_2007']\n",
      "------------------------------------------------------------\n",
      "df select_dtypes(exclude=[np.number]).columns:\n",
      "Index([], dtype='object')\n",
      "------------------------------------------------------------\n",
      "df dtypes.sort_values(ascending=False):\n",
      "made_donation_in_march_2007    int64\n",
      "months_since_first_donation    int64\n",
      "total_volume_donated           int64\n",
      "number_of_donations            int64\n",
      "months_since_last_donation     int64\n",
      "dtype: object\n",
      "------------------------------------------------------------\n",
      "df head().T:\n",
      "                                 0     1     2     3     4\n",
      "months_since_last_donation       2     0     1     2     1\n",
      "number_of_donations             50    13    16    20    24\n",
      "total_volume_donated         12500  3250  4000  5000  6000\n",
      "months_since_first_donation     98    28    35    45    77\n",
      "made_donation_in_march_2007      1     1     1     1     0\n",
      "------------------------------------------------------------\n",
      "df isnull().sum().sum():\n",
      "0\n",
      "------------------------------------------------------------\n",
      "df isna().sum().sort_values(ascending=False):\n",
      "made_donation_in_march_2007    0\n",
      "months_since_first_donation    0\n",
      "total_volume_donated           0\n",
      "number_of_donations            0\n",
      "months_since_last_donation     0\n",
      "dtype: int64\n",
      "------------------------------------------------------------\n",
      "columns[df.isna().any()].tolist():\n",
      "[]\n",
      "\n",
      "df corr().T:\n",
      "                             months_since_last_donation  number_of_donations  total_volume_donated  months_since_first_donation  made_donation_in_march_2007\n",
      "months_since_last_donation                     1.000000            -0.182745             -0.182745                     0.160618                    -0.279869\n",
      "number_of_donations                           -0.182745             1.000000              1.000000                     0.634940                     0.218633\n",
      "total_volume_donated                          -0.182745             1.000000              1.000000                     0.634940                     0.218633\n",
      "months_since_first_donation                    0.160618             0.634940              0.634940                     1.000000                    -0.035854\n",
      "made_donation_in_march_2007                   -0.279869             0.218633              0.218633                    -0.035854                     1.000000\n",
      "\n",
      "df describe(include='all').T:\n",
      "                             count         mean          std    min     25%     50%     75%      max\n",
      "months_since_last_donation   748.0     9.506684     8.095396    0.0    2.75     7.0    14.0     74.0\n",
      "number_of_donations          748.0     5.514706     5.839307    1.0    2.00     4.0     7.0     50.0\n",
      "total_volume_donated         748.0  1378.676471  1459.826781  250.0  500.00  1000.0  1750.0  12500.0\n",
      "months_since_first_donation  748.0    34.282086    24.376714    2.0   16.00    28.0    50.0     98.0\n",
      "made_donation_in_march_2007  748.0     0.237968     0.426124    0.0    0.00     0.0     0.0      1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview data\n",
    "print(\"df shape:\"), print(df.shape), print(\"---\"*20)\n",
    "print(\"df columns:\"), print(df.columns), print(\"---\"*20)\n",
    "print(\"df select_dtypes(include=[np.number]).columns.values:\"), print(df.select_dtypes(include=[np.number]).columns.values), print(\"---\"*20)\n",
    "print(\"df select_dtypes(exclude=[np.number]).columns:\"), print(df.select_dtypes(exclude=[np.number]).columns), print(\"---\"*20)\n",
    "print(\"df dtypes.sort_values(ascending=False):\"), print(df.dtypes.sort_values(ascending=False)), print(\"---\"*20)\n",
    "print(\"df head().T:\"), print(df.head().T), print(\"---\"*20)\n",
    "print(\"df isnull().sum().sum():\"), print(df.isnull().sum().sum()), print(\"---\"*20)\n",
    "print(\"df isna().sum().sort_values(ascending=False):\"), print(df.isna().sum().sort_values(ascending=False)), print(\"---\"*20)\n",
    "# nan finder\n",
    "print(\"columns[df.isna().any()].tolist():\"), print(df.columns[df.isna().any()].tolist()), print(\"\")\n",
    "# stats data\n",
    "print(\"df corr().T:\"), print(df.corr().T), print(\"\")\n",
    "print(\"df describe(include='all').T:\"), print(df.describe(include='all').T), print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxKfgx4ycb3c"
   },
   "source": [
    "## Part 1.1 â€” Begin with baselines\n",
    "\n",
    "What **accuracy score** would you get here with a **\"majority class baseline\"?** \n",
    " \n",
    "(You don't need to split the data into train and test sets yet. You can answer this question either with a scikit-learn function or with a pandas function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3oo31Remcq-x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7620320855614974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Data source\n",
    "X = df.drop(columns=[\"made_donation_in_march_2007\"], axis=1)\n",
    "y = df[\"made_donation_in_march_2007\"]\n",
    "\n",
    "# Majority class baseline = mode\n",
    "majority_class = y.mode()[0]\n",
    "y_pred = np.full(shape=y.shape, fill_value=majority_class)\n",
    "\n",
    "# Accuracy score\n",
    "accuracy = accuracy_score(y,y_pred)\n",
    "print('Accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_KdxE1TrcriI"
   },
   "source": [
    "What **recall score** would you get here with a **majority class baseline?**\n",
    "\n",
    "(You can answer this question either with a scikit-learn function or with no code, just your understanding of recall.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILS0fN0Cctyc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score from majority class baseline: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(y, y_pred)\n",
    "print('Recall score from majority class baseline:',recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqYNDtwKYhji"
   },
   "source": [
    "## Part 1.2 â€” Split data\n",
    "\n",
    "In this Sprint Challenge, you will use \"Cross-Validation with Independent Test Set\" for your model evaluation protocol.\n",
    "\n",
    "First, **split the data into `X_train, X_test, y_train, y_test`**, with random shuffle. (You can include 75% of the data in the train set, and hold out 25% for the test set.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPKf86yDYf0t"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E_ATNJdqTCuZ"
   },
   "source": [
    "## Part 2.1 â€” Make a pipeline\n",
    "\n",
    "Make a **pipeline** which includes:\n",
    "- Preprocessing with any scikit-learn [**Scaler**](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)\n",
    "- Feature selection with **[`SelectKBest`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)([`f_classif`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html))**\n",
    "- Classification with [**`LogisticRegression`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8DRrVU5n5_Jw"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "# data Process\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# model setup\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# metric\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SelectKBest(f_classif),\n",
    "    LogisticRegression(solver = 'lbfgs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5vRkQHatglMG"
   },
   "source": [
    "## Part 2.2 â€”Â Do Grid Search Cross-Validation\n",
    "\n",
    "Do [**GridSearchCV**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) with your pipeline. Use **5 folds** and **recall score**.\n",
    "\n",
    "Include these **parameters for your grid:**\n",
    "\n",
    "#### `SelectKBest`\n",
    "- `k : 1, 2, 3, 4`\n",
    "\n",
    "#### `LogisticRegression`\n",
    "- `class_weight : None, 'balanced'`\n",
    "- `C : .0001, .001, .01, .1, 1.0, 10.0, 100.00, 1000.0, 10000.0`\n",
    "\n",
    "\n",
    "**Fit** on the appropriate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgN8kG0ogBMH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:    7.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('selectkbest', SelectKBest(k=10, score_func=<function f_classif at 0x7f15064ee510>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'selectkbest__k': [1, 2, 3, 4], 'logisticregression__class_weight': [None, 'balanced'], 'logisticregression__C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define param_grid\n",
    "param_grid = {\n",
    "    'selectkbest__k': [1,2,3,4],\n",
    "    'logisticregression__class_weight': [None, 'balanced'],\n",
    "    'logisticregression__C' : [.0001,.001,.01,.1,1.0,10.0,100.00,1000.0,10000.0]\n",
    "}\n",
    "\n",
    "# Fit on the train set, with grid search cross-validation\n",
    "gs = GridSearchCV(pipeline, param_grid=param_grid,cv=5, scoring='recall', verbose=1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "urY_Wp3AiF83"
   },
   "source": [
    "## Part 3 â€”Â Show best score and parameters\n",
    "\n",
    "Display your **best cross-validation score**, and the **best parameters** (the values of `k, class_weight, C`) from the grid search.\n",
    "\n",
    "(You're not evaluated here on how good your score is, or which parameters you find. You're only evaluated on being able to display the information. There are several ways you can get the information, and any way is acceptable.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qAxxkjG7gACP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score:  0.7869710173631743\n",
      "Best paramter: {'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced', 'selectkbest__k': 2}\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('selectkbest', SelectKBest(k=2, score_func=<function f_classif at 0x7f15064ee510>)), ('logisticregression', LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
      "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation Results\n",
    "validation_score = gs.best_score_\n",
    "print('Validation Score: ', validation_score)\n",
    "print('Best parameter:', gs.best_params_)\n",
    "print('Best estimator:', gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['months_since_last_donation', 'number_of_donations', 'total_volume_donated', 'months_since_first_donation'], dtype='object')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Features selected:\n",
      "months_since_last_donation\n",
      "total_volume_donated\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Features not selected:\n",
      "number_of_donations\n",
      "months_since_first_donation\n",
      "----------------------------------------------------------------------------------------------------\n",
      "recall_score: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "selector = gs.best_estimator_.named_steps['selectkbest']\n",
    "all_names = X_train.columns\n",
    "selected_mask = selector.get_support()\n",
    "selected_names=all_names[selected_mask]\n",
    "unselected_names = all_names[~selected_mask]\n",
    "\n",
    "print(all_names)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print('Features selected:')\n",
    "for name in selected_names:\n",
    "  print(name)\n",
    "  \n",
    "print(\"-\"*100)\n",
    "print(\"Features not selected:\")\n",
    "for name in unselected_names:\n",
    "  print(name)\n",
    "\n",
    "print(\"-\"*100)\n",
    "y_pred = gs.predict(X_test)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('recall_score:', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jkyHoRIbEgRR"
   },
   "source": [
    "## Part 4 â€”Â Calculate classification metrics from a confusion matrix\n",
    "\n",
    "Suppose this is the confusion matrix for your binary classification model:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th colspan=\"2\" rowspan=\"2\"></th>\n",
    "    <th colspan=\"2\">Predicted</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Negative</th>\n",
    "    <th>Positive</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th rowspan=\"2\">Actual</th>\n",
    "    <th>Negative</th>\n",
    "    <td>85</td>\n",
    "    <td>58</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Positive</th>\n",
    "    <td>8</td>\n",
    "    <td>36</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LhyMM5H-JpVB"
   },
   "source": [
    "Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZPwqdh2KUcB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6470588235294118\n"
     ]
    }
   ],
   "source": [
    "true_negative  = 85\n",
    "false_positive = 58\n",
    "false_negative = 8\n",
    "true_positive  = 36\n",
    "predicted_negative = true_negative + false_negative\n",
    "predicted_positive = true_positive + false_positive\n",
    "actual_negative = true_negative + false_positive\n",
    "actual_positive = true_positive + false_negative\n",
    "\n",
    "accuracy = (true_negative + true_positive) / (true_negative + false_positive + false_negative + true_positive)\n",
    "precision = true_positive / predicted_positive\n",
    "recall = true_positive / actual_positive\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BRWLfGcGKeQw"
   },
   "source": [
    "Calculate precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-FEZ4i_Kf_n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3829787234042553\n"
     ]
    }
   ],
   "source": [
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h_mH2NYDKi2C"
   },
   "source": [
    "Calculate recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U4_wJGyjKkXJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KEaWsk5Kk9W"
   },
   "source": [
    "## BONUS â€”Â How you can earn a score of 3\n",
    "\n",
    "### Part 1\n",
    "Do feature engineering, to try improving your cross-validation score.\n",
    "\n",
    "### Part 2\n",
    "Add transformations in your pipeline and parameters in your grid, to try improving your cross-validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Data source\n",
    "X = df.drop(columns=[\"made_donation_in_march_2007\"], axis=1)\n",
    "y = df[\"made_donation_in_march_2007\"]\n",
    "\n",
    "# Test polynomialFeatures before split\n",
    "poly = PolynomialFeatures()\n",
    "X = poly.fit_transform(X)\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.25)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    RobustScaler(),\n",
    "    SelectKBest(f_classif),\n",
    "    LogisticRegression(solver = 'liblinear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1350 out of 1350 | elapsed:   34.7s finished\n",
      "/home/superio/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "       with_scaling=True)), ('selectkbest', SelectKBest(k=10, score_func=<function f_classif at 0x7f15064ee510>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_int...ty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'selectkbest__k': range(1, 16), 'logisticregression__class_weight': [None, 'balanced'], 'logisticregression__C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(action='ignore', category=RuntimeWarning)\n",
    "# Define param_grid\n",
    "param_grid = {\n",
    "    'selectkbest__k': range(1, len(X_train.columns)+1),\n",
    "    'logisticregression__class_weight': [None, 'balanced'],\n",
    "    'logisticregression__C' : [.0001,.001,.01,.1,1.0,10.0,100.00,1000.0,10000.0]\n",
    "}\n",
    "\n",
    "# Fit on the train set, with grid search cross-validation\n",
    "gs = GridSearchCV(pipeline, param_grid=param_grid,cv=5, scoring='recall', verbose=1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score:  0.8003565062388592\n",
      "Best paramter: {'logisticregression__C': 0.01, 'logisticregression__class_weight': 'balanced', 'selectkbest__k': 8}\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "       with_scaling=True)), ('selectkbest', SelectKBest(k=8, score_func=<function f_classif at 0x7f15064ee510>)), ('logisticregression', LogisticRegression(C=0.01, class_weight='balanced', dual=False,\n",
      " ...ty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation Results\n",
    "validation_score = gs.best_score_\n",
    "print('Validation Score: ', validation_score)\n",
    "print('Best parameter:', gs.best_params_)\n",
    "print('Best estimator:', gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "Show names of selected features. Then do a final evaluation on the test set â€” what is the test score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=15, step=1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Features selected:\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "8\n",
      "9\n",
      "10\n",
      "12\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Features not selected:\n",
      "0\n",
      "4\n",
      "6\n",
      "7\n",
      "11\n",
      "13\n",
      "14\n",
      "----------------------------------------------------------------------------------------------------\n",
      "recall_score: 0.7169811320754716\n"
     ]
    }
   ],
   "source": [
    "selector = gs.best_estimator_.named_steps['selectkbest']\n",
    "all_names = X_train.columns\n",
    "selected_mask = selector.get_support()\n",
    "selected_names=all_names[selected_mask]\n",
    "unselected_names = all_names[~selected_mask]\n",
    "\n",
    "print(all_names)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print('Features selected:')\n",
    "for name in selected_names:\n",
    "  print(name)\n",
    "  \n",
    "print(\"-\"*100)\n",
    "print(\"Features not selected:\")\n",
    "for name in unselected_names:\n",
    "  print(name)\n",
    "\n",
    "print(\"-\"*100)\n",
    "y_pred = gs.predict(X_test)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('recall_score:', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4\n",
    "Calculate F1 score and False Positive Rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.62      0.72       134\n",
      "           1       0.43      0.72      0.54        53\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       187\n",
      "   macro avg       0.64      0.67      0.63       187\n",
      "weighted avg       0.73      0.65      0.66       187\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative</th>\n",
       "      <td>83</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positive</th>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Negative  Predicted Positive\n",
       "Actual Negative                  83                  51\n",
       "Actual Positive                  15                  38"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"-\"*100)\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
    "             columns=['Predicted Negative', 'Predicted Positive'], \n",
    "             index=['Actual Negative', 'Actual Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6470588235294118\n",
      "Precision: 0.42696629213483145\n",
      "Recall: 0.7169811320754716\n",
      "False Positive Rate: 0.3805970149253731\n",
      "F1 Score: 0.5352112676056338\n"
     ]
    }
   ],
   "source": [
    "true_negative  = 83\n",
    "false_positive = 51\n",
    "false_negative = 15\n",
    "true_positive  = 38\n",
    "predicted_negative = true_negative + false_negative\n",
    "predicted_positive = true_positive + false_positive\n",
    "actual_negative = true_negative + false_positive\n",
    "actual_positive = true_positive + false_negative\n",
    "\n",
    "accuracy = (true_negative + true_positive) / (true_negative + false_positive + false_negative + true_positive)\n",
    "precision = true_positive / predicted_positive\n",
    "recall = true_positive / actual_positive\n",
    "\n",
    "FPR = false_positive/(false_positive+true_negative)\n",
    "f1 = 2 * precision*recall / (precision+recall)\n",
    "print('Accuracy:',accuracy)\n",
    "print('Precision:',precision)\n",
    "print('Recall:',recall)\n",
    "print('False Positive Rate:',FPR)\n",
    "print('F1 Score:',f1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS_Unit_2_Sprint_Challenge_4_Model_Validation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
