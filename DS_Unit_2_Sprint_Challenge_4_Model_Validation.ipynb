{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS_Unit_2_Sprint_Challenge_4_Model_Validation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DimaKav/DS-Unit-2-Sprint-4-Model-Validation/blob/master/DS_Unit_2_Sprint_Challenge_4_Model_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "PC9RfopIWrc9"
      },
      "cell_type": "markdown",
      "source": [
        " # Data Science Unit 2 Sprint Challenge 4 — Model Validation"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "UV7ArLFQN84W"
      },
      "cell_type": "markdown",
      "source": [
        "Follow the instructions for each numbered part to earn a score of 2. See the bottom of the notebook for a list of ways you can earn a score of 3."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bAZcbTtiUlkI"
      },
      "cell_type": "markdown",
      "source": [
        "## Predicting Blood Donations\n",
        "\n",
        "Our dataset is from a mobile blood donation vehicle in Taiwan. The Blood Transfusion Service Center drives to different universities and collects blood as part of a blood drive.\n",
        "\n",
        "The goal is to predict the last column, whether the donor made a donation in March 2007, using information about each donor's history. We'll measure success using recall score as the model evaluation metric.\n",
        "\n",
        "Good data-driven systems for tracking and predicting donations and supply needs can improve the entire supply chain, making sure that more patients get the blood transfusions they need.\n",
        "\n",
        "#### Run this cell to load the data:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gvV9VORbxyvu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data')\n",
        "\n",
        "df = df.rename(columns={\n",
        "    'Recency (months)': 'months_since_last_donation', \n",
        "    'Frequency (times)': 'number_of_donations', \n",
        "    'Monetary (c.c. blood)': 'total_volume_donated', \n",
        "    'Time (months)': 'months_since_first_donation', \n",
        "    'whether he/she donated blood in March 2007': 'made_donation_in_march_2007'\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "IxKfgx4ycb3c"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 1.1 — Begin with baselines\n",
        "\n",
        "What **accuracy score** would you get here with a **\"majority class baseline\"?** \n",
        " \n",
        "(You don't need to split the data into train and test sets yet. You can answer this question either with a scikit-learn function or with a pandas function.)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3oo31Remcq-x",
        "colab": {},
        "outputId": "e272d5d8-9fbe-4c94-e7a2-ebf8c6787ca8"
      },
      "cell_type": "code",
      "source": [
        "df['made_donation_in_march_2007'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    570\n",
              "1    178\n",
              "Name: made_donation_in_march_2007, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "metadata": {
        "id": "ccxXDhY6tRVc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "0 is our majority class"
      ]
    },
    {
      "metadata": {
        "id": "tjvVoFx9tRVd",
        "colab_type": "code",
        "colab": {},
        "outputId": "2924859f-dcf4-46fc-b091-4b6c4c261d4e"
      },
      "cell_type": "code",
      "source": [
        "X = df.drop('made_donation_in_march_2007',axis=1)\n",
        "y = df['made_donation_in_march_2007']\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
        "\n",
        "majority_class = 0\n",
        "y_pred = [majority_class] * len(y_val)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_val, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7754010695187166"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_KdxE1TrcriI"
      },
      "cell_type": "markdown",
      "source": [
        "What **recall score** would you get here with a **majority class baseline?**\n",
        "\n",
        "(You can answer this question either with a scikit-learn function or with no code, just your understanding of recall.)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ILS0fN0Cctyc",
        "colab": {},
        "outputId": "b8feb984-4fce-4737-9f17-647ecfb93a75"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "recall_score(y_val, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QqYNDtwKYhji"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 1.2 — Split data\n",
        "\n",
        "In this Sprint Challenge, you will use \"Cross-Validation with Independent Test Set\" for your model evaluation protocol.\n",
        "\n",
        "First, **split the data into `X_train, X_test, y_train, y_test`**, with random shuffle. (You can include 75% of the data in the train set, and hold out 25% for the test set.)\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mPKf86yDYf0t",
        "colab": {},
        "outputId": "9212993f-f40b-4c48-e745-047b98a551e0"
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.75, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "E_ATNJdqTCuZ"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 2.1 — Make a pipeline\n",
        "\n",
        "Make a **pipeline** which includes:\n",
        "- Preprocessing with any scikit-learn [**Scaler**](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)\n",
        "- Feature selection with **[`SelectKBest`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)([`f_classif`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html))**\n",
        "- Classification with [**`LogisticRegression`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8DRrVU5n5_Jw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import f_classif, SelectKBest\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "pipe = make_pipeline(\n",
        "    RobustScaler(), \n",
        "    SelectKBest(f_classif), \n",
        "    LogisticRegression(solver='lbfgs', random_state=42))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5vRkQHatglMG"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 2.2 — Do Grid Search Cross-Validation\n",
        "\n",
        "Do [**GridSearchCV**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) with your pipeline. Use **5 folds** and **recall score**.\n",
        "\n",
        "Include these **parameters for your grid:**\n",
        "\n",
        "#### `SelectKBest`\n",
        "- `k : 1, 2, 3, 4`\n",
        "\n",
        "#### `LogisticRegression`\n",
        "- `class_weight : None, 'balanced'`\n",
        "- `C : .0001, .001, .01, .1, 1.0, 10.0, 100.00, 1000.0, 10000.0`\n",
        "\n",
        "\n",
        "**Fit** on the appropriate data."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wgN8kG0ogBMH",
        "colab": {},
        "outputId": "20d18fbd-0c01-446e-fff6-2b74e8697f23"
      },
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'selectkbest__k': [1,2,3,4], \n",
        "    'logisticregression__class_weight' : [None, 'balanced'],\n",
        "    'logisticregression__C' : [.0001, .001, .01, .1, 1.0, 10.0, 100.00, 1000.0, 10000.0]\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "gs = GridSearchCV(pipe, param_grid=param_grid, cv=5, \n",
        "                  scoring='neg_mean_absolute_error')\n",
        "\n",
        "gs.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
              "       estimator=Pipeline(memory=None,\n",
              "     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
              "       with_scaling=True)), ('selectkbest', SelectKBest(k=10, score_func=<function f_classif at 0x1a1a8726a8>)), ('logisticregression', LogisticRegression(C=1.0, cla...penalty='l2', random_state=42, solver='lbfgs',\n",
              "          tol=0.0001, verbose=0, warm_start=False))]),\n",
              "       fit_params=None, iid='warn', n_jobs=None,\n",
              "       param_grid={'selectkbest__k': [1, 2, 3, 4], 'logisticregression__class_weight': [None, 'balanced'], 'logisticregression__C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]},\n",
              "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
              "       scoring='neg_mean_absolute_error', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "urY_Wp3AiF83"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 3 — Show best score and parameters\n",
        "\n",
        "Display your **best cross-validation score**, and the **best parameters** (the values of `k, class_weight, C`) from the grid search.\n",
        "\n",
        "(You're not evaluated here on how good your score is, or which parameters you find. You're only evaluated on being able to display the information. There are several ways you can get the information, and any way is acceptable.)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qAxxkjG7gACP",
        "colab": {},
        "outputId": "6b0fe3b4-eb0d-4ea4-dc7e-376018dda007"
      },
      "cell_type": "code",
      "source": [
        "print('Best params:', gs.best_params_)\n",
        "print('Best score:', gs.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best params: {'logisticregression__C': 1.0, 'logisticregression__class_weight': None, 'selectkbest__k': 4}\n",
            "Best score: -0.2192513368983957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jkyHoRIbEgRR"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 4 — Calculate classification metrics from a confusion matrix\n",
        "\n",
        "Suppose this is the confusion matrix for your binary classification model:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th colspan=\"2\" rowspan=\"2\"></th>\n",
        "    <th colspan=\"2\">Predicted</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <th>Negative</th>\n",
        "    <th>Positive</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <th rowspan=\"2\">Actual</th>\n",
        "    <th>Negative</th>\n",
        "    <td>85</td>\n",
        "    <td>58</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <th>Positive</th>\n",
        "    <td>8</td>\n",
        "    <td>36</td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LhyMM5H-JpVB"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TZPwqdh2KUcB",
        "colab": {},
        "outputId": "d0329c97-d7ba-450b-8891-83e62b4ec5e7"
      },
      "cell_type": "code",
      "source": [
        "true_negative  = 85\n",
        "false_positive = 58\n",
        "false_negative = 8\n",
        "true_positive  = 36\n",
        "\n",
        "accuracy = ((true_negative + true_positive) / \n",
        "            (true_negative + false_positive + false_negative + true_positive))\n",
        "accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6470588235294118"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "BRWLfGcGKeQw"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate precision"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "A-FEZ4i_Kf_n",
        "colab": {},
        "outputId": "c1c50166-6da7-45dd-be72-8db79840f015"
      },
      "cell_type": "code",
      "source": [
        "actual_negative = true_negative + false_positive\n",
        "actual_positive = false_positive + true_positive\n",
        "\n",
        "predicted_negative = true_negative + false_negative\n",
        "predicted_positive = false_positive + true_positive\n",
        "\n",
        "precision = true_positive / predicted_positive\n",
        "precision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3829787234042553"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "h_mH2NYDKi2C"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate recall"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "U4_wJGyjKkXJ",
        "colab": {},
        "outputId": "83c6ca4d-3355-4a31-80e2-f3830ba557ac"
      },
      "cell_type": "code",
      "source": [
        "recall = true_positive / actual_positive\n",
        "recall"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3829787234042553"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "9KEaWsk5Kk9W"
      },
      "cell_type": "markdown",
      "source": [
        "## BONUS — How you can earn a score of 3\n",
        "\n",
        "### Part 1\n",
        "Do feature engineering, to try improving your cross-validation score.\n",
        "\n",
        "### Part 2\n",
        "Add transformations in your pipeline and parameters in your grid, to try improving your cross-validation score.\n",
        "\n",
        "### Part 3\n",
        "Show names of selected features. Then do a final evaluation on the test set — what is the test score?\n",
        "\n",
        "### Part 4\n",
        "Calculate F1 score and False Positive Rate. "
      ]
    },
    {
      "metadata": {
        "id": "kEHIwQsYtRWD",
        "colab_type": "code",
        "colab": {},
        "outputId": "9813c14f-5b3b-4715-bc7f-12cfd29d893f"
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>months_since_last_donation</th>\n",
              "      <th>number_of_donations</th>\n",
              "      <th>total_volume_donated</th>\n",
              "      <th>months_since_first_donation</th>\n",
              "      <th>made_donation_in_march_2007</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>12500</td>\n",
              "      <td>98</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>3250</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>4000</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>5000</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>6000</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   months_since_last_donation  number_of_donations  total_volume_donated  \\\n",
              "0                           2                   50                 12500   \n",
              "1                           0                   13                  3250   \n",
              "2                           1                   16                  4000   \n",
              "3                           2                   20                  5000   \n",
              "4                           1                   24                  6000   \n",
              "\n",
              "   months_since_first_donation  made_donation_in_march_2007  \n",
              "0                           98                            1  \n",
              "1                           28                            1  \n",
              "2                           35                            1  \n",
              "3                           45                            1  \n",
              "4                           77                            0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "fENxWVBptRWG",
        "colab_type": "code",
        "colab": {},
        "outputId": "86903853-71e3-4bbe-c122-1e2d14bd54cf"
      },
      "cell_type": "code",
      "source": [
        "df.var()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "months_since_last_donation     6.553543e+01\n",
              "number_of_donations            3.409751e+01\n",
              "total_volume_donated           2.131094e+06\n",
              "months_since_first_donation    5.942242e+02\n",
              "made_donation_in_march_2007    1.815819e-01\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "metadata": {
        "id": "IxXhdWn8tRWI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Part 1\n",
        "\n",
        "# Lets log-normalize the column with high variance\n",
        "df['total_volume_normed'] = np.log(df['total_volume_donated'])\n",
        "del df['total_volume_donated']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r_R7_ZhytRWK",
        "colab_type": "code",
        "colab": {},
        "outputId": "7735961f-90fc-436c-dc66-6dbc2442ed98"
      },
      "cell_type": "code",
      "source": [
        "# Part 2\n",
        "\n",
        "X = df.drop('made_donation_in_march_2007',axis=1)\n",
        "y = df['made_donation_in_march_2007']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.75, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'selectkbest__k': [1,2,3,4], \n",
        "    'logisticregression__class_weight' : [None, 'balanced'],\n",
        "    'logisticregression__C' : [.0001, .001, .01, .1, 1.0, 10.0, 100.00, 1000.0, 10000.0],\n",
        "    'logisticregression__intercept_scaling' : [0.001, 0.005, 0.01, 1]\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "gs = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
        "\n",
        "gs.fit(X_train, y_train)\n",
        "print('Train score:', gs.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train score: -0.20320855614973263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tkD6kZSTtRWN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Score got closer to 0, but it's mostly due to log transformation of high variance variable from Part 1..."
      ]
    },
    {
      "metadata": {
        "id": "XHgpQMiYtRWN",
        "colab_type": "code",
        "colab": {},
        "outputId": "1bc0aa56-c649-4fa9-dfe5-477c8ba5b3a5"
      },
      "cell_type": "code",
      "source": [
        "# Part 3\n",
        "\n",
        "# Show names of selected features\n",
        "selector = gs.best_estimator_.named_steps['selectkbest']\n",
        "all_names = X_train.columns\n",
        "selected_mask = selector.get_support()\n",
        "selected_names = all_names[selected_mask]\n",
        "unselected_names = all_names[~selected_mask]\n",
        "\n",
        "print('Features selected:')\n",
        "for name in selected_names:\n",
        "    print(name)\n",
        "\n",
        "print()\n",
        "print('Features not selected:')\n",
        "for name in unselected_names:\n",
        "    print(name)\n",
        "    \n",
        "# Final evaluation on the test set (test score)\n",
        "test_score = gs.score(X_test, y_test)\n",
        "print('\\nTest Score:', test_score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features selected:\n",
            "months_since_last_donation\n",
            "number_of_donations\n",
            "months_since_first_donation\n",
            "total_volume_normed\n",
            "\n",
            "Features not selected:\n",
            "\n",
            "Test Score: -0.24064171122994651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wIOql3-LtRWQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "afa20b8d-782d-422c-fcf4-b86112a8390a"
      },
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(561,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "metadata": {
        "id": "NAB7gp6UtRWU",
        "colab_type": "code",
        "colab": {},
        "outputId": "08fc69d1-fbc9-4f24-cb5a-d78e7ba8afb3"
      },
      "cell_type": "code",
      "source": [
        "# Part 4\n",
        "\n",
        "gs = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='f1')\n",
        "\n",
        "gs.score(X_train, y_train)\n",
        "\n",
        "\n",
        "# from sklearn.metrics import roc_auc_score, roc_curve\n",
        "# fpr, tpr, thresholds = roc_curve(y_train, y_pred_)\n",
        "# print('False positive rate:', fpr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-136-806078443bdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \"\"\"\n\u001b[0;32m--> 456\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             raise ValueError(\"No score function explicitly defined, \"\n",
            "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_check_is_fitted\u001b[0;34m(self, method_name)\u001b[0m\n\u001b[1;32m    472\u001b[0m                                  % (type(self).__name__, method_name))\n\u001b[1;32m    473\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'best_estimator_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_estimator_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "KPWQZC2YtRWW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}