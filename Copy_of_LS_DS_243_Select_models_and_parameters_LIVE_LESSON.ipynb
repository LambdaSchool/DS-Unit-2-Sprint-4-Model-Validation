{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LS_DS_243_Select_models_and_parameters LIVE LESSON.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veritaem/DS-Unit-2-Sprint-4-Model-Validation/blob/master/Copy_of_LS_DS_243_Select_models_and_parameters_LIVE_LESSON.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "O67uhlT4MExK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "_Lambda School Data Science — Model Validation_\n",
        "\n",
        "# Select models and parameters\n",
        "\n",
        "Objectives\n",
        "- Hyperparameter optimization\n",
        "- Model selection"
      ]
    },
    {
      "metadata": {
        "id": "VE4rfZd4NUGA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Today we'll use this process:\n",
        "\n",
        "## \"A universal workflow of machine learning\"\n",
        "\n",
        "_Excerpt from Francois Chollet, [Deep Learning with Python](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/README.md), Chapter 4: Fundamentals of machine learning_\n",
        " \n",
        "**1. Define the problem at hand and the data on which you’ll train.** Collect this data, or annotate it with labels if need be.\n",
        "\n",
        "**2. Choose how you’ll measure success on your problem.** Which metrics will you monitor on your validation data?\n",
        "\n",
        "**3. Determine your evaluation protocol:** hold-out validation? K-fold validation? Which portion of the data should you use for validation?\n",
        "\n",
        "**4. Develop a first model that does better than a basic baseline:** a model with statistical power.\n",
        "\n",
        "**5. Develop a model that overfits.** The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\n",
        "\n",
        "**6. Regularize your model and tune its hyperparameters, based on performance on the validation data.** Repeatedly modify your model, train it, evaluate on your validation data (not the test data, at this point), modify it again, and repeat, until the model is as good as it can get. \n",
        "\n",
        "Iterate on feature engineering: add new features, or remove features that don’t seem to be informative. Once you’ve developed a satisfactory model configuration, you can train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.\n"
      ]
    },
    {
      "metadata": {
        "id": "3kt6bzEcOIaa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Define the problem at hand and the data on which you'll train"
      ]
    },
    {
      "metadata": {
        "id": "di16k7vpRg67",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We'll apply the workflow to a [project from _Python Data Science Handbook_](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic) by Jake VanderPlas:\n",
        "\n",
        "> **Predicting Bicycle Traffic**\n",
        "\n",
        "> As an example, let's take a look at whether we can predict the number of bicycle trips across Seattle's Fremont Bridge based on weather, season, and other factors.\n",
        "\n",
        "> We will join the bike data with another dataset, and try to determine the extent to which weather and seasonal factors—temperature, precipitation, and daylight hours—affect the volume of bicycle traffic through this corridor. Fortunately, the NOAA makes available their daily [weather station data](http://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND) (I used station ID USW00024233) and we can easily use Pandas to join the two data sources.\n",
        "\n",
        "> Let's start by loading the two datasets, indexing by date:"
      ]
    },
    {
      "metadata": {
        "id": "19dpb_d0R1A6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So this is a regression problem, not a classification problem. We'll define the target, choose an evaluation metric, and choose models that are appropriate for regression problems.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "os1zruXQ30KM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download data"
      ]
    },
    {
      "metadata": {
        "id": "5XVu-HSeMDtV",
        "colab_type": "code",
        "outputId": "11a5b726-cf8c-42a5-f0d7-777a29781af8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "!curl -o FremontBridge.csv https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1536k    0 1536k    0     0   788k      0 --:--:--  0:00:01 --:--:--  787k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sih_7mTzMdfr",
        "colab_type": "code",
        "outputId": "0859d41b-a0a1-4d60-f89c-db4f9f2d3661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-31 00:03:27--  https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 234945 (229K) [text/plain]\n",
            "Saving to: ‘BicycleWeather.csv.12’\n",
            "\n",
            "\rBicycleWeather.csv.   0%[                    ]       0  --.-KB/s               \rBicycleWeather.csv. 100%[===================>] 229.44K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2019-01-31 00:03:28 (7.73 MB/s) - ‘BicycleWeather.csv.12’ saved [234945/234945]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9GYm74kD34OQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load data"
      ]
    },
    {
      "metadata": {
        "id": "BfQ7gE28MNdF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Modified from cells 15, 16, and 20, at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "counts = pd.read_csv('FremontBridge.csv', index_col='Date', parse_dates=True, \n",
        "                     infer_datetime_format=True)\n",
        "\n",
        "weather = pd.read_csv('BicycleWeather.csv', index_col='DATE', parse_dates=True, \n",
        "                      infer_datetime_format=True)\n",
        "\n",
        "daily = counts.resample('d').sum()\n",
        "daily['Total'] = daily.sum(axis=1)\n",
        "daily = daily[['Total']] # remove other columns\n",
        "\n",
        "weather_columns = ['PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND']\n",
        "daily = daily.join(weather[weather_columns], how='inner')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i0YYD6rvypb4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Make a feature for yesterday's total\n",
        "daily['Total_yesterday'] = daily.Total.shift(1)\n",
        "\n",
        "daily = daily.drop(index=daily.index[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VVB3g4704An5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### First fast look at the data\n",
        "- What's the shape?\n",
        "- What's the date range?\n",
        "- What's the target and the features?"
      ]
    },
    {
      "metadata": {
        "id": "t50E2fTUWBBU",
        "colab_type": "code",
        "outputId": "a90d7e10-90b4-471c-a58d-df3c07ff6aa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "daily.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1063, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "hAHlhrjcx8lR",
        "colab_type": "code",
        "outputId": "c04a5282-81b0-4293-8a5d-fb370c9e2d79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "daily.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-10-04</th>\n",
              "      <td>3475.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>189</td>\n",
              "      <td>83</td>\n",
              "      <td>65</td>\n",
              "      <td>3521.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-05</th>\n",
              "      <td>3148.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>217</td>\n",
              "      <td>89</td>\n",
              "      <td>57</td>\n",
              "      <td>3475.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-06</th>\n",
              "      <td>2006.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>239</td>\n",
              "      <td>78</td>\n",
              "      <td>51</td>\n",
              "      <td>3148.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-07</th>\n",
              "      <td>2142.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>239</td>\n",
              "      <td>78</td>\n",
              "      <td>13</td>\n",
              "      <td>2006.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-08</th>\n",
              "      <td>3537.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211</td>\n",
              "      <td>78</td>\n",
              "      <td>19</td>\n",
              "      <td>2142.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Total  PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
              "2012-10-04  3475.0     0     0     0   189    83    65           3521.0\n",
              "2012-10-05  3148.0     0     0     0   217    89    57           3475.0\n",
              "2012-10-06  2006.0     0     0     0   239    78    51           3148.0\n",
              "2012-10-07  2142.0     0     0     0   239    78    13           2006.0\n",
              "2012-10-08  3537.0     0     0     0   211    78    19           2142.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "BZrbDVDGx-zY",
        "colab_type": "code",
        "outputId": "d9a76e9b-c5e4-485a-81e6-f1ec7573d646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "daily.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-08-28</th>\n",
              "      <td>2653.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>233</td>\n",
              "      <td>156</td>\n",
              "      <td>26</td>\n",
              "      <td>4336.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-29</th>\n",
              "      <td>699.0</td>\n",
              "      <td>325</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>222</td>\n",
              "      <td>133</td>\n",
              "      <td>58</td>\n",
              "      <td>2653.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-30</th>\n",
              "      <td>1213.0</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>200</td>\n",
              "      <td>128</td>\n",
              "      <td>47</td>\n",
              "      <td>699.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-31</th>\n",
              "      <td>2823.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>189</td>\n",
              "      <td>161</td>\n",
              "      <td>58</td>\n",
              "      <td>1213.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-09-01</th>\n",
              "      <td>2876.0</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>194</td>\n",
              "      <td>139</td>\n",
              "      <td>-9999</td>\n",
              "      <td>2823.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Total  PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
              "2015-08-28  2653.0     5     0     0   233   156    26           4336.0\n",
              "2015-08-29   699.0   325     0     0   222   133    58           2653.0\n",
              "2015-08-30  1213.0   102     0     0   200   128    47            699.0\n",
              "2015-08-31  2823.0     0     0     0   189   161    58           1213.0\n",
              "2015-09-01  2876.0    58     0     0   194   139 -9999           2823.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "XgMvCsaWJR7Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Target\n",
        "- Total : Daily total number of bicycle trips across Seattle's Fremont Bridge\n",
        "\n",
        "Features\n",
        "- Date (index) : from 2012-10-04 to 2015-09-01\n",
        "- Total_yesterday : Total trips yesterday\n",
        "- PRCP : Precipitation (1/10 mm)\n",
        "- SNOW : Snowfall (1/10 mm)\n",
        "- SNWD : Snow depth (1/10 mm)\n",
        "- TMAX : Maximum temperature (1/10 Celsius)\n",
        "- TMIN : Minimum temperature (1/10 Celsius)\n",
        "- AWND : Average daily wind speed (1/10 meters per second)"
      ]
    },
    {
      "metadata": {
        "id": "lenL-przSYCo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Choose how you’ll measure success on your problem.\n",
        "\n",
        "Which metrics will you monitor on your validation data?\n",
        "\n",
        "This is a regression problem, so we need to choose a regression [metric](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values).\n",
        "\n",
        "\n",
        "\n",
        "I'll choose mean absolute error.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1TqbomapSyRP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IRHrB3rsS5hF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Determine your evaluation protocol \n",
        "\n",
        "We're doing model selection, hyperparameter optimization, and performance estimation. So generally we have two ideal [options](https://sebastianraschka.com/images/blog/2018/model-evaluation-selection-part4/model-eval-conclusions.jpg) to choose from:\n",
        "\n",
        "- 3-way holdout method (train/validation/test split)\n",
        "- Cross-validation with independent test set\n",
        "\n",
        "I'll choose cross-validation with independent test set. Scikit-learn makes cross-validation convenient for us!\n",
        "\n",
        "Specifically, I will use random shuffled cross validation to train and validate, but I will hold out an \"out-of-time\" test set, from the last 100 days of data:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "_hyIxD6f0zMa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = daily[:-100]\n",
        "test = daily[-100:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mb7Qa43S1TdK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = train.drop(columns='Total')\n",
        "y_train = train.Total\n",
        "\n",
        "X_test  = test.drop(columns='Total')\n",
        "y_test  = test.Total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vH6IsORQTvTU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Develop a first model that does better than a basic baseline"
      ]
    },
    {
      "metadata": {
        "id": "DJBs2nQkj7oB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Look at the target's distribution and descriptive stats"
      ]
    },
    {
      "metadata": {
        "id": "P5peakv9Zs71",
        "colab_type": "code",
        "outputId": "e22bd908-f328-4e4d-bd7e-36ff6a6cf870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.distplot(y_train);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py:6521: MatplotlibDeprecationWarning: \n",
            "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
            "  alternative=\"'density'\", removal=\"3.1\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEGCAYAAACHGfl5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Z_Rh_iO814gi",
        "colab_type": "code",
        "outputId": "dcb5ccb7-d8c4-44fb-f503-10dd4edd0583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "cell_type": "code",
      "source": [
        "y_train.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     963.000000\n",
              "mean     2534.329180\n",
              "std      1224.065027\n",
              "min        98.000000\n",
              "25%      1755.000000\n",
              "50%      2381.000000\n",
              "75%      3317.500000\n",
              "max      6088.000000\n",
              "Name: Total, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "fEjxxgV9kExY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Basic baseline 1"
      ]
    },
    {
      "metadata": {
        "id": "6GepKdQjYcEP",
        "colab_type": "code",
        "outputId": "948f41a8-8816-4d01-92fb-8aded256f0f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_pred = np.full(shape=y_train.shape, fill_value=y_train.mean())\n",
        "mean_absolute_error(y_train, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "980.8981106765484"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "tN2I_F3FkIHb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Basic baseline 2"
      ]
    },
    {
      "metadata": {
        "id": "ZW8bhZFtTunV",
        "colab_type": "code",
        "outputId": "e6cc6dde-3007-4fe1-a8c5-e357ac7a721a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "mean_absolute_error(y_train, X_train.Total_yesterday)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "708.061266874351"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "Ggf3VpxwkJ0T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### First model that does better than a basic baseline"
      ]
    },
    {
      "metadata": {
        "id": "KfaqL1Ezer2-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html"
      ]
    },
    {
      "metadata": {
        "id": "OeBtU68skfW-",
        "colab_type": "code",
        "outputId": "de6d428b-478a-4556-ff14-d8316209ad61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "scores = cross_validate(LinearRegression(), X_train, y_train, \n",
        "                        scoring='neg_mean_absolute_error', cv=3, \n",
        "                        return_train_score=True, return_estimator=True)\n",
        "\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>0.003782</td>\n",
              "      <td>0.001704</td>\n",
              "      <td>-555.186275</td>\n",
              "      <td>-619.509206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>0.002234</td>\n",
              "      <td>0.004599</td>\n",
              "      <td>-651.126513</td>\n",
              "      <td>-583.427702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>0.002621</td>\n",
              "      <td>0.001751</td>\n",
              "      <td>-615.965800</td>\n",
              "      <td>-589.341301</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           estimator  fit_time  score_time  \\\n",
              "0  LinearRegression(copy_X=True, fit_intercept=Tr...  0.003782    0.001704   \n",
              "1  LinearRegression(copy_X=True, fit_intercept=Tr...  0.002234    0.004599   \n",
              "2  LinearRegression(copy_X=True, fit_intercept=Tr...  0.002621    0.001751   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -555.186275  -619.509206  \n",
              "1 -651.126513  -583.427702  \n",
              "2 -615.965800  -589.341301  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "7Mv7LPCm4j1s",
        "colab_type": "code",
        "outputId": "bfa88fb5-f124-4f31-976b-15e0e4fd212a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "scores['test_score'].mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-607.4261958631806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "yjcfVLcK5GvN",
        "colab_type": "code",
        "outputId": "c4324a2e-df4f-4202-9904-1d97e831cab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        }
      },
      "cell_type": "code",
      "source": [
        "for i, model in enumerate(scores['estimator']):\n",
        "    coefficients = model.coef_\n",
        "    intercept = model.intercept_\n",
        "    feature_names = X_train.columns\n",
        "    \n",
        "    print('Model from cross validation fold #' + str(i))\n",
        "    print('Intercept', model.intercept_)\n",
        "    print(pd.Series(coefficients, feature_names).to_string())\n",
        "    print('\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model from cross validation fold #0\n",
            "Intercept 566.7766337283679\n",
            "PRCP               -3.525103\n",
            "SNOW               -0.082029\n",
            "SNWD              -12.045027\n",
            "TMAX                9.475238\n",
            "TMIN               -4.607775\n",
            "AWND               -2.745191\n",
            "Total_yesterday     0.417360\n",
            "\n",
            "\n",
            "Model from cross validation fold #1\n",
            "Intercept 671.9064515706045\n",
            "PRCP               -2.772253\n",
            "SNOW               -0.000995\n",
            "SNWD               20.800688\n",
            "TMAX                8.804948\n",
            "TMIN               -3.741386\n",
            "AWND               -6.108300\n",
            "Total_yesterday     0.405074\n",
            "\n",
            "\n",
            "Model from cross validation fold #2\n",
            "Intercept 465.84525362296563\n",
            "PRCP               -2.876196\n",
            "SNOW               -0.016432\n",
            "SNWD               -8.809696\n",
            "TMAX               10.419441\n",
            "TMIN               -5.862868\n",
            "AWND               -2.398991\n",
            "Total_yesterday     0.423493\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xtR0jNxE6OAG",
        "colab_type": "code",
        "outputId": "97b150f7-397d-4d4b-c9f9-f6c9596fb338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "model = sm.OLS(y_train, sm.add_constant(X_train))\n",
        "print(model.fit().summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  Total   R-squared:                       0.628\n",
            "Model:                            OLS   Adj. R-squared:                  0.625\n",
            "Method:                 Least Squares   F-statistic:                     230.2\n",
            "Date:                Thu, 31 Jan 2019   Prob (F-statistic):          4.80e-200\n",
            "Time:                        00:03:41   Log-Likelihood:                -7736.8\n",
            "No. Observations:                 963   AIC:                         1.549e+04\n",
            "Df Residuals:                     955   BIC:                         1.553e+04\n",
            "Df Model:                           7                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "===================================================================================\n",
            "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
            "-----------------------------------------------------------------------------------\n",
            "const             571.7691     93.165      6.137      0.000     388.937     754.601\n",
            "PRCP               -3.0616      0.396     -7.726      0.000      -3.839      -2.284\n",
            "SNOW               -0.0271      0.038     -0.721      0.471      -0.101       0.047\n",
            "SNWD               -9.1379      8.974     -1.018      0.309     -26.748       8.472\n",
            "TMAX                9.4823      0.774     12.258      0.000       7.964      11.000\n",
            "TMIN               -4.6742      1.026     -4.555      0.000      -6.688      -2.660\n",
            "AWND               -3.7006      1.747     -2.119      0.034      -7.128      -0.273\n",
            "Total_yesterday     0.4165      0.025     16.460      0.000       0.367       0.466\n",
            "==============================================================================\n",
            "Omnibus:                        6.601   Durbin-Watson:                   1.571\n",
            "Prob(Omnibus):                  0.037   Jarque-Bera (JB):                6.648\n",
            "Skew:                          -0.187   Prob(JB):                       0.0360\n",
            "Kurtosis:                       2.841   Cond. No.                     1.09e+04\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 1.09e+04. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
            "  from pandas.core import datetools\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "fg1YI4X8n9nI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Develop a model that overfits. \n",
        "\n",
        "\"The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\" —Chollet"
      ]
    },
    {
      "metadata": {
        "id": "lodd6UPOoy89",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://jakevdp.github.io/PythonDataScienceHandbook/figures/05.03-validation-curve.png\">\n",
        "\n",
        "Diagram source: https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn"
      ]
    },
    {
      "metadata": {
        "id": "FrmQ3RM0w2JE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Polynomial Regression?"
      ]
    },
    {
      "metadata": {
        "id": "uctwo0X3pTw5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Copied from cell 10 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "def PolynomialRegression(degree=2, **kwargs):\n",
        "    return make_pipeline(PolynomialFeatures(degree),\n",
        "                         LinearRegression(**kwargs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wvY4HOXVw7Mj",
        "colab_type": "code",
        "outputId": "9e24b52a-2368-4c58-c458-6d36e389c269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "cell_type": "code",
      "source": [
        "for degree in [0, 1, 2, 3]:\n",
        "    features = PolynomialFeatures(degree).fit(X_train).get_feature_names(X_train.columns)\n",
        "    print(f'{degree} degree polynomial has {len(features)} features')\n",
        "    print(features)\n",
        "    print('\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 degree polynomial has 1 features\n",
            "['1']\n",
            "\n",
            "\n",
            "1 degree polynomial has 8 features\n",
            "['1', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND', 'Total_yesterday']\n",
            "\n",
            "\n",
            "2 degree polynomial has 36 features\n",
            "['1', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND', 'Total_yesterday', 'PRCP^2', 'PRCP SNOW', 'PRCP SNWD', 'PRCP TMAX', 'PRCP TMIN', 'PRCP AWND', 'PRCP Total_yesterday', 'SNOW^2', 'SNOW SNWD', 'SNOW TMAX', 'SNOW TMIN', 'SNOW AWND', 'SNOW Total_yesterday', 'SNWD^2', 'SNWD TMAX', 'SNWD TMIN', 'SNWD AWND', 'SNWD Total_yesterday', 'TMAX^2', 'TMAX TMIN', 'TMAX AWND', 'TMAX Total_yesterday', 'TMIN^2', 'TMIN AWND', 'TMIN Total_yesterday', 'AWND^2', 'AWND Total_yesterday', 'Total_yesterday^2']\n",
            "\n",
            "\n",
            "3 degree polynomial has 120 features\n",
            "['1', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND', 'Total_yesterday', 'PRCP^2', 'PRCP SNOW', 'PRCP SNWD', 'PRCP TMAX', 'PRCP TMIN', 'PRCP AWND', 'PRCP Total_yesterday', 'SNOW^2', 'SNOW SNWD', 'SNOW TMAX', 'SNOW TMIN', 'SNOW AWND', 'SNOW Total_yesterday', 'SNWD^2', 'SNWD TMAX', 'SNWD TMIN', 'SNWD AWND', 'SNWD Total_yesterday', 'TMAX^2', 'TMAX TMIN', 'TMAX AWND', 'TMAX Total_yesterday', 'TMIN^2', 'TMIN AWND', 'TMIN Total_yesterday', 'AWND^2', 'AWND Total_yesterday', 'Total_yesterday^2', 'PRCP^3', 'PRCP^2 SNOW', 'PRCP^2 SNWD', 'PRCP^2 TMAX', 'PRCP^2 TMIN', 'PRCP^2 AWND', 'PRCP^2 Total_yesterday', 'PRCP SNOW^2', 'PRCP SNOW SNWD', 'PRCP SNOW TMAX', 'PRCP SNOW TMIN', 'PRCP SNOW AWND', 'PRCP SNOW Total_yesterday', 'PRCP SNWD^2', 'PRCP SNWD TMAX', 'PRCP SNWD TMIN', 'PRCP SNWD AWND', 'PRCP SNWD Total_yesterday', 'PRCP TMAX^2', 'PRCP TMAX TMIN', 'PRCP TMAX AWND', 'PRCP TMAX Total_yesterday', 'PRCP TMIN^2', 'PRCP TMIN AWND', 'PRCP TMIN Total_yesterday', 'PRCP AWND^2', 'PRCP AWND Total_yesterday', 'PRCP Total_yesterday^2', 'SNOW^3', 'SNOW^2 SNWD', 'SNOW^2 TMAX', 'SNOW^2 TMIN', 'SNOW^2 AWND', 'SNOW^2 Total_yesterday', 'SNOW SNWD^2', 'SNOW SNWD TMAX', 'SNOW SNWD TMIN', 'SNOW SNWD AWND', 'SNOW SNWD Total_yesterday', 'SNOW TMAX^2', 'SNOW TMAX TMIN', 'SNOW TMAX AWND', 'SNOW TMAX Total_yesterday', 'SNOW TMIN^2', 'SNOW TMIN AWND', 'SNOW TMIN Total_yesterday', 'SNOW AWND^2', 'SNOW AWND Total_yesterday', 'SNOW Total_yesterday^2', 'SNWD^3', 'SNWD^2 TMAX', 'SNWD^2 TMIN', 'SNWD^2 AWND', 'SNWD^2 Total_yesterday', 'SNWD TMAX^2', 'SNWD TMAX TMIN', 'SNWD TMAX AWND', 'SNWD TMAX Total_yesterday', 'SNWD TMIN^2', 'SNWD TMIN AWND', 'SNWD TMIN Total_yesterday', 'SNWD AWND^2', 'SNWD AWND Total_yesterday', 'SNWD Total_yesterday^2', 'TMAX^3', 'TMAX^2 TMIN', 'TMAX^2 AWND', 'TMAX^2 Total_yesterday', 'TMAX TMIN^2', 'TMAX TMIN AWND', 'TMAX TMIN Total_yesterday', 'TMAX AWND^2', 'TMAX AWND Total_yesterday', 'TMAX Total_yesterday^2', 'TMIN^3', 'TMIN^2 AWND', 'TMIN^2 Total_yesterday', 'TMIN AWND^2', 'TMIN AWND Total_yesterday', 'TMIN Total_yesterday^2', 'AWND^3', 'AWND^2 Total_yesterday', 'AWND Total_yesterday^2', 'Total_yesterday^3']\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XEUdG9-ktHoa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation curve (with Polynomial Regression)"
      ]
    },
    {
      "metadata": {
        "id": "_ryO1hVKr-6f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html\n",
        "\n",
        "> Validation curve. Determine training and test scores for varying parameter values. This is similar to grid search with one parameter."
      ]
    },
    {
      "metadata": {
        "id": "znJgKqPcqBh-",
        "colab_type": "code",
        "outputId": "798575d8-085d-4008-d5ce-e2e2ed627b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "cell_type": "code",
      "source": [
        "# Modified from cell 13 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import validation_curve\n",
        "\n",
        "degree = [0, 1, 2]\n",
        "train_score, val_score = validation_curve(\n",
        "    PolynomialRegression(), X_train, y_train,\n",
        "    param_name='polynomialfeatures__degree', param_range=degree, \n",
        "    scoring='neg_mean_absolute_error', cv=3)\n",
        "\n",
        "plt.plot(degree, np.median(train_score, 1), color='blue', label='training score')\n",
        "plt.plot(degree, np.median(val_score, 1), color='red', label='validation score')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('degree');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfGBkzSy2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "HUdGHWhvtVnV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Grid Search (with Polynomial Regression)\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/grid_search.html"
      ]
    },
    {
      "metadata": {
        "id": "GziXyq8Is6dL",
        "colab_type": "code",
        "outputId": "315c09fb-2bf7-44b3-c8ae-c2c5d2a29403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'polynomialfeatures__degree': [0, 1, 2, 3]\n",
        "}\n",
        "\n",
        "gridsearch = GridSearchCV(PolynomialRegression(), param_grid=param_grid, \n",
        "                          scoring='neg_mean_absolute_error', cv=3, \n",
        "                          return_train_score=True, verbose=10)\n",
        "\n",
        "gridsearch.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "[CV] polynomialfeatures__degree=0 ....................................\n",
            "[CV]  polynomialfeatures__degree=0, score=-1026.3529857047195, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=0 ....................................\n",
            "[CV]  polynomialfeatures__degree=0, score=-1001.6149251268913, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=0 ....................................\n",
            "[CV]  polynomialfeatures__degree=0, score=-927.0707048650538, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=1 ....................................\n",
            "[CV]  polynomialfeatures__degree=1, score=-555.1862745374103, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=1 ....................................\n",
            "[CV]  polynomialfeatures__degree=1, score=-651.1265132746228, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=1 ....................................\n",
            "[CV]  polynomialfeatures__degree=1, score=-615.9657997775082, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=2 ....................................\n",
            "[CV]  polynomialfeatures__degree=2, score=-7553.67367810515, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=2 ....................................\n",
            "[CV]  polynomialfeatures__degree=2, score=-1439.191570208428, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=2 ....................................\n",
            "[CV]  polynomialfeatures__degree=2, score=-644.1228337571547, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=3 ....................................\n",
            "[CV]  polynomialfeatures__degree=3, score=-2487.2087241103723, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=3 ....................................\n",
            "[CV]  polynomialfeatures__degree=3, score=-97950.22398935535, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=3 ....................................\n",
            "[CV]  polynomialfeatures__degree=3, score=-1835.2490429251202, total=   0.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
              "       estimator=Pipeline(memory=None,\n",
              "     steps=[('polynomialfeatures', PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)), ('linearregression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
              "         normalize=False))]),\n",
              "       fit_params=None, iid='warn', n_jobs=None,\n",
              "       param_grid={'polynomialfeatures__degree': [0, 1, 2, 3]},\n",
              "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "       scoring='neg_mean_absolute_error', verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "sVb-HGgjCop3",
        "colab_type": "code",
        "outputId": "94c57638-165f-46ff-f8dd-480f5b35cf79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "cell_type": "code",
      "source": [
        "pd.DataFrame(gridsearch.cv_results_).sort_values(by='rank_test_score')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>param_polynomialfeatures__degree</th>\n",
              "      <th>params</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.003089</td>\n",
              "      <td>0.001735</td>\n",
              "      <td>-607.426196</td>\n",
              "      <td>-597.426070</td>\n",
              "      <td>1</td>\n",
              "      <td>{'polynomialfeatures__degree': 1}</td>\n",
              "      <td>1</td>\n",
              "      <td>-555.186275</td>\n",
              "      <td>-619.509206</td>\n",
              "      <td>-651.126513</td>\n",
              "      <td>-583.427702</td>\n",
              "      <td>-615.965800</td>\n",
              "      <td>-589.341301</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>39.630174</td>\n",
              "      <td>15.800661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.004543</td>\n",
              "      <td>0.002287</td>\n",
              "      <td>-985.012872</td>\n",
              "      <td>-979.844161</td>\n",
              "      <td>0</td>\n",
              "      <td>{'polynomialfeatures__degree': 0}</td>\n",
              "      <td>2</td>\n",
              "      <td>-1026.352986</td>\n",
              "      <td>-968.880368</td>\n",
              "      <td>-1001.614925</td>\n",
              "      <td>-970.755413</td>\n",
              "      <td>-927.070705</td>\n",
              "      <td>-999.896701</td>\n",
              "      <td>0.000829</td>\n",
              "      <td>0.000218</td>\n",
              "      <td>42.197661</td>\n",
              "      <td>14.199935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.005297</td>\n",
              "      <td>0.003243</td>\n",
              "      <td>-3212.329361</td>\n",
              "      <td>-576.333816</td>\n",
              "      <td>2</td>\n",
              "      <td>{'polynomialfeatures__degree': 2}</td>\n",
              "      <td>3</td>\n",
              "      <td>-7553.673678</td>\n",
              "      <td>-595.089615</td>\n",
              "      <td>-1439.191570</td>\n",
              "      <td>-568.150803</td>\n",
              "      <td>-644.122834</td>\n",
              "      <td>-565.761032</td>\n",
              "      <td>0.000570</td>\n",
              "      <td>0.000766</td>\n",
              "      <td>3086.906373</td>\n",
              "      <td>13.298189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.015846</td>\n",
              "      <td>0.004315</td>\n",
              "      <td>-34090.893919</td>\n",
              "      <td>-601.797899</td>\n",
              "      <td>3</td>\n",
              "      <td>{'polynomialfeatures__degree': 3}</td>\n",
              "      <td>4</td>\n",
              "      <td>-2487.208724</td>\n",
              "      <td>-565.787908</td>\n",
              "      <td>-97950.223989</td>\n",
              "      <td>-663.520180</td>\n",
              "      <td>-1835.249043</td>\n",
              "      <td>-576.085609</td>\n",
              "      <td>0.001057</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>45156.149752</td>\n",
              "      <td>43.846251</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
              "1       0.003089         0.001735      -607.426196       -597.426070   \n",
              "0       0.004543         0.002287      -985.012872       -979.844161   \n",
              "2       0.005297         0.003243     -3212.329361       -576.333816   \n",
              "3       0.015846         0.004315    -34090.893919       -601.797899   \n",
              "\n",
              "  param_polynomialfeatures__degree                             params  \\\n",
              "1                                1  {'polynomialfeatures__degree': 1}   \n",
              "0                                0  {'polynomialfeatures__degree': 0}   \n",
              "2                                2  {'polynomialfeatures__degree': 2}   \n",
              "3                                3  {'polynomialfeatures__degree': 3}   \n",
              "\n",
              "   rank_test_score  split0_test_score  split0_train_score  split1_test_score  \\\n",
              "1                1        -555.186275         -619.509206        -651.126513   \n",
              "0                2       -1026.352986         -968.880368       -1001.614925   \n",
              "2                3       -7553.673678         -595.089615       -1439.191570   \n",
              "3                4       -2487.208724         -565.787908      -97950.223989   \n",
              "\n",
              "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
              "1         -583.427702        -615.965800         -589.341301      0.000123   \n",
              "0         -970.755413        -927.070705         -999.896701      0.000829   \n",
              "2         -568.150803        -644.122834         -565.761032      0.000570   \n",
              "3         -663.520180       -1835.249043         -576.085609      0.001057   \n",
              "\n",
              "   std_score_time  std_test_score  std_train_score  \n",
              "1        0.000008       39.630174        15.800661  \n",
              "0        0.000218       42.197661        14.199935  \n",
              "2        0.000766     3086.906373        13.298189  \n",
              "3        0.000059    45156.149752        43.846251  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "xj82P0VdwYlh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Random Forest?\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
      ]
    },
    {
      "metadata": {
        "id": "_yYXpk99C4cM",
        "colab_type": "code",
        "outputId": "d88f68a5-c1b6-46cd-9bb0-451c864792a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "-"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>0.213903</td>\n",
              "      <td>0.011299</td>\n",
              "      <td>-560.057598</td>\n",
              "      <td>-240.293281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>0.217904</td>\n",
              "      <td>0.010903</td>\n",
              "      <td>-636.727945</td>\n",
              "      <td>-222.115261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>0.215158</td>\n",
              "      <td>0.011134</td>\n",
              "      <td>-645.727179</td>\n",
              "      <td>-219.466947</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           estimator  fit_time  score_time  \\\n",
              "0  (DecisionTreeRegressor(criterion='mse', max_de...  0.213903    0.011299   \n",
              "1  (DecisionTreeRegressor(criterion='mse', max_de...  0.217904    0.010903   \n",
              "2  (DecisionTreeRegressor(criterion='mse', max_de...  0.215158    0.011134   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -560.057598  -240.293281  \n",
              "1 -636.727945  -222.115261  \n",
              "2 -645.727179  -219.466947  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "GWBfKtraEFRH",
        "colab_type": "code",
        "outputId": "5773792c-0d5f-4f49-84b2-73ea9e0e1dad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "scores['test_score'].mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-614.1709071742231"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "vofwgIpSweEb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation Curve (with Random Forest)"
      ]
    },
    {
      "metadata": {
        "id": "apKk4vKiwgtM",
        "colab_type": "code",
        "outputId": "1e174239-13f7-4e50-8e97-2bf1592152d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "cell_type": "code",
      "source": [
        "# Modified from cell 13 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import validation_curve\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100)\n",
        "\n",
        "depth = [2, 3, 4, 5, 6]\n",
        "train_score, val_score = validation_curve(\n",
        "    model, X_train, y_train,\n",
        "    param_name='max_depth', param_range=depth, \n",
        "    scoring='neg_mean_absolute_error', cv=3)\n",
        "\n",
        "plt.plot(depth, np.median(train_score, 1), color='blue', label='training score')\n",
        "plt.plot(depth, np.median(val_score, 1), color='red', label='validation score')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('depth');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEGCAYAAABrQF4qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA5QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "DQoMvZ7-yCAQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Grid Search (with Random Forest)"
      ]
    },
    {
      "metadata": {
        "id": "bk_dX_mByKm7",
        "colab_type": "code",
        "outputId": "a3327994-85ac-42ea-f8e2-dc6d77a0f01e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1156
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200], \n",
        "    'max_depth': [4, 5], \n",
        "    'criterion': ['mse', 'mae']\n",
        "}\n",
        "\n",
        "gridsearch = GridSearchCV(RandomForestRegressor(), param_grid=param_grid, \n",
        "                          scoring='neg_mean_absolute_error', cv=3, \n",
        "                          return_train_score=True, verbose=10)\n",
        "\n",
        "gridsearch.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "[CV] criterion=mse, max_depth=4, n_estimators=100 ....................\n",
            "[CV]  criterion=mse, max_depth=4, n_estimators=100, score=-551.9832487854005, total=   0.1s\n",
            "[CV] criterion=mse, max_depth=4, n_estimators=100 ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mse, max_depth=4, n_estimators=100, score=-646.2774427800027, total=   0.1s\n",
            "[CV] criterion=mse, max_depth=4, n_estimators=100 ....................\n",
            "[CV]  criterion=mse, max_depth=4, n_estimators=100, score=-619.9751621267615, total=   0.1s\n",
            "[CV] criterion=mse, max_depth=4, n_estimators=200 ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mse, max_depth=4, n_estimators=200, score=-553.9005611376716, total=   0.2s\n",
            "[CV] criterion=mse, max_depth=4, n_estimators=200 ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mse, max_depth=4, n_estimators=200, score=-643.1633578439836, total=   0.2s\n",
            "[CV] criterion=mse, max_depth=4, n_estimators=200 ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mse, max_depth=4, n_estimators=200, score=-622.6210554035924, total=   0.2s\n",
            "[CV] criterion=mse, max_depth=5, n_estimators=100 ....................\n",
            "[CV]  criterion=mse, max_depth=5, n_estimators=100, score=-544.3341202296036, total=   0.1s\n",
            "[CV] criterion=mse, max_depth=5, n_estimators=100 ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    1.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    1.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mse, max_depth=5, n_estimators=100, score=-639.4333297156987, total=   0.1s\n",
            "[CV] criterion=mse, max_depth=5, n_estimators=100 ....................\n",
            "[CV]  criterion=mse, max_depth=5, n_estimators=100, score=-629.4001723283556, total=   0.1s\n",
            "[CV] criterion=mse, max_depth=5, n_estimators=200 ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    1.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    1.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mse, max_depth=5, n_estimators=200, score=-544.3619651768528, total=   0.3s\n",
            "[CV] criterion=mse, max_depth=5, n_estimators=200 ....................\n",
            "[CV]  criterion=mse, max_depth=5, n_estimators=200, score=-636.3486315209469, total=   0.3s\n",
            "[CV] criterion=mse, max_depth=5, n_estimators=200 ....................\n",
            "[CV]  criterion=mse, max_depth=5, n_estimators=200, score=-627.1845557147951, total=   0.3s\n",
            "[CV] criterion=mae, max_depth=4, n_estimators=100 ....................\n",
            "[CV]  criterion=mae, max_depth=4, n_estimators=100, score=-545.6285825545172, total=   0.7s\n",
            "[CV] criterion=mae, max_depth=4, n_estimators=100 ....................\n",
            "[CV]  criterion=mae, max_depth=4, n_estimators=100, score=-641.9298442367601, total=   0.7s\n",
            "[CV] criterion=mae, max_depth=4, n_estimators=100 ....................\n",
            "[CV]  criterion=mae, max_depth=4, n_estimators=100, score=-613.8147663551403, total=   0.7s\n",
            "[CV] criterion=mae, max_depth=4, n_estimators=200 ....................\n",
            "[CV]  criterion=mae, max_depth=4, n_estimators=200, score=-545.0613395638629, total=   1.4s\n",
            "[CV] criterion=mae, max_depth=4, n_estimators=200 ....................\n",
            "[CV]  criterion=mae, max_depth=4, n_estimators=200, score=-636.3323676012461, total=   1.3s\n",
            "[CV] criterion=mae, max_depth=4, n_estimators=200 ....................\n",
            "[CV]  criterion=mae, max_depth=4, n_estimators=200, score=-615.1190887850468, total=   1.3s\n",
            "[CV] criterion=mae, max_depth=5, n_estimators=100 ....................\n",
            "[CV]  criterion=mae, max_depth=5, n_estimators=100, score=-540.40507788162, total=   0.8s\n",
            "[CV] criterion=mae, max_depth=5, n_estimators=100 ....................\n",
            "[CV]  criterion=mae, max_depth=5, n_estimators=100, score=-634.4096884735203, total=   0.7s\n",
            "[CV] criterion=mae, max_depth=5, n_estimators=100 ....................\n",
            "[CV]  criterion=mae, max_depth=5, n_estimators=100, score=-613.46746105919, total=   0.8s\n",
            "[CV] criterion=mae, max_depth=5, n_estimators=200 ....................\n",
            "[CV]  criterion=mae, max_depth=5, n_estimators=200, score=-538.9590654205607, total=   1.5s\n",
            "[CV] criterion=mae, max_depth=5, n_estimators=200 ....................\n",
            "[CV]  criterion=mae, max_depth=5, n_estimators=200, score=-632.0917912772586, total=   1.5s\n",
            "[CV] criterion=mae, max_depth=5, n_estimators=200 ....................\n",
            "[CV]  criterion=mae, max_depth=5, n_estimators=200, score=-610.6781074766354, total=   1.5s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   15.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 18.1 s, sys: 42.3 ms, total: 18.2 s\n",
            "Wall time: 18.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p6-hSpq4GL_G",
        "colab_type": "code",
        "outputId": "1168273e-2670-43e1-e547-eaf5cb0386ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(gridsearch.cv_results_)\n",
        "print(f'Best result from grid search of {len(results)} parameter combinations')\n",
        "results.sort_values(by='rank_test_score').head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best result from grid search of 8 parameter combinations\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>params</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.489019</td>\n",
              "      <td>0.01267</td>\n",
              "      <td>-593.909655</td>\n",
              "      <td>-492.030457</td>\n",
              "      <td>mae</td>\n",
              "      <td>5</td>\n",
              "      <td>200</td>\n",
              "      <td>{'criterion': 'mae', 'max_depth': 5, 'n_estima...</td>\n",
              "      <td>1</td>\n",
              "      <td>-538.959065</td>\n",
              "      <td>-514.607181</td>\n",
              "      <td>-632.091791</td>\n",
              "      <td>-477.022457</td>\n",
              "      <td>-610.678107</td>\n",
              "      <td>-484.461733</td>\n",
              "      <td>0.033288</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>39.827226</td>\n",
              "      <td>16.250478</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
              "7       1.489019          0.01267      -593.909655       -492.030457   \n",
              "\n",
              "  param_criterion param_max_depth param_n_estimators  \\\n",
              "7             mae               5                200   \n",
              "\n",
              "                                              params  rank_test_score  \\\n",
              "7  {'criterion': 'mae', 'max_depth': 5, 'n_estima...                1   \n",
              "\n",
              "   split0_test_score  split0_train_score  split1_test_score  \\\n",
              "7        -538.959065         -514.607181        -632.091791   \n",
              "\n",
              "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
              "7         -477.022457        -610.678107         -484.461733      0.033288   \n",
              "\n",
              "   std_score_time  std_test_score  std_train_score  \n",
              "7        0.000089       39.827226        16.250478  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "ZW5HfYtU0GW2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## FEATURE ENGINEERING!"
      ]
    },
    {
      "metadata": {
        "id": "0ms-eoOHFvPG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Jake VanderPlas demonstrates this feature engineering: \n",
        "https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic"
      ]
    },
    {
      "metadata": {
        "id": "sEwME8wR3A5g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Modified from code cells 17-21 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
        "\n",
        "\n",
        "# patterns of use generally vary from day to day; \n",
        "# let's add binary columns that indicate the day of the week:\n",
        "days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "for i, day in enumerate(days):\n",
        "    X_train[day] = (X_train.index.dayofweek == i).astype(float)\n",
        "\n",
        "\n",
        "    \n",
        "# we might expect riders to behave differently on holidays; \n",
        "# let's add an indicator of this as well:\n",
        "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "cal = USFederalHolidayCalendar()\n",
        "holidays = cal.holidays('2012', '2016')\n",
        "X_train = X_train.join(pd.Series(1, index=holidays, name='holiday'))\n",
        "X_train['holiday'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# We also might suspect that the hours of daylight would affect \n",
        "# how many people ride; let's use the standard astronomical calculation \n",
        "# to add this information:\n",
        "def hours_of_daylight(date, axis=23.44, latitude=47.61):\n",
        "    \"\"\"Compute the hours of daylight for the given date\"\"\"\n",
        "    days = (date - pd.datetime(2000, 12, 21)).days\n",
        "    m = (1. - np.tan(np.radians(latitude))\n",
        "         * np.tan(np.radians(axis) * np.cos(days * 2 * np.pi / 365.25)))\n",
        "    return 24. * np.degrees(np.arccos(1 - np.clip(m, 0, 2))) / 180.\n",
        "\n",
        "X_train['daylight_hrs'] = list(map(hours_of_daylight, X_train.index))\n",
        "\n",
        "\n",
        "\n",
        "# temperatures are in 1/10 deg C; convert to C\n",
        "X_train['TMIN'] /= 10\n",
        "X_train['TMAX'] /= 10\n",
        "\n",
        "# We can also calcuate the average temperature.\n",
        "X_train['Temp (C)'] = 0.5 * (X_train['TMIN'] + X_train['TMAX'])\n",
        "\n",
        "\n",
        "\n",
        "# precip is in 1/10 mm; convert to inches\n",
        "X_train['PRCP'] /= 254\n",
        "\n",
        "# In addition to the inches of precipitation, let's add a flag that \n",
        "# indicates whether a day is dry (has zero precipitation):\n",
        "X_train['dry day'] = (X_train['PRCP'] == 0).astype(int)\n",
        "\n",
        "\n",
        "\n",
        "# Let's add a counter that increases from day 1, and measures how many \n",
        "# years have passed. This will let us measure any observed annual increase \n",
        "# or decrease in daily crossings:\n",
        "X_train['annual'] = (X_train.index - X_train.index[0]).days / 365."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dDGkAv813Wtj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Linear Regression (with new features)"
      ]
    },
    {
      "metadata": {
        "id": "cj3HTM6p5F1A",
        "colab_type": "code",
        "outputId": "5716b34b-bb55-4da7-81f4-7d3b2829630f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "scores = cross_validate(LinearRegression(), X_train, y_train, \n",
        "                        scoring='neg_mean_absolute_error', cv=3, \n",
        "                        return_train_score=True, return_estimator=True)\n",
        "\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>0.005094</td>\n",
              "      <td>0.002737</td>\n",
              "      <td>-297.692524</td>\n",
              "      <td>-294.532315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>0.008880</td>\n",
              "      <td>0.002161</td>\n",
              "      <td>-300.419037</td>\n",
              "      <td>-283.779461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>0.007908</td>\n",
              "      <td>0.002076</td>\n",
              "      <td>-322.640378</td>\n",
              "      <td>-283.509114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           estimator  fit_time  score_time  \\\n",
              "0  LinearRegression(copy_X=True, fit_intercept=Tr...  0.005094    0.002737   \n",
              "1  LinearRegression(copy_X=True, fit_intercept=Tr...  0.008880    0.002161   \n",
              "2  LinearRegression(copy_X=True, fit_intercept=Tr...  0.007908    0.002076   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -297.692524  -294.532315  \n",
              "1 -300.419037  -283.779461  \n",
              "2 -322.640378  -283.509114  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "b6zxN2xB3bX_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Random Forest (with new features)"
      ]
    },
    {
      "metadata": {
        "id": "3sWUDZIz1-kk",
        "colab_type": "code",
        "outputId": "a6160517-c5ee-44bc-e725-c322f1ac490e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "%%time \n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100], \n",
        "    'max_depth': [5, 10, 15], \n",
        "    'criterion': ['mae']\n",
        "}\n",
        "\n",
        "# TODO: Instantiate and fit a GridSearchCV and look at best results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
            "Wall time: 9.3 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0QEBUVR13kcb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Ridge Regression (with new features)\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
      ]
    },
    {
      "metadata": {
        "id": "4voLbIxU8r6r",
        "colab_type": "code",
        "outputId": "76f98b10-fb8a-4a41-9ea1-1dd2fd627ca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "param_grid = {\n",
        "    'alpha': [0.1, 1.0, 10.]\n",
        "}\n",
        "\n",
        "\n",
        "gridsearch = GridSearchCV(Ridge(), param_grid=param_grid, \n",
        "                          scoring='neg_mean_absolute_error', cv=3, \n",
        "                          return_train_score=True)\n",
        "\n",
        "gridsearch.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
              "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
              "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
              "       fit_params=None, iid='warn', n_jobs=None,\n",
              "       param_grid={'alpha': [0.1, 1.0, 10.0]}, pre_dispatch='2*n_jobs',\n",
              "       refit=True, return_train_score=True,\n",
              "       scoring='neg_mean_absolute_error', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "sTc3aGx6JYVF",
        "colab_type": "code",
        "outputId": "07b5760b-14b0-4bdb-ce39-dd9532eb7d15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "# TODO: Look at best results\n",
        "results = pd.DataFrame(gridsearch.cv_results_)\n",
        "print(f'Best result from grid search of {len(results)} parameter combinations')\n",
        "results.sort_values(by='rank_test_score').head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best result from grid search of 3 parameter combinations\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>param_alpha</th>\n",
              "      <th>params</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.002562</td>\n",
              "      <td>0.001883</td>\n",
              "      <td>-306.481001</td>\n",
              "      <td>-287.183852</td>\n",
              "      <td>1</td>\n",
              "      <td>{'alpha': 1.0}</td>\n",
              "      <td>1</td>\n",
              "      <td>-295.097222</td>\n",
              "      <td>-294.519125</td>\n",
              "      <td>-301.453949</td>\n",
              "      <td>-283.740595</td>\n",
              "      <td>-322.891834</td>\n",
              "      <td>-283.291836</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>11.890853</td>\n",
              "      <td>5.190056</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
              "1       0.002562         0.001883      -306.481001       -287.183852   \n",
              "\n",
              "  param_alpha          params  rank_test_score  split0_test_score  \\\n",
              "1           1  {'alpha': 1.0}                1        -295.097222   \n",
              "\n",
              "   split0_train_score  split1_test_score  split1_train_score  \\\n",
              "1         -294.519125        -301.453949         -283.740595   \n",
              "\n",
              "   split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
              "1        -322.891834         -283.291836      0.000069        0.000014   \n",
              "\n",
              "   std_test_score  std_train_score  \n",
              "1       11.890853         5.190056  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "31Ufir2XJEWp",
        "colab_type": "code",
        "outputId": "682f4fc5-1dda-45cf-dbe2-7bd902b5adf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "cell_type": "code",
      "source": [
        "model = gridsearch.best_estimator_\n",
        "\n",
        "coefficients = model.coef_\n",
        "intercept = model.intercept_\n",
        "feature_names = X_train.columns\n",
        "\n",
        "print('Best model from grid search cross validation')\n",
        "print('Intercept', intercept)\n",
        "print(pd.Series(coefficients, feature_names).to_string())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best model from grid search cross validation\n",
            "Intercept 33.741779570641484\n",
            "PRCP               -553.070741\n",
            "SNOW                 -0.002829\n",
            "SNWD                 -1.877519\n",
            "TMAX                 63.833062\n",
            "TMIN                -37.450291\n",
            "AWND                 -1.900084\n",
            "Total_yesterday       0.296029\n",
            "Mon                 779.221395\n",
            "Tue                 432.700039\n",
            "Wed                 368.367626\n",
            "Thu                 274.054021\n",
            "Fri                  47.251356\n",
            "Sat               -1099.692199\n",
            "Sun                -801.902237\n",
            "holiday            -939.301546\n",
            "daylight_hrs         70.256463\n",
            "Temp (C)             13.191386\n",
            "dry day             298.475434\n",
            "annual               44.518889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dofdwyTf3pm0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Compare to statsmodels"
      ]
    },
    {
      "metadata": {
        "id": "i-Qt4mDk_yBY",
        "colab_type": "code",
        "outputId": "d7838d7e-5bf2-4082-8c0c-fc45cb4f11b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 844
        }
      },
      "cell_type": "code",
      "source": [
        "# TODO: Same as before\n",
        "model = sm.OLS(y_train, sm.add_constant(X_train))\n",
        "print(model.fit().summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  Total   R-squared:                       0.902\n",
            "Model:                            OLS   Adj. R-squared:                  0.901\n",
            "Method:                 Least Squares   F-statistic:                     513.8\n",
            "Date:                Thu, 31 Jan 2019   Prob (F-statistic):               0.00\n",
            "Time:                        00:04:04   Log-Likelihood:                -7092.6\n",
            "No. Observations:                 963   AIC:                         1.422e+04\n",
            "Df Residuals:                     945   BIC:                         1.431e+04\n",
            "Df Model:                          17                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "===================================================================================\n",
            "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
            "-----------------------------------------------------------------------------------\n",
            "const              33.0481     66.293      0.499      0.618     -97.051     163.147\n",
            "PRCP             -562.6226     56.568     -9.946      0.000    -673.636    -451.609\n",
            "SNOW               -0.0025      0.020     -0.129      0.897      -0.041       0.036\n",
            "SNWD               -1.8308      4.642     -0.394      0.693     -10.941       7.279\n",
            "TMAX               63.6645      4.785     13.306      0.000      54.275      73.054\n",
            "TMIN              -37.1413      5.413     -6.862      0.000     -47.763     -26.519\n",
            "AWND               -1.8502      0.910     -2.033      0.042      -3.637      -0.064\n",
            "Total_yesterday     0.2934      0.022     13.630      0.000       0.251       0.336\n",
            "Mon               790.2012     41.051     19.249      0.000     709.640     870.763\n",
            "Tue               441.4649     32.982     13.385      0.000     376.739     506.191\n",
            "Wed               376.8835     33.935     11.106      0.000     310.287     443.480\n",
            "Thu               282.8744     33.665      8.403      0.000     216.808     348.941\n",
            "Fri                52.4558     32.802      1.599      0.110     -11.918     116.829\n",
            "Sat             -1103.8595     32.242    -34.237      0.000   -1167.133   -1040.586\n",
            "Sun              -806.9722     40.114    -20.117      0.000    -885.695    -728.250\n",
            "holiday          -983.4044     78.191    -12.577      0.000   -1136.853    -829.955\n",
            "daylight_hrs       70.3750      8.400      8.378      0.000      53.890      86.860\n",
            "Temp (C)           13.2616      1.252     10.591      0.000      10.804      15.719\n",
            "dry day           301.0276     33.915      8.876      0.000     234.471     367.584\n",
            "annual             44.6618     16.620      2.687      0.007      12.045      77.279\n",
            "==============================================================================\n",
            "Omnibus:                       35.650   Durbin-Watson:                   1.665\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               78.276\n",
            "Skew:                           0.188   Prob(JB):                     1.01e-17\n",
            "Kurtosis:                       4.345   Cond. No.                     2.64e+19\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 1.09e-29. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "edpJ87A8A8sd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Feature engineering, explained by Francois Chollet\n",
        "\n",
        "> _Feature engineering_ is the process of using your own knowledge about the data and about the machine learning algorithm at hand to make the algorithm work better by applying hardcoded (nonlearned) transformations to the data before it goes into the model. In many cases, it isn’t reasonable to expect a machine-learning model to be able to learn from completely arbitrary data. The data needs to be presented to the model in a way that will make the model’s job easier.\n",
        "\n",
        "> Let’s look at an intuitive example. Suppose you’re trying to develop a model that can take as input an image of a clock and can output the time of day.\n",
        "\n",
        "> If you choose to use the raw pixels of the image as input data, then you have a difficult machine-learning problem on your hands. You’ll need a convolutional neural network to solve it, and you’ll have to expend quite a bit of computational resources to train the network.\n",
        "\n",
        "> But if you already understand the problem at a high level (you understand how humans read time on a clock face), then you can come up with much better input features for a machine-learning algorithm: for instance, write a Python script to follow the black pixels of the clock hands and output the (x, y) coordinates of the tip of each hand. Then a simple machine-learning algorithm can learn to associate these coordinates with the appropriate time of day.\n",
        "\n",
        "> You can go even further: do a coordinate change, and express the (x, y) coordinates as polar coordinates with regard to the center of the image. Your input will become the angle theta of each clock hand. At this point, your features are making the problem so easy that no machine learning is required; a simple rounding operation and dictionary lookup are enough to recover the approximate time of day.\n",
        "\n",
        "> That’s the essence of feature engineering: making a problem easier by expressing it in a simpler way. It usually requires understanding the problem in depth.\n",
        "\n",
        "> Before convolutional neural networks became successful on the MNIST digit-classification problem, solutions were typically based on hardcoded features such as the number of loops in a digit image, the height of each digit in an image, a histogram of pixel values, and so on.\n",
        "\n",
        "> Neural networks are capable of automatically extracting useful features from raw data. Does this mean you don’t have to worry about feature engineering as long as you’re using deep neural networks? No, for two reasons:\n",
        "\n",
        "> - Good features still allow you to solve problems more elegantly while using fewer resources. For instance, it would be ridiculous to solve the problem of reading a clock face using a convolutional neural network.\n",
        "> - Good features let you solve a problem with far less data. The ability of deep-learning models to learn features on their own relies on having lots of training data available; if you have only a few samples, then the information value in their features becomes critical.\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "JIH1DE1sgseY"
      },
      "cell_type": "markdown",
      "source": [
        "Target\n",
        "- Total : Daily total number of bicycle trips across Seattle's Fremont Bridge\n",
        "\n",
        "Features\n",
        "- Date (index) : from 2012-10-04 to 2015-09-01\n",
        "- Total_yesterday : Total trips yesterday\n",
        "- PRCP : Precipitation (1/10 mm)\n",
        "- SNOW : Snowfall (1/10 mm)\n",
        "- SNWD : Snow depth (1/10 mm)\n",
        "- TMAX : Maximum temperature (1/10 Celsius)\n",
        "- TMIN : Minimum temperature (1/10 Celsius)\n",
        "- AWND : Average daily wind speed (1/10 meters per second)"
      ]
    },
    {
      "metadata": {
        "id": "75BjhlaIjTyz",
        "colab_type": "code",
        "outputId": "67546cb0-0dcf-438e-f8aa-64a5b6b61681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "cell_type": "code",
      "source": [
        "pd.set_option('display.height', 1000)\n",
        "pd.set_option('display.max_rows', 1500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "X_train.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>holiday</th>\n",
              "      <th>daylight_hrs</th>\n",
              "      <th>Temp (C)</th>\n",
              "      <th>dry day</th>\n",
              "      <th>annual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.123576</td>\n",
              "      <td>-41.390447</td>\n",
              "      <td>0.109034</td>\n",
              "      <td>15.673209</td>\n",
              "      <td>7.830737</td>\n",
              "      <td>31.888889</td>\n",
              "      <td>2536.141225</td>\n",
              "      <td>0.142264</td>\n",
              "      <td>0.142264</td>\n",
              "      <td>0.142264</td>\n",
              "      <td>0.143302</td>\n",
              "      <td>0.143302</td>\n",
              "      <td>0.143302</td>\n",
              "      <td>0.143302</td>\n",
              "      <td>0.028037</td>\n",
              "      <td>11.677381</td>\n",
              "      <td>11.751973</td>\n",
              "      <td>0.554517</td>\n",
              "      <td>1.317808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.264611</td>\n",
              "      <td>643.435674</td>\n",
              "      <td>2.700110</td>\n",
              "      <td>6.994807</td>\n",
              "      <td>4.914016</td>\n",
              "      <td>14.643764</td>\n",
              "      <td>1224.232861</td>\n",
              "      <td>0.349502</td>\n",
              "      <td>0.349502</td>\n",
              "      <td>0.349502</td>\n",
              "      <td>0.350563</td>\n",
              "      <td>0.350563</td>\n",
              "      <td>0.350563</td>\n",
              "      <td>0.350563</td>\n",
              "      <td>0.165165</td>\n",
              "      <td>2.568741</td>\n",
              "      <td>5.756242</td>\n",
              "      <td>0.497277</td>\n",
              "      <td>0.762023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-9999.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.600000</td>\n",
              "      <td>-7.100000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.218894</td>\n",
              "      <td>-3.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.600000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1755.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.206870</td>\n",
              "      <td>7.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.658904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.400000</td>\n",
              "      <td>7.800000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>2381.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.364878</td>\n",
              "      <td>10.850000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.317808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.129921</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.600000</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>3325.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.118901</td>\n",
              "      <td>16.375000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.976712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.200787</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>35.600000</td>\n",
              "      <td>18.300000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>6088.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.781095</td>\n",
              "      <td>26.700000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.635616</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             PRCP         SNOW        SNWD        TMAX        TMIN        AWND  Total_yesterday         Mon         Tue         Wed         Thu         Fri         Sat         Sun     holiday  daylight_hrs    Temp (C)     dry day      annual\n",
              "count  963.000000   963.000000  963.000000  963.000000  963.000000  963.000000       963.000000  963.000000  963.000000  963.000000  963.000000  963.000000  963.000000  963.000000  963.000000    963.000000  963.000000  963.000000  963.000000\n",
              "mean     0.123576   -41.390447    0.109034   15.673209    7.830737   31.888889      2536.141225    0.142264    0.142264    0.142264    0.143302    0.143302    0.143302    0.143302    0.028037     11.677381   11.751973    0.554517    1.317808\n",
              "std      0.264611   643.435674    2.700110    6.994807    4.914016   14.643764      1224.232861    0.349502    0.349502    0.349502    0.350563    0.350563    0.350563    0.350563    0.165165      2.568741    5.756242    0.497277    0.762023\n",
              "min      0.000000 -9999.000000    0.000000   -1.600000   -7.100000    4.000000        98.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000      8.218894   -3.800000    0.000000    0.000000\n",
              "25%      0.000000     0.000000    0.000000   10.600000    4.400000   22.000000      1755.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000      9.206870    7.750000    0.000000    0.658904\n",
              "50%      0.000000     0.000000    0.000000   14.400000    7.800000   29.000000      2381.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000     11.364878   10.850000    1.000000    1.317808\n",
              "75%      0.129921     0.000000    0.000000   20.600000   11.700000   41.000000      3325.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000     14.118901   16.375000    1.000000    1.976712\n",
              "max      2.200787    74.000000   80.000000   35.600000   18.300000   95.000000      6088.000000    1.000000    1.000000    1.000000    1.000000    1.000000    1.000000    1.000000    1.000000     15.781095   26.700000    1.000000    2.635616"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "LfVkmjGpkRp8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train.replace(-9999, 0, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jiwc_3l79J52",
        "colab_type": "code",
        "outputId": "3e749b5c-545d-413d-80c4-f421c6318fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>holiday</th>\n",
              "      <th>daylight_hrs</th>\n",
              "      <th>Temp (C)</th>\n",
              "      <th>dry day</th>\n",
              "      <th>annual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.123576</td>\n",
              "      <td>0.142264</td>\n",
              "      <td>0.109034</td>\n",
              "      <td>15.673209</td>\n",
              "      <td>7.830737</td>\n",
              "      <td>31.888889</td>\n",
              "      <td>2536.141225</td>\n",
              "      <td>0.142264</td>\n",
              "      <td>0.142264</td>\n",
              "      <td>0.142264</td>\n",
              "      <td>0.143302</td>\n",
              "      <td>0.143302</td>\n",
              "      <td>0.143302</td>\n",
              "      <td>0.143302</td>\n",
              "      <td>0.028037</td>\n",
              "      <td>11.677381</td>\n",
              "      <td>11.751973</td>\n",
              "      <td>0.554517</td>\n",
              "      <td>1.317808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.264611</td>\n",
              "      <td>2.671461</td>\n",
              "      <td>2.700110</td>\n",
              "      <td>6.994807</td>\n",
              "      <td>4.914016</td>\n",
              "      <td>14.643764</td>\n",
              "      <td>1224.232861</td>\n",
              "      <td>0.349502</td>\n",
              "      <td>0.349502</td>\n",
              "      <td>0.349502</td>\n",
              "      <td>0.350563</td>\n",
              "      <td>0.350563</td>\n",
              "      <td>0.350563</td>\n",
              "      <td>0.350563</td>\n",
              "      <td>0.165165</td>\n",
              "      <td>2.568741</td>\n",
              "      <td>5.756242</td>\n",
              "      <td>0.497277</td>\n",
              "      <td>0.762023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.600000</td>\n",
              "      <td>-7.100000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.218894</td>\n",
              "      <td>-3.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.600000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1755.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.206870</td>\n",
              "      <td>7.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.658904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.400000</td>\n",
              "      <td>7.800000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>2381.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.364878</td>\n",
              "      <td>10.850000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.317808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.129921</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.600000</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>3325.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.118901</td>\n",
              "      <td>16.375000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.976712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.200787</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>35.600000</td>\n",
              "      <td>18.300000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>6088.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.781095</td>\n",
              "      <td>26.700000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.635616</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             PRCP        SNOW        SNWD        TMAX        TMIN        AWND  Total_yesterday         Mon         Tue         Wed         Thu         Fri         Sat         Sun     holiday  daylight_hrs    Temp (C)     dry day      annual\n",
              "count  963.000000  963.000000  963.000000  963.000000  963.000000  963.000000       963.000000  963.000000  963.000000  963.000000  963.000000  963.000000  963.000000  963.000000  963.000000    963.000000  963.000000  963.000000  963.000000\n",
              "mean     0.123576    0.142264    0.109034   15.673209    7.830737   31.888889      2536.141225    0.142264    0.142264    0.142264    0.143302    0.143302    0.143302    0.143302    0.028037     11.677381   11.751973    0.554517    1.317808\n",
              "std      0.264611    2.671461    2.700110    6.994807    4.914016   14.643764      1224.232861    0.349502    0.349502    0.349502    0.350563    0.350563    0.350563    0.350563    0.165165      2.568741    5.756242    0.497277    0.762023\n",
              "min      0.000000    0.000000    0.000000   -1.600000   -7.100000    4.000000        98.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000      8.218894   -3.800000    0.000000    0.000000\n",
              "25%      0.000000    0.000000    0.000000   10.600000    4.400000   22.000000      1755.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000      9.206870    7.750000    0.000000    0.658904\n",
              "50%      0.000000    0.000000    0.000000   14.400000    7.800000   29.000000      2381.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000     11.364878   10.850000    1.000000    1.317808\n",
              "75%      0.129921    0.000000    0.000000   20.600000   11.700000   41.000000      3325.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000     14.118901   16.375000    1.000000    1.976712\n",
              "max      2.200787   74.000000   80.000000   35.600000   18.300000   95.000000      6088.000000    1.000000    1.000000    1.000000    1.000000    1.000000    1.000000    1.000000    1.000000     15.781095   26.700000    1.000000    2.635616"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "vbaKa1RIgiZM",
        "colab_type": "code",
        "outputId": "8f8cc997-87c9-4ae0-e984-ea7bdefb4b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>holiday</th>\n",
              "      <th>daylight_hrs</th>\n",
              "      <th>Temp (C)</th>\n",
              "      <th>dry day</th>\n",
              "      <th>annual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-10-04</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18.9</td>\n",
              "      <td>8.3</td>\n",
              "      <td>65</td>\n",
              "      <td>3521.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.219142</td>\n",
              "      <td>13.60</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-05</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21.7</td>\n",
              "      <td>8.9</td>\n",
              "      <td>57</td>\n",
              "      <td>3475.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.161038</td>\n",
              "      <td>15.30</td>\n",
              "      <td>1</td>\n",
              "      <td>0.002740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-06</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>7.8</td>\n",
              "      <td>51</td>\n",
              "      <td>3148.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.103056</td>\n",
              "      <td>15.85</td>\n",
              "      <td>1</td>\n",
              "      <td>0.005479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-07</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>7.8</td>\n",
              "      <td>13</td>\n",
              "      <td>2006.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.045208</td>\n",
              "      <td>15.85</td>\n",
              "      <td>1</td>\n",
              "      <td>0.008219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-08</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21.1</td>\n",
              "      <td>7.8</td>\n",
              "      <td>19</td>\n",
              "      <td>2142.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.987503</td>\n",
              "      <td>14.45</td>\n",
              "      <td>1</td>\n",
              "      <td>0.010959</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday  Mon  Tue  Wed  Thu  Fri  Sat  Sun  holiday  daylight_hrs  Temp (C)  dry day    annual\n",
              "2012-10-04   0.0     0     0  18.9   8.3    65           3521.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0      0.0     11.219142     13.60        1  0.000000\n",
              "2012-10-05   0.0     0     0  21.7   8.9    57           3475.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0      0.0     11.161038     15.30        1  0.002740\n",
              "2012-10-06   0.0     0     0  23.9   7.8    51           3148.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0      0.0     11.103056     15.85        1  0.005479\n",
              "2012-10-07   0.0     0     0  23.9   7.8    13           2006.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0      0.0     11.045208     15.85        1  0.008219\n",
              "2012-10-08   0.0     0     0  21.1   7.8    19           2142.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0      1.0     10.987503     14.45        1  0.010959"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "H3QS_87JhGO8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#to add in yesterdays presip along with a straight flag for whether it precipiatered or not yesterday\n",
        "X_train['PRCP_yest'] = X_train.PRCP.shift(1)\n",
        "X_train['PRCP_yest_flag'] = (X_train['PRCP_yest'] + X_train['SNOW'] + X_train['SNWD']==0).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IPugYU5unfNz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train['Windchill'] = (((X_train['Temp (C)'] * (9/5) + 32) * .6215) + 34.74) - (35.75 * (X_train['AWND']** .16)) + (.4275 * (X_train['Temp (C)'])) * (X_train['AWND'] ** .16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bB0U6QshsV8X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train.Windchill = X_train.Windchill.round(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DGqb2-sQ-bkt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train['Rl_Cold'] = (((X_train['Temp (C)'] * (9/5) + 32) - X_train['Windchill']) -32) * (5/9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4HsVA_eStv05",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "for i, month in enumerate(months):\n",
        "  X_train[month] = (X_train.index.month == i).astype(float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V6sb6lcj-u-W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train['TMIN_ln'] = X_train['TMIN'] **2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-DoZfBpbsJE7",
        "colab_type": "code",
        "outputId": "8c071884-706c-4370-afa7-09cbd8272554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "X_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(963, 36)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>holiday</th>\n",
              "      <th>daylight_hrs</th>\n",
              "      <th>Temp (C)</th>\n",
              "      <th>dry day</th>\n",
              "      <th>annual</th>\n",
              "      <th>PRCP_yest</th>\n",
              "      <th>PRCP_yest_flag</th>\n",
              "      <th>Windchill</th>\n",
              "      <th>Rl_Cold</th>\n",
              "      <th>Jan</th>\n",
              "      <th>Feb</th>\n",
              "      <th>Mar</th>\n",
              "      <th>Apr</th>\n",
              "      <th>May</th>\n",
              "      <th>Jun</th>\n",
              "      <th>Jul</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Nov</th>\n",
              "      <th>Dec</th>\n",
              "      <th>TMIN_ln</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-10-04</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18.9</td>\n",
              "      <td>8.3</td>\n",
              "      <td>65</td>\n",
              "      <td>3521.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.219142</td>\n",
              "      <td>13.60</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>11.46</td>\n",
              "      <td>7.233333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>68.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-05</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21.7</td>\n",
              "      <td>8.9</td>\n",
              "      <td>57</td>\n",
              "      <td>3475.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.161038</td>\n",
              "      <td>15.30</td>\n",
              "      <td>1</td>\n",
              "      <td>0.002740</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>15.97</td>\n",
              "      <td>6.427778</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-06</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>7.8</td>\n",
              "      <td>51</td>\n",
              "      <td>3148.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.103056</td>\n",
              "      <td>15.85</td>\n",
              "      <td>1</td>\n",
              "      <td>0.005479</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>18.01</td>\n",
              "      <td>5.844444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-07</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>7.8</td>\n",
              "      <td>13</td>\n",
              "      <td>2006.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.045208</td>\n",
              "      <td>15.85</td>\n",
              "      <td>1</td>\n",
              "      <td>0.008219</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>28.68</td>\n",
              "      <td>-0.083333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-08</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21.1</td>\n",
              "      <td>7.8</td>\n",
              "      <td>19</td>\n",
              "      <td>2142.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.987503</td>\n",
              "      <td>14.45</td>\n",
              "      <td>1</td>\n",
              "      <td>0.010959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>23.42</td>\n",
              "      <td>1.438889</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.84</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday  Mon  Tue  Wed  Thu  Fri  Sat  Sun  holiday  daylight_hrs  Temp (C)  dry day    annual  PRCP_yest  PRCP_yest_flag  Windchill   Rl_Cold  Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec  TMIN_ln\n",
              "2012-10-04   0.0     0     0  18.9   8.3    65           3521.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0      0.0     11.219142     13.60        1  0.000000        NaN               0      11.46  7.233333  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0    68.89\n",
              "2012-10-05   0.0     0     0  21.7   8.9    57           3475.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0      0.0     11.161038     15.30        1  0.002740        0.0               1      15.97  6.427778  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0    79.21\n",
              "2012-10-06   0.0     0     0  23.9   7.8    51           3148.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0      0.0     11.103056     15.85        1  0.005479        0.0               1      18.01  5.844444  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0    60.84\n",
              "2012-10-07   0.0     0     0  23.9   7.8    13           2006.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0      0.0     11.045208     15.85        1  0.008219        0.0               1      28.68 -0.083333  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0    60.84\n",
              "2012-10-08   0.0     0     0  21.1   7.8    19           2142.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0      1.0     10.987503     14.45        1  0.010959        0.0               1      23.42  1.438889  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0    60.84"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "tDfGVvb3szOa",
        "colab_type": "code",
        "outputId": "f0bd25b5-ee50-48f4-a692-893d5564175d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "cell_type": "code",
      "source": [
        "y_train.rolling(100).mean().plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8c6eb55fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEECAYAAADAoTRlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkYIk+AshRAqS4C+EEClIgr8QQqSg/x9T/IAyv4MxKgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "6wjh_gLM3obm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.drop(index=daily.index[0])\n",
        "y_train = y_train.drop(index=daily.index[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yVuBeFdVmtaD",
        "colab_type": "code",
        "outputId": "2b05955d-0432-419f-f76b-51303ab152cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "scores = cross_validate(LinearRegression(), X_train, y_train, \n",
        "                        scoring='neg_mean_absolute_error', cv=3, \n",
        "                        return_train_score=True, return_estimator=True)\n",
        "\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>0.016336</td>\n",
              "      <td>0.002319</td>\n",
              "      <td>-306.069398</td>\n",
              "      <td>-275.188952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>0.009459</td>\n",
              "      <td>0.004164</td>\n",
              "      <td>-288.766133</td>\n",
              "      <td>-268.642530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>0.010253</td>\n",
              "      <td>0.002235</td>\n",
              "      <td>-316.481434</td>\n",
              "      <td>-261.168922</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           estimator  fit_time  score_time  test_score  train_score\n",
              "0  LinearRegression(copy_X=True, fit_intercept=Tr...  0.016336    0.002319 -306.069398  -275.188952\n",
              "1  LinearRegression(copy_X=True, fit_intercept=Tr...  0.009459    0.004164 -288.766133  -268.642530\n",
              "2  LinearRegression(copy_X=True, fit_intercept=Tr...  0.010253    0.002235 -316.481434  -261.168922"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "TUTchAdn54Od",
        "colab_type": "code",
        "outputId": "03328cc7-ba01-4f79-c22c-f60bf6333dcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1156
        }
      },
      "cell_type": "code",
      "source": [
        "model = sm.OLS(y_train, sm.add_constant(X_train))\n",
        "print(model.fit().summary())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  Total   R-squared:                       0.914\n",
            "Model:                            OLS   Adj. R-squared:                  0.911\n",
            "Method:                 Least Squares   F-statistic:                     310.3\n",
            "Date:                Thu, 31 Jan 2019   Prob (F-statistic):               0.00\n",
            "Time:                        00:04:05   Log-Likelihood:                -7021.9\n",
            "No. Observations:                 962   AIC:                         1.411e+04\n",
            "Df Residuals:                     929   BIC:                         1.427e+04\n",
            "Df Model:                          32                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "===================================================================================\n",
            "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
            "-----------------------------------------------------------------------------------\n",
            "const              67.3989    233.826      0.288      0.773    -391.489     526.287\n",
            "PRCP             -587.5579     54.316    -10.817      0.000    -694.155    -480.961\n",
            "SNOW                3.8354      4.502      0.852      0.395      -5.000      12.671\n",
            "SNWD               -1.2054      4.417     -0.273      0.785      -9.873       7.462\n",
            "TMAX               70.3430      6.258     11.241      0.000      58.062      82.624\n",
            "TMIN              -14.8907      8.560     -1.740      0.082     -31.690       1.909\n",
            "AWND               -8.8094      3.138     -2.807      0.005     -14.968      -2.651\n",
            "Total_yesterday     0.2942      0.025     11.813      0.000       0.245       0.343\n",
            "Mon               800.0225     52.033     15.375      0.000     697.907     902.138\n",
            "Tue               451.5822     45.105     10.012      0.000     363.064     540.101\n",
            "Wed               380.4513     46.267      8.223      0.000     289.650     471.252\n",
            "Thu               286.3119     46.369      6.175      0.000     195.312     377.311\n",
            "Fri                52.6656     45.273      1.163      0.245     -36.184     141.515\n",
            "Sat             -1100.5539     44.675    -24.635      0.000   -1188.229   -1012.879\n",
            "Sun              -803.0805     51.972    -15.452      0.000    -905.076    -701.085\n",
            "holiday         -1009.0232     74.668    -13.513      0.000   -1155.561    -862.485\n",
            "daylight_hrs       48.8053     31.728      1.538      0.124     -13.463     111.073\n",
            "Temp (C)           27.7261      4.719      5.875      0.000      18.465      36.988\n",
            "dry day           338.1447     32.906     10.276      0.000     273.566     402.723\n",
            "annual             39.4346     16.337      2.414      0.016       7.374      71.495\n",
            "PRCP_yest         132.6340     55.900      2.373      0.018      22.929     242.339\n",
            "PRCP_yest_flag    -52.4987     33.678     -1.559      0.119    -118.593      13.596\n",
            "Windchill          -5.9262      6.708     -0.883      0.377     -19.092       7.239\n",
            "Rl_Cold            31.0185      8.081      3.839      0.000      15.160      46.877\n",
            "Jan              1.096e-13   1.76e-14      6.241      0.000    7.51e-14    1.44e-13\n",
            "Feb               199.3704     55.410      3.598      0.000      90.626     308.114\n",
            "Mar               149.7191     75.882      1.973      0.049       0.799     298.640\n",
            "Apr                19.0176    116.399      0.163      0.870    -209.419     247.454\n",
            "May               103.2700    166.702      0.619      0.536    -223.887     430.427\n",
            "Jun               436.6472    209.037      2.089      0.037      26.409     846.886\n",
            "Jul               248.5852    233.900      1.063      0.288    -210.448     707.618\n",
            "Aug               168.8749    224.788      0.751      0.453    -272.277     610.026\n",
            "Sep               177.0051    189.404      0.935      0.350    -194.705     548.715\n",
            "Oct               168.9981    140.903      1.199      0.231    -107.526     445.523\n",
            "Nov               234.4487     89.243      2.627      0.009      59.308     409.589\n",
            "Dec               169.2336     59.638      2.838      0.005      52.193     286.274\n",
            "TMIN_ln            -2.3229      0.540     -4.304      0.000      -3.382      -1.264\n",
            "==============================================================================\n",
            "Omnibus:                       28.402   Durbin-Watson:                   1.845\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               65.924\n",
            "Skew:                          -0.042   Prob(JB):                     4.84e-15\n",
            "Kurtosis:                       4.280   Cond. No.                     1.11e+16\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 6.18e-23. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CTVdYIz_WRNQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train2 = X_train.drop(['Jan', 'Feb', 'Mar', 'Oct', 'Nov', 'Dec'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sKFQLibtWr_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "8dab988b-27b1-41fd-8bdf-1f0c1ba44eb7"
      },
      "cell_type": "code",
      "source": [
        "scores = cross_validate(LinearRegression(), X_train2, y_train, \n",
        "                        scoring='neg_mean_absolute_error', cv=3, \n",
        "                        return_train_score=True, return_estimator=True)\n",
        "\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>0.006082</td>\n",
              "      <td>0.002420</td>\n",
              "      <td>-287.573218</td>\n",
              "      <td>-276.502068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>0.003370</td>\n",
              "      <td>0.001568</td>\n",
              "      <td>-291.350093</td>\n",
              "      <td>-269.345301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>0.005046</td>\n",
              "      <td>0.001613</td>\n",
              "      <td>-316.303240</td>\n",
              "      <td>-260.764457</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           estimator  fit_time  score_time  test_score  train_score\n",
              "0  LinearRegression(copy_X=True, fit_intercept=Tr...  0.006082    0.002420 -287.573218  -276.502068\n",
              "1  LinearRegression(copy_X=True, fit_intercept=Tr...  0.003370    0.001568 -291.350093  -269.345301\n",
              "2  LinearRegression(copy_X=True, fit_intercept=Tr...  0.005046    0.001613 -316.303240  -260.764457"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "YjQKiNQ2WMJc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1872
        },
        "outputId": "84c39df1-ff49-4085-cb2b-874f24de2a15"
      },
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2015-05-25    1737.0\n",
              "2015-05-26    4254.0\n",
              "2015-05-27    4771.0\n",
              "2015-05-28    5142.0\n",
              "2015-05-29    4548.0\n",
              "2015-05-30    2308.0\n",
              "2015-05-31    2251.0\n",
              "2015-06-01    2989.0\n",
              "2015-06-02    3078.0\n",
              "2015-06-03    3658.0\n",
              "2015-06-04    4637.0\n",
              "2015-06-05    4333.0\n",
              "2015-06-06    2475.0\n",
              "2015-06-07    2487.0\n",
              "2015-06-08    4475.0\n",
              "2015-06-09    4935.0\n",
              "2015-06-10    4977.0\n",
              "2015-06-11    4719.0\n",
              "2015-06-12    3769.0\n",
              "2015-06-13    2688.0\n",
              "2015-06-14    2556.0\n",
              "2015-06-15    4581.0\n",
              "2015-06-16    4551.0\n",
              "2015-06-17    4711.0\n",
              "2015-06-18    4284.0\n",
              "2015-06-19    3417.0\n",
              "2015-06-20    2323.0\n",
              "2015-06-21    2170.0\n",
              "2015-06-22    4456.0\n",
              "2015-06-23    4998.0\n",
              "2015-06-24    4725.0\n",
              "2015-06-25    4709.0\n",
              "2015-06-26    3869.0\n",
              "2015-06-27    2210.0\n",
              "2015-06-28    2101.0\n",
              "2015-06-29    4181.0\n",
              "2015-06-30    4655.0\n",
              "2015-07-01    4651.0\n",
              "2015-07-02    3937.0\n",
              "2015-07-03    2313.0\n",
              "2015-07-04    2443.0\n",
              "2015-07-05    1919.0\n",
              "2015-07-06    4066.0\n",
              "2015-07-07    4635.0\n",
              "2015-07-08    4761.0\n",
              "2015-07-09    4479.0\n",
              "2015-07-10    3772.0\n",
              "2015-07-11    2053.0\n",
              "2015-07-12    2037.0\n",
              "2015-07-13    4069.0\n",
              "2015-07-14    4795.0\n",
              "2015-07-15    4686.0\n",
              "2015-07-16    4424.0\n",
              "2015-07-17    3813.0\n",
              "2015-07-18    2195.0\n",
              "2015-07-19    1963.0\n",
              "2015-07-20    4213.0\n",
              "2015-07-21    4268.0\n",
              "2015-07-22    4648.0\n",
              "2015-07-23    4359.0\n",
              "2015-07-24    3628.0\n",
              "2015-07-25    1384.0\n",
              "2015-07-26    1452.0\n",
              "2015-07-27    4102.0\n",
              "2015-07-28    4715.0\n",
              "2015-07-29    4734.0\n",
              "2015-07-30    4379.0\n",
              "2015-07-31    3887.0\n",
              "2015-08-01    2219.0\n",
              "2015-08-02    1883.0\n",
              "2015-08-03    4243.0\n",
              "2015-08-04    4655.0\n",
              "2015-08-05    4108.0\n",
              "2015-08-06    4295.0\n",
              "2015-08-07    4100.0\n",
              "2015-08-08    2014.0\n",
              "2015-08-09    2945.0\n",
              "2015-08-10    3898.0\n",
              "2015-08-11    4530.0\n",
              "2015-08-12    4403.0\n",
              "2015-08-13    4428.0\n",
              "2015-08-14    2062.0\n",
              "2015-08-15    1702.0\n",
              "2015-08-16    2333.0\n",
              "2015-08-17    4319.0\n",
              "2015-08-18    4508.0\n",
              "2015-08-19    4548.0\n",
              "2015-08-20    3846.0\n",
              "2015-08-21    3606.0\n",
              "2015-08-22    2090.0\n",
              "2015-08-23    2016.0\n",
              "2015-08-24    4072.0\n",
              "2015-08-25    4473.0\n",
              "2015-08-26    4331.0\n",
              "2015-08-27    4336.0\n",
              "2015-08-28    2653.0\n",
              "2015-08-29     699.0\n",
              "2015-08-30    1213.0\n",
              "2015-08-31    2823.0\n",
              "2015-09-01    2876.0\n",
              "Name: Total, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "oux-dd-5FD6p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ASSIGNMENT\n",
        "\n",
        "### Core assignment\n",
        "\n",
        "Complete the notebook cells that were originally commented **`TODO`**. \n",
        "\n",
        "Then, focus on feature engineering to improve your cross validation scores. Collaborate with your cohort on Slack. You could start with the ideas [Jake VanderPlas suggests:](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic)\n",
        "\n",
        "> Our model is almost certainly missing some relevant information. For example, nonlinear effects (such as effects of precipitation and cold temperature) and nonlinear trends within each variable (such as disinclination to ride at very cold and very hot temperatures) cannot be accounted for in this model. Additionally, we have thrown away some of the finer-grained information (such as the difference between a rainy morning and a rainy afternoon), and we have ignored correlations between days (such as the possible effect of a rainy Tuesday on Wednesday's numbers, or the effect of an unexpected sunny day after a streak of rainy days). These are all potentially interesting effects, and you now have the tools to begin exploring them if you wish!\n",
        "\n",
        "At the end of the day, take the last step in the \"universal workflow of machine learning\" — \"You can train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.\"\n",
        "\n",
        "See the [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) documentation for the `refit` parameter, `best_estimator_` attribute, and `predict` method:\n",
        "\n",
        "> **refit : boolean, or string, default=True**\n",
        "\n",
        "> Refit an estimator using the best found parameters on the whole dataset.\n",
        "\n",
        "> The refitted estimator is made available at the `best_estimator_` attribute and permits using `predict` directly on this `GridSearchCV` instance.\n",
        "\n",
        "### More options\n",
        "\n",
        "**A.** Apply this lesson to other datasets.\n",
        "\n",
        "**B.** We predicted the number of bicycle trips based on that day's weather. But imagine you were asked to predict trips at the beginning of each day, based only on data known at the time of prediction or before — so you cannot use the current day's weather. How would you wrangle the features to handle this new requirement? How does this impact the predictive accuracy and coefficients of your models?\n",
        "\n",
        "**C.** In additon to `GridSearchCV`, scikit-learn has [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html), which is sometimes even better. Another library called scikit-optimize has [`BayesSearchCV`](https://scikit-optimize.github.io/notebooks/sklearn-gridsearchcv-replacement.html). Experiment with these alternatives.\n",
        "\n",
        "**D.** _[Introduction to Machine Learning with Python](http://shop.oreilly.com/product/0636920030515.do)_ discusses options for \"Grid-Searching Which Model To Use\" in Chapter 6:\n",
        "\n",
        "> You can even go further in combining GridSearchCV and Pipeline: it is also possible to search over the actual steps being performed in the pipeline (say whether to use StandardScaler or MinMaxScaler). This leads to an even bigger search space and should be considered carefully. Trying all possible solutions is usually not a viable machine learning strategy. However, here is an example comparing a RandomForestClassifier and an SVC ...\n",
        "\n",
        "The example is shown in [the accompanying notebook](https://github.com/amueller/introduction_to_ml_with_python/blob/master/06-algorithm-chains-and-pipelines.ipynb), code cells 35-37. Could you apply this concept to your own pipelines?\n",
        "\n",
        "\n"
      ]
    }
  ]
}