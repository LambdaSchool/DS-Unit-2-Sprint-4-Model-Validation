{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pump_all.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cocoisland/DS-Unit-2-Sprint-4-Model-Validation/blob/master/pump_all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ar3-zhbQ05lc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download Kaggle Dataset into Google Drive, so that CoLab can assess these data."
      ]
    },
    {
      "metadata": {
        "id": "F8UAmVspRyRj",
        "colab_type": "code",
        "outputId": "bdc75fb1-128c-4c92-f134-f0ef65359c38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.2)\n",
            "Requirement already satisfied: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.11.29)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.0.1)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: Unidecode>=0.04.16 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.0.23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qZtI_YhhR_Ue",
        "colab_type": "code",
        "outputId": "903e8ea1-abd3-4b0c-acf3-2c6f30b00d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%env KAGGLE_CONFIG_DIR=/content/drive/My Drive/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "env: KAGGLE_CONFIG_DIR=/content/drive/My Drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ol286mJ7SEGs",
        "colab_type": "code",
        "outputId": "bb7492ec-3b4d-4c71-c010-513c3825cb1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle  competitions download -c ds1-predictive-modeling-challenge"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sample_submission.csv to /content\n",
            "\r  0% 0.00/236k [00:00<?, ?B/s]\n",
            "100% 236k/236k [00:00<00:00, 94.6MB/s]\n",
            "Downloading test_features.csv.zip to /content\n",
            "  0% 0.00/948k [00:00<?, ?B/s]\n",
            "100% 948k/948k [00:00<00:00, 62.7MB/s]\n",
            "Downloading train_labels.csv.zip to /content\n",
            "  0% 0.00/211k [00:00<?, ?B/s]\n",
            "100% 211k/211k [00:00<00:00, 67.4MB/s]\n",
            "Downloading train_features.csv.zip to /content\n",
            "  0% 0.00/3.81M [00:00<?, ?B/s]\n",
            "100% 3.81M/3.81M [00:00<00:00, 126MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NUqCZMfnSIDo",
        "colab_type": "code",
        "outputId": "80c0bc33-9796-4fb7-cc37-7722a8b12231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip train_features.csv.zip\n",
        "!unzip train_labels.csv.zip\n",
        "!unzip test_features.csv.zip\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train_features.csv.zip\n",
            "  inflating: train_features.csv      \n",
            "Archive:  train_labels.csv.zip\n",
            "  inflating: train_labels.csv        \n",
            "Archive:  test_features.csv.zip\n",
            "  inflating: test_features.csv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IDKC-12RSLyX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aUPmwnpxSpYQ",
        "colab_type": "code",
        "outputId": "8c18dd3f-bcbb-469c-da13-a26cbb69bbe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('train_features.csv',index_col='id')\n",
        "df_test = pd.read_csv('test_features.csv',index_col='id')\n",
        "df_label = pd.read_csv('train_labels.csv')\n",
        "df_sample = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "df_train.shape, df_test.shape, df_label.shape, df_sample.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((59400, 39), (14358, 39), (59400, 2), (14358, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "R4v5SKwj1jRP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Begin project by establishing Baseline metrics.\n",
        "### Method 1: Majority baseline by value_counts. Random chance predictions have \n",
        "1. 54% functional well pump.\n",
        "2. 38% non-functional pump.\n",
        "3. 7%  repairable."
      ]
    },
    {
      "metadata": {
        "id": "FYLd0POx2U9O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "00c503fa-602b-421c-99b8-74d00a1af693"
      },
      "cell_type": "code",
      "source": [
        "df_label.status_group.value_counts(normalize=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "functional                 0.543081\n",
              "non functional             0.384242\n",
              "functional needs repair    0.072677\n",
              "Name: status_group, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "6wY38ibYUyPS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "accuracy = df_label.status_group.value_counts(normalize=True)[0]\n",
        "\n",
        "# Create score dataframe\n",
        "score=pd.DataFrame(columns=['method','accuracy', 'shape'])\n",
        "score.loc[0]=['majority_baseline',accuracy, (1,1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4sv1NCtKBcwp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Method 2: Feed LogisticRegression with numeric only.\n",
        "* Numeric data value can range so wide that no regression iteration can ever be enough to converge. \n",
        "* Do not increase max_iteration of LogisticRegression, instead call a Scaler."
      ]
    },
    {
      "metadata": {
        "id": "cdWG0hosDPG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "465e6acc-ded2-46b0-e0e0-68afcddb7086"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "df_num = df_train.select_dtypes(np.number)\n",
        "\n",
        "X=df_num\n",
        "y = df_label.status_group\n",
        "\n",
        "pipe = make_pipeline(\n",
        "    RobustScaler(),\n",
        "    LogisticRegression(solver='lbfgs',multi_class='auto',max_iter=500)\n",
        "    )\n",
        "\n",
        "pipe.fit(X,y)\n",
        "\n",
        "y_pred = pipe.predict(X)\n",
        "\n",
        "accuracy= accuracy_score(y, y_pred)\n",
        "score.loc[score.shape[0]]=['logReg_num', accuracy, X.shape]\n",
        "\n",
        "print('Accuracy score=', accuracy)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score= 0.5577946127946128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ICEC2n4Q4yCQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Method 2: LogisticRegression with non-numeric categorical value object only.\n",
        "* Encoders are friend of LogisticRegression, transforming non-numeric data  into numeric.\n",
        "#### But nasty data character are hidden landmine bomb to Encoder. \n",
        "* Nasty datatype - NaN, '?', space in front/after, keyword:False, True, None .\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "imm7YANRDm3a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def obj_cleanup(X5):\n",
        "  X5.replace('\\ 2\\ ','two', regex=True, inplace=True)\n",
        "  X5.replace(';','semicolon', regex=True, inplace=True)\n",
        "  X5.replace(\"`\", \"back_quote\", regex=True, inplace=True)\n",
        "  X5.replace(\"'\", \"quote\", regex=True, inplace=True)\n",
        "  X5.replace(\"\\(\", \"left_paren\", regex=True, inplace=True)\n",
        "  X5.replace(\"\\)\", \"right_paren\", regex=True, inplace=True)\n",
        "  X5.replace(\"\\/\", \"back_slash\", regex=True, inplace=True)\n",
        "  X5.replace(\"\\\\\", \"fwd_slash\", regex=True, inplace=True)\n",
        "  X5.replace(\"   \", \"space\", regex=True, inplace=True)\n",
        "  X5.replace(\"\\.\", \"dot\", regex=True, inplace=True)\n",
        "  return X5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KGXexIOUld_r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Example of finding problem maker\n",
        "'''test = df.select_dtypes([np.object]).apply(lambda x: x.str.contains(';').any())\n",
        "str_cols = df.select_dtypes([np.object]).columns\n",
        "str_cols[test]'''\n",
        "\n",
        "#df_test.loc[df_test['scheme_name'].str.contains('\\.')]['scheme_name']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0s8DckMZ7d1e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Best define a function for data cleanup, so that the cleanup process can be\n",
        "# applied to df_test data as well.\n",
        "\n",
        "def cleanup(data):\n",
        "  data.fillna('unknown', axis=1, inplace=True)\n",
        "  \n",
        "  # Nasty keyword(False, True) object breaks OneHotEncoder\n",
        "  data['permit'] = data['permit'].astype(dtype='str')\n",
        "  data['public_meeting'] = data['public_meeting'].astype(dtype='str')\n",
        "  \n",
        "  # One unique value adds no value, hence removed\n",
        "  data.drop('recorded_by', axis=1, inplace=True)\n",
        "  \n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PQi8iw69yLAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0fc802b5-31ec-4a31-dfc9-fcce3df2ac18"
      },
      "cell_type": "code",
      "source": [
        "# Example of nasty keyword data value hidden in permit column out 39 column features.\n",
        "df_train.permit.unique()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, True, nan], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "BCjB0kY7yJcJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcfbcf0d-76d6-48a2-fb9e-4d18cac8e666"
      },
      "cell_type": "code",
      "source": [
        "# copy()- make sure all cleanup work are copied over.\n",
        "df_train = cleanup(df_train).copy()\n",
        "df_test = cleanup(df_test).copy()\n",
        "\n",
        "df_train.permit.unique()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['False', 'True', 'unknown'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "000s36q4_ppN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c7565b9-e6a0-48a4-d583-80f33cf65cf2"
      },
      "cell_type": "code",
      "source": [
        "# Any NaN will show as True\n",
        "df_train.isnull().any().any()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "uROrPnKsz3vi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### High cardinality features add no value but noise to regression.  \n",
        "* Filter out features with high number of unique categorical values by eyeballing method.\n",
        "* nunique() function lists out number of unique categorical values.\n"
      ]
    },
    {
      "metadata": {
        "id": "DxOVAciq54Yu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Exclude non-number columns with high number of categorical values. \n",
        "# High cardinality columns when split by encoding turns into many useless noisy data.\n",
        "filter_cols  = df_train.select_dtypes(object).nunique().sort_values().index.tolist()[:-6]\n",
        "df_obj = df_train[filter_cols].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Efg7Zq614oFU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### OneHotEncoding non-numeric categorical value into 0 and 1.\n",
        "* Automatically increase both training accuracy score and testing bias into the model."
      ]
    },
    {
      "metadata": {
        "id": "2BMZnLX9_JDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39565fb4-d8a4-4b0b-c048-ede9d0a7eaa8"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "X=df_obj\n",
        "y=df_label.status_group\n",
        "\n",
        "pipe = make_pipeline(\n",
        "    OneHotEncoder(categories='auto'),\n",
        "    LogisticRegression(solver='lbfgs', multi_class='ovr',\n",
        "                      max_iter=500))\n",
        "\n",
        "pipe.fit(X,y)\n",
        "y_pred = pipe.predict(X)\n",
        "accuracy=accuracy_score(y, y_pred)\n",
        "\n",
        "score.loc[score.shape[0]] = ['logReg_OneHotEncoder', accuracy, X.shape]\n",
        "print('Accuracy score=', accuracy)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score= 0.757020202020202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tsNLmYqp3Jmi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Method 3: LogisticRegression with categorical value without Encoder.\n",
        "* Transforming unique categorical value into nominal value is more accurate and efficient than OneHotEncoding."
      ]
    },
    {
      "metadata": {
        "id": "zTIqaFQQhWxC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f72ba8f-4b42-4567-d2b4-3a076d2bbbe5"
      },
      "cell_type": "code",
      "source": [
        "df_cat = df_obj.apply(lambda x: x.astype('category').cat.codes)\n",
        "\n",
        "X=df_cat\n",
        "y=df_label.status_group\n",
        "\n",
        "pipe = make_pipeline(\n",
        "    RobustScaler(),\n",
        "    LogisticRegression(solver='lbfgs',multi_class='auto',max_iter=500)\n",
        "    )\n",
        "\n",
        "pipe.fit(X,y)\n",
        "\n",
        "y_pred = pipe.predict(X)\n",
        "\n",
        "accuracy=accuracy_score(y, y_pred)\n",
        "score.loc[score.shape[0]] = ['logReg_cat_codes', accuracy, X.shape]\n",
        "print('Accuracy score=', accuracy)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score= 0.6286531986531987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1IHKBBOykatV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Method 4: Include all non-numeric categorical value (all cardinality) using cat code.\n",
        "* Converting non-numeric to category code, solve the high cardinality columns problem."
      ]
    },
    {
      "metadata": {
        "id": "inX-sQ7bkZ1E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16de9271-da97-4d1a-b947-24ff48bdac52"
      },
      "cell_type": "code",
      "source": [
        "df_cat_all = df_train.apply(lambda x: x.astype('category').cat.codes)\n",
        "X=df_cat_all\n",
        "y=df_label.status_group\n",
        "\n",
        "pipe = make_pipeline(\n",
        "    RobustScaler(),\n",
        "    LogisticRegression(solver='lbfgs',multi_class='auto',max_iter=500)\n",
        "    )\n",
        "\n",
        "pipe.fit(X,y)\n",
        "\n",
        "y_pred = pipe.predict(X)\n",
        "\n",
        "accuracy=accuracy_score(y, y_pred)\n",
        "score.loc[score.shape[0]] = ['logReg_cat_allcodes', accuracy, X.shape]\n",
        "print('Accuracy score=', accuracy)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score= 0.6557912457912458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qzm1GXijoJce",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Method 5: Everything both numeric and non-numeric using Encoder\n",
        "* OneHotEncoder going crazy transforming both numeric and non-numeric, turning LogisticRegression into a neural network overfitting model?\n",
        "#### Accuracy of 96% on training data? OneHotEncoder not to be trusted. Using this model to predict on df_test data, yields nonsense category unknown error."
      ]
    },
    {
      "metadata": {
        "id": "Ox86M5qeoIiF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74e43e37-e383-43fd-f720-4c51a7356e5c"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "#X=df_train\n",
        "y=df_label.status_group\n",
        "\n",
        "pipe = make_pipeline(\n",
        "    OneHotEncoder(categories='auto'),\n",
        "    LogisticRegression(solver='lbfgs', multi_class='ovr',\n",
        "                      max_iter=2000))\n",
        "\n",
        "pipe.fit(X,y)\n",
        "y_pred = pipe.predict(X)\n",
        "accuracy=accuracy_score(y, y_pred)\n",
        "\n",
        "score.loc[score.shape[0]] = ['logReg_allnumcat_Encoding', accuracy, X.shape]\n",
        "print('Accuracy score=', accuracy)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score= 0.9674579124579125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-ixR8zAfo_WX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "7c15bcf0-46b4-4b5c-fac0-531963c76c1e"
      },
      "cell_type": "code",
      "source": [
        "score"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>method</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>shape</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>majority_baseline</td>\n",
              "      <td>0.543081</td>\n",
              "      <td>(1, 1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>logReg_num</td>\n",
              "      <td>0.557795</td>\n",
              "      <td>(59400, 9)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>logReg_OneHotEncoder</td>\n",
              "      <td>0.757020</td>\n",
              "      <td>(59400, 23)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>logReg_cat_codes</td>\n",
              "      <td>0.628653</td>\n",
              "      <td>(59400, 23)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>logReg_cat_allcodes</td>\n",
              "      <td>0.655791</td>\n",
              "      <td>(59400, 38)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>logReg_allnumcat_Encoding</td>\n",
              "      <td>0.967458</td>\n",
              "      <td>(59400, 38)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      method  accuracy        shape\n",
              "0          majority_baseline  0.543081       (1, 1)\n",
              "1                 logReg_num  0.557795   (59400, 9)\n",
              "2       logReg_OneHotEncoder  0.757020  (59400, 23)\n",
              "3           logReg_cat_codes  0.628653  (59400, 23)\n",
              "4        logReg_cat_allcodes  0.655791  (59400, 38)\n",
              "5  logReg_allnumcat_Encoding  0.967458  (59400, 38)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "cgO97KiX5bOs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Exploration - making sense of data"
      ]
    },
    {
      "metadata": {
        "id": "7EeknyBk70fl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# grouping longitude+latitude into local centroid\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def add_local_gps(X3):\n",
        "  points=X3[['longitude','latitude']]\n",
        "  points = points.drop(points[points.longitude == 0].index)\n",
        "  \n",
        "  km = KMeans(n_clusters=20)\n",
        "  km = km.fit(points)\n",
        "  \n",
        "  points['centroid']=km.labels_\n",
        "  return points['centroid']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jJoB8e7JxuoB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot longitude+latitude with centroid\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def viz_gps(X3):\n",
        "  points=X3[['longitude','latitude']]\n",
        "  points = points.drop(points[points.longitude == 0].index)\n",
        "\n",
        "  '''\n",
        "  sum_of_squared_distanced = []\n",
        "\n",
        "  K = range(1,25)\n",
        "  for k in K:\n",
        "    km = KMeans(n_clusters=k)\n",
        "    km = km.fit(points)\n",
        "    sum_of_squared_distanced.append(km.inertia_)\n",
        "\n",
        "  plt.plot(K, sum_of_squared_distanced, marker=\"X\")\n",
        "  plt.xlabel('k', fontsize=15)\n",
        "  plt.ylabel('Sum_of_squared_distanced', fontsize=15)\n",
        "  plt.title('Elbow Method to find the optimal k by eyeball', fontsize=15)\n",
        "  plt.show()\n",
        "'''\n",
        "  km = KMeans(n_clusters=20)\n",
        "  km = km.fit(points)\n",
        "\n",
        "  plt.scatter(points.longitude, points.latitude, c=km.labels_, cmap='rainbow')\n",
        "\n",
        "  plt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:,1], color='black')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G4I8DUZ4S2D8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# feature engineering-turning continuous numeric into discrete value.\n",
        "# Hopefully logistic classifier can map discrete value to target\n",
        "def num_cleanup(X1):\n",
        "  '''\n",
        "  date_recorded\n",
        "  ['amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private',\n",
        "       'region_code', 'district_code', 'population', 'construction_year']\n",
        "  '''\n",
        "  \n",
        "  # categorical value nan converted to unknown to be processed by regression.\n",
        "  X2 = X1.fillna('unknown')\n",
        "  \n",
        "  # added recorded_year_built\n",
        "  # convert date_recorded as year \n",
        "  dates = pd.to_datetime(X2.date_recorded)\n",
        "  X2['recorded_year_built'] = dates.dt.year - X2['construction_year']\n",
        "  X2.loc[X2.recorded_year_built > 1000 ] = 0\n",
        "  X2.date_recorded = dates.dt.year\n",
        "  \n",
        "  #\n",
        "  bins=[-100,0,100,500,1000,1250,1500,2000]\n",
        "  labels=[0,100,500,1000,1250,1500,2000]\n",
        "  #X2['gps_height_bin']= pd.cut(X2.gps_height, bins, labels=labels)\n",
        "  #X2.drop(['gps_height'], axis=1, inplace=True)\n",
        "  \n",
        "  # replace longitude, latitude with centroid\n",
        "  X2['centroid']=add_local_gps(X1)\n",
        "  #X2.drop(['longitude','latitude'], axis=1, inplace=True)\n",
        "  \n",
        "  type_dict = {'amount_tsh':'float64',    # nunique()=98\n",
        "               'date_recorded':'float64', # date into year\n",
        "               'gps_height':'float64',\n",
        "               #'gps_height_bin':'float64',    #added bins; reduce score 0.02\n",
        "               'centroid':'float64',  # centroid=25,2000: no impact on score.\n",
        "               'num_private':'float64',   # nunique()=65\n",
        "               'population':'float64',    # nunique()=1049\n",
        "               'construction_year':'float64',   # nunique()=55\n",
        "               'recorded_year_built':'float64', #added\n",
        "               'region_code':'float64',   # nunique()=27\n",
        "               'district_code':'float64'  # nunique=20 \n",
        "              }\n",
        "  X2 = X2.astype(dtype = type_dict)\n",
        "  \n",
        "  X2 = X2.fillna(0)\n",
        "\n",
        "  return X2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ef_CfcBKFfFb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sklearn.feature_selection as fe\n",
        "\n",
        "def variance_threshold_selector(data, threshold=0.03):\n",
        "    selector = fe.VarianceThreshold(threshold)\n",
        "    selector.fit(data)\n",
        "    return data[data.columns[selector.get_support(indices=True)]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nHHnomyoIRwP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train.funder = df_train.funder.replace('0', 'missing')\n",
        "X_dummies = pd.get_dummies(df_train.funder)\n",
        "funder_filter=variance_threshold_selector(X_dummies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W6NHBVmGFv_j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train.funder = df_train.funder.replace('0', 'missing')\n",
        "X_dummies = ce.OneHotEncoder().fit_transform(s)\n",
        "dummy_filter=variance_threshold_selector(X_dummies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L9HNVGB_weF1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def obj_cleanup(X):\n",
        "  \n",
        "  X4=X.copy()\n",
        "  \n",
        "  '''# extraction_type_class 0.714 - 0.713\n",
        "  X4.extraction_type_class.replace('other','otr_extr',inplace=True)\n",
        "    \n",
        "  # management 0.713 - 0.708\n",
        "  X4.management=X4.management.replace('unknown','unkwn_mgmt')\n",
        "  X4.management=X4.management.replace('other','otr_mgmt')\n",
        "   \n",
        "  # payment\n",
        "  X4.payment=X4.payment.replace('unknown','unkwn_pmt')\n",
        "  \n",
        "  # quality_group\n",
        "  X4.quality_group=X4.quality_group.replace('unknown','unkwn_qual_grp')\n",
        "    \n",
        "  # quantity\n",
        "  X4.quantity=X4.quantity.replace('unknown','unknown_quantity')\n",
        "  \n",
        "  # waterpoint_type\n",
        "  X4.waterpoint_type=X4.waterpoint_type.replace('other','otr_wtr')\n",
        "  '''\n",
        "  type_dict = {\n",
        "               'basin':'object',   \n",
        "               'region':'object', \n",
        "               'lga':'object',\n",
        "               'extraction_type_class':'object', \n",
        "               'management':'object',  \n",
        "               'payment':'object',   \n",
        "               'quality_group':'object',\n",
        "               'quantity':'object' ,\n",
        "               'source_type':'object', \n",
        "               'waterpoint_type':'object'   \n",
        "              }\n",
        "  cols=list(type_dict.keys())\n",
        "  X4 = X4[cols].astype(dtype = type_dict)\n",
        "  \n",
        "  \n",
        "  return X4\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RoOVuatC4K__",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "cc7d5d77-20ec-4d2f-b256-93e59e47e6d1"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X=df_final\n",
        "y = df_label.status_group\n",
        "\n",
        "pipe.fit(X,y)\n",
        "\n",
        "y_pred = pipe.predict(X)\n",
        "print('Accuracy score=', accuracy_score(y, y_pred))\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy score= 0.725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xqa1sIcFQuIs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_pred = pipe.predict(df_final_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mTPu1S0HTRyH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_obj_clean.apply(lambda x: x.astype('category').cat.codes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ozWyxUvAMGjo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8a11c77-359b-4d9b-f672-31910076042a"
      },
      "cell_type": "code",
      "source": [
        "# Clean and prepare data\n",
        "df_num = df_train.select_dtypes('number').copy()\n",
        "df_num['date_recorded'] = df_train['date_recorded']\n",
        "df_num_test = df_test.select_dtypes('number').copy()\n",
        "df_num_test['date_recorded'] = df_test['date_recorded']\n",
        "\n",
        "df_clean = num_cleanup(df_num).copy()\n",
        "df_clean_test = num_cleanup(df_num_test).copy()\n",
        "\n",
        "\n",
        "df_obj = df_train.select_dtypes(object).copy()\n",
        "df_obj_test = df_test.select_dtypes(object).copy()\n",
        "\n",
        "df_obj_clean = obj_cleanup(df_obj).copy()\n",
        "df_obj_test_clean = obj_cleanup(df_obj_test).copy()\n",
        "\n",
        "df_final = df_clean.join(df_obj_clean)\n",
        "df_final_test = df_clean_test.join(df_obj_clean)\n",
        "\n",
        "df_final.shape, df_final_test.shape\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((59400, 22), (14358, 22))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "Zo_8JDri8cIV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_pred = pipe.predict(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5mmKivbbYUGY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import warning\n",
        "\n",
        "warnings.filterwarnings(action='ignore', category='FutureWarning')\n",
        "\n",
        "X=df_num\n",
        "y = df_label.status_group\n",
        "\n",
        "pipe = make_pipeline(\n",
        "    SelectKBest(f_classif),\n",
        "    LogisticRegression(max_iter=500))\n",
        "\n",
        "param_grid = {\n",
        "    'selectkbest__k': [5,9, 'all'],\n",
        "    'logisticregression__class_weight': [None, 'balanced'],\n",
        "    'logisticregression__penalty': ['l1', 'l2'],\n",
        "    'logisticregression__C': [.1, 1.0, 10.0]\n",
        "}\n",
        "\n",
        "\n",
        "gs = GridSearchCV(pipe, param_grid=param_grid, cv=3, \n",
        "                  scoring='accuracy', return_train_score=True,\n",
        "                  verbose=1)\n",
        "\n",
        "gs.fit(X, y)\n",
        "\n",
        "\n",
        "print('Accuracy Score:', gs.best_score_)\n",
        "print('Best estimator:', gs.best_estimator_)\n",
        "print()\n",
        "\n",
        "results = pd.DataFrame(gs.cv_results_)\n",
        "print('Best result from grid search of {} parameter combinations'.format(len(results)))\n",
        "results.sort_values(by='rank_test_score').head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ePoiacyIZDO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X=df_num\n",
        "y = df_label.status_group\n",
        "\n",
        "pipe.fit(X,y)\n",
        "\n",
        "y_pred = pipe.predict(X)\n",
        "print('Accuracy score=', accuracy_score(y, y_pred))\n",
        "\n",
        "y_test_pred = pipe.predict(df_num_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nigsv7brS2NC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_pred = pipe.predict(df_num_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jd_1lI-iufTm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scores = cross_validate(LogisticRegression(solver='lbfgs',class_weight=None, max_iter=1500), \n",
        "                        X, y, \n",
        "                        scoring='accuracy', cv=3,\n",
        "                        return_train_score=True, return_estimator=True)\n",
        "\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FG0MbN2ytPGw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Xgboost\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "modelxgb = XGBClassifier(objective = 'multi:softmax', booster = 'gbtree', nrounds = 'min.error.idx', \n",
        "                      num_class = 3, maximize = False, eval_metric = 'merror', eta = .1,\n",
        "                      max_depth = 14, colsample_bytree = .4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nNlT3_Yxtu-V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Xgboost\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "score = (cross_val_score(modelxgb, X, y, cv=5,n_jobs = -1))\n",
        "score.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PlKsxqz0qFaI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_num.drop(['gps_height_bin','amount_tsh','date_recorded','num_private',\n",
        "            'gps_height','construction_year'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "etKXe5uOw1Yo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_num.drop(['region_code'],axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qkoc2CKFcyTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "abbeb09b-444c-4326-e73a-c5f1b4134781"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X=df_num.copy()\n",
        "y = df_label.status_group\n",
        "\n",
        "model = LogisticRegression(solver='lbfgs', \n",
        "             multi_class='auto',max_iter=3000).fit(X, y)\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "print('Accuracy score=', accuracy_score(y, y_pred))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score= 0.5985353535353536\n",
            "CPU times: user 1min 2s, sys: 33.7 s, total: 1min 35s\n",
            "Wall time: 48.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LViQl3-cgNSn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(df_num_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3daDPoMlcQko",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#submission as format as df_sample\n",
        "y_submission = pd.DataFrame()\n",
        "\n",
        "y_submission['id'] = df_test.index\n",
        "y_submission['status_group']=y_pred\n",
        "y_submission.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pg1XZ60_cUSz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "y_submission.to_csv('data_all.csv', index=False)\n",
        "files.download(\"data_all.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}