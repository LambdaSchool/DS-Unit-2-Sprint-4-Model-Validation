{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PC9RfopIWrc9"
   },
   "source": [
    " # Data Science Unit 2 Sprint Challenge 4 — Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UV7ArLFQN84W"
   },
   "source": [
    "Follow the instructions for each numbered part to earn a score of 2. See the bottom of the notebook for a list of ways you can earn a score of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAZcbTtiUlkI"
   },
   "source": [
    "## Predicting Blood Donations\n",
    "\n",
    "Our dataset is from a mobile blood donation vehicle in Taiwan. The Blood Transfusion Service Center drives to different universities and collects blood as part of a blood drive.\n",
    "\n",
    "The goal is to predict the last column, whether the donor made a donation in March 2007, using information about each donor's history. We'll measure success using recall score as the model evaluation metric.\n",
    "\n",
    "Good data-driven systems for tracking and predicting donations and supply needs can improve the entire supply chain, making sure that more patients get the blood transfusions they need.\n",
    "\n",
    "#### Run this cell to load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvV9VORbxyvu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data')\n",
    "\n",
    "df = df.rename(columns={\n",
    "    'Recency (months)': 'months_since_last_donation', \n",
    "    'Frequency (times)': 'number_of_donations', \n",
    "    'Monetary (c.c. blood)': 'total_volume_donated', \n",
    "    'Time (months)': 'months_since_first_donation', \n",
    "    'whether he/she donated blood in March 2007': 'made_donation_in_march_2007'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxKfgx4ycb3c"
   },
   "source": [
    "## Part 1.1 — Begin with baselines\n",
    "\n",
    "What **accuracy score** would you get here with a **\"majority class baseline\"?** \n",
    " \n",
    "(You don't need to split the data into train and test sets yet. You can answer this question either with a scikit-learn function or with a pandas function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3oo31Remcq-x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    570\n",
      "1    178\n",
      "Name: made_donation_in_march_2007, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check our values\n",
    "print(df['made_donation_in_march_2007'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Class Baseline Accuracy:\n",
      "0.7620320855614974\n"
     ]
    }
   ],
   "source": [
    "#accuracy == true/total\n",
    "print('Majority Class Baseline Accuracy:')\n",
    "print(570/(570+178))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_KdxE1TrcriI"
   },
   "source": [
    "What **recall score** would you get here with a **majority class baseline?**\n",
    "\n",
    "(You can answer this question either with a scikit-learn function or with no code, just your understanding of recall.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILS0fN0Cctyc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for 1:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Recall == true positives/true positives+false negatives\n",
    "print('Recall for 1:')\n",
    "print('0')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqYNDtwKYhji"
   },
   "source": [
    "## Part 1.2 — Split data\n",
    "\n",
    "In this Sprint Challenge, you will use \"Cross-Validation with Independent Test Set\" for your model evaluation protocol.\n",
    "\n",
    "First, **split the data into `X_train, X_test, y_train, y_test`**, with random shuffle. (You can include 75% of the data in the train set, and hold out 25% for the test set.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPKf86yDYf0t"
   },
   "outputs": [],
   "source": [
    "#split our data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df['made_donation_in_march_2007']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.75, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 561\n",
      "187 561\n"
     ]
    }
   ],
   "source": [
    "#make sure the split went well\n",
    "print(len(X_train), len(X_test))\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E_ATNJdqTCuZ"
   },
   "source": [
    "## Part 2.1 — Make a pipeline\n",
    "\n",
    "Make a **pipeline** which includes:\n",
    "- Preprocessing with any scikit-learn [**Scaler**](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)\n",
    "- Feature selection with **[`SelectKBest`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)([`f_classif`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html))**\n",
    "- Classification with [**`LogisticRegression`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all necessary components for our pipeline\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import pipeline\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build pipeline using Robust scaler, select k best, and logistic regression \n",
    "\n",
    "pipe = pipeline.make_pipeline(\n",
    "    RobustScaler(),\n",
    "    SelectKBest(f_classif),\n",
    "    LogisticRegression(solver='lbfgs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'robustscaler', 'selectkbest', 'logisticregression', 'robustscaler__copy', 'robustscaler__quantile_range', 'robustscaler__with_centering', 'robustscaler__with_scaling', 'selectkbest__k', 'selectkbest__score_func', 'logisticregression__C', 'logisticregression__class_weight', 'logisticregression__dual', 'logisticregression__fit_intercept', 'logisticregression__intercept_scaling', 'logisticregression__max_iter', 'logisticregression__multi_class', 'logisticregression__n_jobs', 'logisticregression__penalty', 'logisticregression__random_state', 'logisticregression__solver', 'logisticregression__tol', 'logisticregression__verbose', 'logisticregression__warm_start'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Handy little function to see the keys for my gridsearch\n",
    "pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5vRkQHatglMG"
   },
   "source": [
    "## Part 2.2 — Do Grid Search Cross-Validation\n",
    "\n",
    "Do [**GridSearchCV**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) with your pipeline. Use **5 folds** and **recall score**.\n",
    "\n",
    "Include these **parameters for your grid:**\n",
    "\n",
    "#### `SelectKBest`\n",
    "- `k : 1, 2, 3, 4`\n",
    "\n",
    "#### `LogisticRegression`\n",
    "- `class_weight : None, 'balanced'`\n",
    "- `C : .0001, .001, .01, .1, 1.0, 10.0, 100.00, 1000.0, 10000.0`\n",
    "\n",
    "\n",
    "**Fit** on the appropriate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgN8kG0ogBMH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:    3.5s finished\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "       with_scaling=True)), ('selectkbest', SelectKBest(k=10, score_func=<function f_classif at 0x1a1d24b730>)), ('logisticregression', LogisticRegression(C=1.0, cla...nalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'selectkbest__k': [1, 2, 3, 4], 'logisticregression__class_weight': [None, 'balanced'], 'logisticregression__C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'selectkbest__k': [1, 2, 3, 4], \n",
    "    'logisticregression__class_weight': [None, 'balanced'],\n",
    "    'logisticregression__C': [.0001, .001, .01, .1, 1.0, 10.0, 100.00, 1000.0, 10000.0]\n",
    "}\n",
    "\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid=param_grid, cv=5, \n",
    "                  scoring='recall', \n",
    "                  verbose=1)\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "urY_Wp3AiF83"
   },
   "source": [
    "## Part 3 — Show best score and parameters\n",
    "\n",
    "Display your **best cross-validation score**, and the **best parameters** (the values of `k, class_weight, C`) from the grid search.\n",
    "\n",
    "(You're not evaluated here on how good your score is, or which parameters you find. You're only evaluated on being able to display the information. There are several ways you can get the information, and any way is acceptable.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qAxxkjG7gACP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Best Cross-Validation Score: 0.7507427213309567\n",
      "\n",
      " Current Best estimator: Pipeline(memory=None,\n",
      "     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "       with_scaling=True)), ('selectkbest', SelectKBest(k=4, score_func=<function f_classif at 0x1a1d24b730>)), ('logisticregression', LogisticRegression(C=10.0, class_weight='balanced', dual=False,\n",
      "   ...enalty='l2', random_state=None,\n",
      "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validation_score = gs.best_score_\n",
    "print()\n",
    "print('Current Best Cross-Validation Score:', validation_score)\n",
    "print()\n",
    "print(' Current Best estimator:', gs.best_estimator_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jkyHoRIbEgRR"
   },
   "source": [
    "## Part 4 — Calculate classification metrics from a confusion matrix\n",
    "\n",
    "Suppose this is the confusion matrix for your binary classification model:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th colspan=\"2\" rowspan=\"2\"></th>\n",
    "    <th colspan=\"2\">Predicted</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Negative</th>\n",
    "    <th>Positive</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th rowspan=\"2\">Actual</th>\n",
    "    <th>Negative</th>\n",
    "    <td>85</td>\n",
    "    <td>58</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Positive</th>\n",
    "    <td>8</td>\n",
    "    <td>36</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LhyMM5H-JpVB"
   },
   "source": [
    "Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZPwqdh2KUcB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6470588235294118\n"
     ]
    }
   ],
   "source": [
    "#accuracy == (true positive + true negative)/Total\n",
    "tp = 36\n",
    "tn = 85\n",
    "fp = 58\n",
    "fn = 8\n",
    "\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BRWLfGcGKeQw"
   },
   "source": [
    "Calculate precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-FEZ4i_Kf_n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3829787234042553\n"
     ]
    }
   ],
   "source": [
    "#precision == tp/tp+fp\n",
    "precision = tp/(tp+fp)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h_mH2NYDKi2C"
   },
   "source": [
    "Calculate recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U4_wJGyjKkXJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "#recall == tp/tp+fn\n",
    "recall = tp/(tp+fn)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KEaWsk5Kk9W"
   },
   "source": [
    "## BONUS — How you can earn a score of 3\n",
    "\n",
    "### Part 1\n",
    "Do feature engineering, to try improving your cross-validation score.\n",
    "\n",
    "### Part 2\n",
    "Add transformations in your pipeline and parameters in your grid, to try improving your cross-validation score.\n",
    "\n",
    "### Part 3\n",
    "Show names of selected features. Then do a final evaluation on the test set — what is the test score?\n",
    "\n",
    "### Part 4\n",
    "Calculate F1 score and False Positive Rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports go here\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate polynomial features\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_polynomial = poly.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 15 features.\n"
     ]
    }
   ],
   "source": [
    "#Use RFECV to narrow features \n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_polynomial)\n",
    "\n",
    "rfe = RFECV(LogisticRegression(solver='lbfgs', class_weight='balanced'), scoring='recall', \n",
    "            step=20, cv=3, verbose=1)\n",
    "\n",
    "X_train_subset = rfe.fit_transform(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Features selected:\n",
      "1\n",
      "months_since_last_donation\n",
      "number_of_donations\n",
      "total_volume_donated\n",
      "months_since_first_donation\n",
      "months_since_last_donation^2\n",
      "months_since_last_donation number_of_donations\n",
      "months_since_last_donation total_volume_donated\n",
      "months_since_last_donation months_since_first_donation\n",
      "number_of_donations^2\n",
      "number_of_donations total_volume_donated\n",
      "number_of_donations months_since_first_donation\n",
      "total_volume_donated^2\n",
      "total_volume_donated months_since_first_donation\n",
      "months_since_first_donation^2\n"
     ]
    }
   ],
   "source": [
    "#names of selected poly features\n",
    "#borrowed directly from Ryan Herr (thanks!)\n",
    "\n",
    "all_names = poly.get_feature_names(X_train.columns)\n",
    "selected_mask = rfe.support_\n",
    "selected_names = [name for name, selected in zip(all_names, selected_mask) if selected]\n",
    "\n",
    "print(f'{rfe.n_features_} Features selected:')\n",
    "for name in selected_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Score: 0.6830404889228419\n",
      "\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=6, score_func=<function f_classif at 0x1a1d24b730>)), ('logisticregression', LogisticRegression(C=10.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
      "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:    1.3s finished\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Define an estimator and param_grid\n",
    "\n",
    "#received a warning that feature[0] is a constant \n",
    "new_X = X_train_subset[:,1:]\n",
    "\n",
    "#use selectkbest to tighten up the features generated by the RFECV\n",
    "pipe = pipeline.make_pipeline(\n",
    "        SelectKBest(f_classif),\n",
    "        LogisticRegression(solver='lbfgs', class_weight = 'balanced'))\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'selectkbest__k': [5,6,7,8,9,10,11,12,13,14],\n",
    "    'logisticregression__C': [.0001, .001, .01, .1, 1.0,10.0]\n",
    "}\n",
    "\n",
    "#cv = 3 because I want to save electricity \n",
    "gs = GridSearchCV(pipe, param_grid=param_grid, cv=3, \n",
    "                  scoring='recall', \n",
    "                  verbose=1)\n",
    "\n",
    "gs.fit(new_X, y_train)\n",
    "validation_score = gs.best_score_\n",
    "print()\n",
    "print('Cross-Validation Score:', validation_score)\n",
    "print()\n",
    "print('Best estimator:', gs.best_estimator_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.6119402985074627\n"
     ]
    }
   ],
   "source": [
    "# Do everything that we did up there, down here\n",
    "\n",
    "X_test_polynomial = poly.transform(X_test)\n",
    "X_test_scaled = scaler.transform(X_test_polynomial)\n",
    "X_test_subset = rfe.transform(X_test_scaled)\n",
    "\n",
    "new_X_test = X_test_subset[:,1:]\n",
    "\n",
    "test_score = gs.score(new_X_test, y_test)\n",
    "y_pred = gs.predict(new_X_test)\n",
    "print('Test Score:', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not great, but better than pure chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[313 114]\n",
      " [ 52  82]]\n",
      "\n",
      "f1 score  0.49696969696969695\n",
      "\n",
      "False positive rate  0.26697892271662765\n"
     ]
    }
   ],
   "source": [
    "#generate confusion matrix and f1 score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('')\n",
    "print('f1 score ',f1_score(y_test, y_pred))\n",
    "print('')\n",
    "\n",
    "#false positive == FP/total negative\n",
    "#false positive == 114\n",
    "#total negative == 427\n",
    "\n",
    "print('False positive rate ', 114/427)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS_Unit_2_Sprint_Challenge_4_Model_Validation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
