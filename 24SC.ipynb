{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS_Unit_2_Sprint_Challenge_4_Model_Validation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quinn-dougherty/DS-Unit-2-Sprint-4-Model-Validation/blob/master/24SC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "PC9RfopIWrc9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " # Data Science Unit 2 Sprint Challenge 4 — Model Validation"
      ]
    },
    {
      "metadata": {
        "id": "UV7ArLFQN84W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Follow the instructions for each numbered part to earn a score of 2. See the bottom of the notebook for a list of ways you can earn a score of 3."
      ]
    },
    {
      "metadata": {
        "id": "bAZcbTtiUlkI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Predicting Blood Donations\n",
        "\n",
        "Our dataset is from a mobile blood donation vehicle in Taiwan. The Blood Transfusion Service Center drives to different universities and collects blood as part of a blood drive.\n",
        "\n",
        "The goal is to predict the last column, whether the donor made a donation in March 2007, using information about each donor's history. We'll measure success using recall score as the model evaluation metric.\n",
        "\n",
        "Good data-driven systems for tracking and predicting donations and supply needs can improve the entire supply chain, making sure that more patients get the blood transfusions they need.\n",
        "\n",
        "#### Run this cell to load the data:"
      ]
    },
    {
      "metadata": {
        "id": "gvV9VORbxyvu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "d8308a3f-4c50-456a-a940-2328fad4605e"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler,RobustScaler, PolynomialFeatures\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data')\n",
        "\n",
        "dependent = 'made_donation_07'\n",
        "\n",
        "df = df.rename(columns={\n",
        "    'Recency (months)': 'months_since_last_donation', \n",
        "    'Frequency (times)': 'number_of_donations', \n",
        "    'Monetary (c.c. blood)': 'total_volume_donated', \n",
        "    'Time (months)': 'months_since_first_donation', \n",
        "    'whether he/she donated blood in March 2007': dependent\n",
        "})\n",
        "\n",
        "\n",
        "print(df[dependent].value_counts())\n",
        "\n",
        "df.head()\n"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    570\n",
            "1    178\n",
            "Name: made_donation_07, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>months_since_last_donation</th>\n",
              "      <th>number_of_donations</th>\n",
              "      <th>total_volume_donated</th>\n",
              "      <th>months_since_first_donation</th>\n",
              "      <th>made_donation_07</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>12500</td>\n",
              "      <td>98</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>3250</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>4000</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>5000</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>6000</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   months_since_last_donation  number_of_donations  total_volume_donated  \\\n",
              "0                           2                   50                 12500   \n",
              "1                           0                   13                  3250   \n",
              "2                           1                   16                  4000   \n",
              "3                           2                   20                  5000   \n",
              "4                           1                   24                  6000   \n",
              "\n",
              "   months_since_first_donation  made_donation_07  \n",
              "0                           98                 1  \n",
              "1                           28                 1  \n",
              "2                           35                 1  \n",
              "3                           45                 1  \n",
              "4                           77                 0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "metadata": {
        "id": "IxKfgx4ycb3c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 1.1 — Begin with baselines\n",
        "\n",
        "What **accuracy score** would you get here with a **\"majority class baseline\"?** \n",
        " \n",
        "(You don't need to split the data into train and test sets yet. You can answer this question either with a scikit-learn function or with a pandas function.)"
      ]
    },
    {
      "metadata": {
        "id": "3oo31Remcq-x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef0bff46-b79a-4291-8872-98f62fc3ec30"
      },
      "cell_type": "code",
      "source": [
        "majority_class = df[dependent].value_counts().idxmax()\n",
        "\n",
        "y0 = pd.DataFrame(np.full((df.shape[0], 1) , fill_value=majority_class), columns=['predicted' + dependent])\n",
        "\n",
        "accuracy = np.divide(df[dependent].value_counts()[majority_class], df.shape[0])\n",
        "\n",
        "print(f'The majority-class baseline has an accuracy score of {accuracy:.3}')\n"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The majority-class baseline has an accuracy score of 0.762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_KdxE1TrcriI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What **recall score** would you get here with a **majority class baseline?**\n",
        "\n",
        "(You can answer this question either with a scikit-learn function or with no code, just your understanding of recall.)\n",
        "\n",
        "## We _never_ predicted `1` in the majority-class baseline. \n",
        "## our `True Positive` rate is `0`. \n",
        "## $Recall = \\frac{Accurately-predicted-1}{1-is-observed-in-data} = \\frac{0}{178} = 0$"
      ]
    },
    {
      "metadata": {
        "id": "ILS0fN0Cctyc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QqYNDtwKYhji",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 1.2 — Split data\n",
        "\n",
        "In this Sprint Challenge, you will use \"Cross-Validation with Independent Test Set\" for your model evaluation protocol.\n",
        "\n",
        "First, **split the data into `X_train, X_test, y_train, y_test`**, with random shuffle. (You can include 75% of the data in the train set, and hold out 25% for the test set.)\n"
      ]
    },
    {
      "metadata": {
        "id": "mPKf86yDYf0t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e08f5fc6-6e85-4a00-9528-5177cae23221"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop(dependent, axis=1), \n",
        "                                                    df[dependent], \n",
        "                                                    test_size=0.25, \n",
        "                                                    shuffle=True)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(561, 4) (187, 4) (561,) (187,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E_ATNJdqTCuZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 2.1 — Make a pipeline\n",
        "\n",
        "Make a **pipeline** which includes:\n",
        "- Preprocessing with any scikit-learn [**Scaler**](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)\n",
        "- Feature selection with **[`SelectKBest`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)([`f_classif`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html))**\n",
        "- Classification with [**`LogisticRegression`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
      ]
    },
    {
      "metadata": {
        "id": "8DRrVU5n5_Jw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define an estimator and param_grid\n",
        "pipe = Pipeline(steps=[\n",
        "    ('scale', RobustScaler()), \n",
        "    ('reduce_dim', SelectKBest(f_classif)), \n",
        "    ('classify', LogisticRegression(solver='lbfgs'))])\n",
        "\n",
        "# pipe.fit(X_train,y_train)\n",
        "\n",
        "# sum(pipe.predict(X_test) == y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5vRkQHatglMG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 2.2 — Do Grid Search Cross-Validation\n",
        "\n",
        "Do [**GridSearchCV**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) with your pipeline. Use **5 folds** and **recall score**.\n",
        "\n",
        "Include these **parameters for your grid:**\n",
        "\n",
        "#### `SelectKBest`\n",
        "- `k : 1, 2, 3, 4`\n",
        "\n",
        "#### `LogisticRegression`\n",
        "- `class_weight : None, 'balanced'`\n",
        "- `C : .0001, .001, .01, .1, 1.0, 10.0, 100.00, 1000.0, 10000.0`\n",
        "\n",
        "\n",
        "**Fit** on the appropriate data."
      ]
    },
    {
      "metadata": {
        "id": "wgN8kG0ogBMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "b64d08d7-307c-4e4a-f462-0031499c0c9d"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "pg = {\n",
        "    'reduce_dim__k': range(1,5),\n",
        "    'classify__class_weight': ['None', 'Balanced'],\n",
        "    'classify__C': [10**k for k in range(-4, 5)]\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(pipe, param_grid=pg, cv=5, scoring='recall', \n",
        "                  verbose=10, n_jobs=-1, return_train_score=True, iid=True)\n",
        "# i'm on GPU\n",
        "gs.fit(X_train, y_train)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0255s.) Setting batch_size=14.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done 242 tasks      | elapsed:    1.6s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 424 ms, sys: 5.46 ms, total: 430 ms\n",
            "Wall time: 2.29 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:    2.3s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "W1_0mNW08l8o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "urY_Wp3AiF83",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 3 — Show best score and parameters\n",
        "\n",
        "Display your **best cross-validation score**, and the **best parameters** (the values of `k, class_weight, C`) from the grid search.\n",
        "\n",
        "(You're not evaluated here on how good your score is, or which parameters you find. You're only evaluated on being able to display the information. There are several ways you can get the information, and any way is acceptable.)"
      ]
    },
    {
      "metadata": {
        "id": "qAxxkjG7gACP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "2847698f-f7bb-4a43-c7ac-35b24a9622ab"
      },
      "cell_type": "code",
      "source": [
        "print(gs.best_estimator_)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pipeline(memory=None,\n",
            "     steps=[('scale', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
            "       with_scaling=True)), ('reduce_dim', SelectKBest(k=3, score_func=<function f_classif at 0x7f6e936807b8>)), ('classify', LogisticRegression(C=10, class_weight='None', dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
            "          tol=0.0001, verbose=0, warm_start=False))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k2eyrpro-R1b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "a68257f1-7b2f-42eb-a16c-dd8ecc97f3a8"
      },
      "cell_type": "code",
      "source": [
        "best_k = 3\n",
        "best_classweight = 'None'\n",
        "best_C = 10\n",
        "\n",
        "report3 = f'According to my 5-fold gridsearch: \\n\\tthe best number of ' + \\\n",
        "          f'features to select is {best_k}\\n\\tthe best class-weighing ' + \\\n",
        "          f'is {best_classweight}\\n\\tthe best regularization ' +\\\n",
        "          f'strength is {best_C}' \n",
        "\n",
        "print(report3)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "According to my 5-fold gridsearch: \n",
            "\tthe best number of features to select is 3\n",
            "\tthe best class-weighing is None\n",
            "\tthe best regularization strength is 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jkyHoRIbEgRR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 4 — Calculate classification metrics from a confusion matrix\n",
        "\n",
        "Suppose this is the confusion matrix for your binary classification model:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th colspan=\"2\" rowspan=\"2\"></th>\n",
        "    <th colspan=\"2\">Predicted</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <th>Negative</th>\n",
        "    <th>Positive</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <th rowspan=\"2\">Actual</th>\n",
        "    <th>Negative</th>\n",
        "    <td>85</td>\n",
        "    <td>58</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <th>Positive</th>\n",
        "    <td>8</td>\n",
        "    <td>36</td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "LhyMM5H-JpVB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate accuracy"
      ]
    },
    {
      "metadata": {
        "id": "TZPwqdh2KUcB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "7596c610-a471-4918-cbdd-1527aa541802"
      },
      "cell_type": "code",
      "source": [
        "def confusionmatrix(model=gs.best_estimator_, dat=X_test, target=y_test):\n",
        "#   rows = pd.MultiIndex.from_product([['Actual', 'Predicted'],\n",
        "#                                      ['Negative', 'Positive']])\n",
        "  seconds = ['Negative', 'Positive']\n",
        "  firsts = ['Actual', 'Predicted']\n",
        "  \n",
        "  print(\"at an implicit decision rule of 0.5, i.e., if model(dat)>=0.5 then model(dat)=1\")\n",
        "  \n",
        "  def tupdex(first): \n",
        "    return [first + ' ' + seconds[0], first + ' ' + seconds[1]]\n",
        "  \n",
        "  c = np.empty((2,2))\n",
        "  \n",
        "  def fill(i,j): \n",
        "    val = sum([x==i and y==j for x,y in zip(target, model.predict(dat))])\n",
        "    c[i][j] = val\n",
        "    pass\n",
        "  fill(0,0)\n",
        "  fill(0,1)\n",
        "  fill(1,0)\n",
        "  fill(1,1)\n",
        "  df = pd.DataFrame(c, index=tupdex(firsts[0]), columns=tupdex(firsts[1]))\n",
        "  return df\n",
        "\n",
        "pipe1_cm = confusionmatrix(gs.best_estimator_)\n",
        "\n",
        "pipe1_cm"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "at an implicit decision rule of 0.5, i.e., if model(dat)>=0.5 then model(dat)=1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Negative</th>\n",
              "      <th>Predicted Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual Negative</th>\n",
              "      <td>134.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual Positive</th>\n",
              "      <td>45.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Predicted Negative  Predicted Positive\n",
              "Actual Negative               134.0                 3.0\n",
              "Actual Positive                45.0                 5.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "metadata": {
        "id": "BRWLfGcGKeQw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate precision"
      ]
    },
    {
      "metadata": {
        "id": "A-FEZ4i_Kf_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "accbe4e9-fbe9-4fb4-d966-9cbde94d7cdc"
      },
      "cell_type": "code",
      "source": [
        "def precision(cm=confusionmatrix()): \n",
        "  TP = cm['Predicted Positive'].loc['Actual Positive']\n",
        "  PP = cm['Predicted Positive'].sum()\n",
        "  return np.divide(TP, PP)\n",
        "\n",
        "precision()"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "at an implicit decision rule of 0.5, i.e., if model(dat)>=0.5 then model(dat)=1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "metadata": {
        "id": "h_mH2NYDKi2C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate recall"
      ]
    },
    {
      "metadata": {
        "id": "U4_wJGyjKkXJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0cf5e293-5740-477c-e2a3-316b4f132483"
      },
      "cell_type": "code",
      "source": [
        "def recall(cm=confusionmatrix()): \n",
        "  TP = cm['Predicted Positive'].loc['Actual Positive']\n",
        "  AP = cm.loc['Actual Positive'].sum()\n",
        "  return np.divide(TP, AP)\n",
        "\n",
        "recall()\n",
        "\n",
        "def F1(cm=confusionmatrix()): \n",
        "  prec = precision(cm)\n",
        "  reca = recall(cm)\n",
        "  return 2 * np.divide(prec * reca, prec + reca)\n",
        "\n",
        "def typeI(cm=confusionmatrix()):\n",
        "  return cm['Predicted Positive'].loc['Actual Negative']"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "at an implicit decision rule of 0.5, i.e., if model(dat)>=0.5 then model(dat)=1\n",
            "at an implicit decision rule of 0.5, i.e., if model(dat)>=0.5 then model(dat)=1\n",
            "at an implicit decision rule of 0.5, i.e., if model(dat)>=0.5 then model(dat)=1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l5vVS8JqKUHA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "48a66152-e85c-4ca3-f4c1-d5c2a86ded10"
      },
      "cell_type": "code",
      "source": [
        "def confusion_report(cm=confusionmatrix()):\n",
        "  s1 = f'this model got a precision score of {precision(cm):.3}\\n'\n",
        "  s2 = f'a recall score of {recall(cm):.3}\\n'\n",
        "  s3 = f'an F1 score of {F1(cm):.3}\\n'\n",
        "  s4 = f'and {int(typeI(cm))} Type I errors'\n",
        "  return s1+s2+s3+s4\n",
        "\n",
        "initial_pipeline_performance = (report3, confusion_report(pipe1_cm), pipe1_cm)\n",
        "\n",
        "print(initial_pipeline_performance[0])\n",
        "print(initial_pipeline_performance[1])\n",
        "initial_pipeline_performance[2]"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "at an implicit decision rule of 0.5, i.e., if model(dat)>=0.5 then model(dat)=1\n",
            "According to my 5-fold gridsearch: \n",
            "\tthe best number of features to select is 3\n",
            "\tthe best class-weighing is None\n",
            "\tthe best regularization strength is 10\n",
            "this model got a precision score of 0.625\n",
            "a recall score of 0.1\n",
            "an F1 score of 0.172\n",
            "and 3 Type I errors\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Negative</th>\n",
              "      <th>Predicted Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual Negative</th>\n",
              "      <td>134.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual Positive</th>\n",
              "      <td>45.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Predicted Negative  Predicted Positive\n",
              "Actual Negative               134.0                 3.0\n",
              "Actual Positive                45.0                 5.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "metadata": {
        "id": "9KEaWsk5Kk9W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## BONUS — How you can earn a score of 3\n",
        "\n",
        "### Part 1\n",
        "Do feature engineering, to try improving your cross-validation score.\n",
        "\n",
        "### Part 2\n",
        "Add transformations in your pipeline and parameters in your grid, to try improving your cross-validation score.\n",
        "\n",
        "### Part 3\n",
        "Show names of selected features. Then do a final evaluation on the test set — what is the test score?\n",
        "\n",
        "### Part 4\n",
        "Calculate F1 score and False Positive Rate. "
      ]
    },
    {
      "metadata": {
        "id": "QA2s12fYO-Pa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "998ce463-9dd1-4a5c-d7d6-da7e925741c2"
      },
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "\n",
        "X = df.drop(dependent, axis=1)\n",
        "y = df[dependent]\n",
        "\n",
        "poly = PolynomialFeatures(degree=4)\n",
        "poly.fit(X)\n",
        "X_poly = pd.DataFrame(poly.transform(X), columns=poly.get_feature_names(X.columns))\n",
        "\n",
        "print(X_poly.shape)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_poly, \n",
        "                                                    y, \n",
        "                                                    test_size=0.25, \n",
        "                                                    shuffle=True)\n",
        "print(X_train2.shape, X_test2.shape, y_train2.shape, y_test2.shape)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(748, 70)\n",
            "(561, 70) (187, 70) (561,) (187,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fMzimVQYL5w_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d919720f-e7ce-444c-d48b-35e0ef30814f"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# i pick 17 as my number by whihc I want observations to outnumber features: \n",
        "B = int(np.divide(X_poly.shape[0], 17))\n",
        "\n",
        "# Define an estimator and param_grid\n",
        "pipe2 = Pipeline(steps=[\n",
        "    ('scale', StandardScaler()), \n",
        "    ('reduce_dim', SelectKBest(f_classif)), \n",
        "    ('classify', LogisticRegression(solver='lbfgs', max_iter=12345))])\n",
        "\n",
        "pg2 = {\n",
        "    'reduce_dim__k': range(B//3,B, 2),\n",
        "    'classify__class_weight': ['None', 'Balanced'],\n",
        "    'classify__C': [10**k for k in range(-4, 5)]\n",
        "}\n",
        "\n",
        "gs2 = GridSearchCV(pipe2, param_grid=pg2, cv=15, scoring='recall', \n",
        "                  verbose=4, n_jobs=-1, return_train_score=True, iid=True)\n",
        "# i'm on GPU\n",
        "gs2.fit(X_train2, y_train2)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 15 folds for each of 270 candidates, totalling 4050 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    3.9s\n",
            "[Parallel(n_jobs=-1)]: Done 1084 tasks      | elapsed:   21.4s\n",
            "[Parallel(n_jobs=-1)]: Done 2284 tasks      | elapsed:   56.9s\n",
            "[Parallel(n_jobs=-1)]: Done 2863 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=-1)]: Done 3226 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=-1)]: Done 3558 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=-1)]: Done 3965 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=-1)]: Done 4050 out of 4050 | elapsed:  7.7min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [0] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 13.5 s, sys: 986 ms, total: 14.5 s\n",
            "Wall time: 7min 45s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "942tPXf7RutE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "9fe9ee1e-8ac5-48f4-ebaf-2352202471c0"
      },
      "cell_type": "code",
      "source": [
        "gs2.best_estimator_"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "     steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('reduce_dim', SelectKBest(k=38, score_func=<function f_classif at 0x7f6e936807b8>)), ('classify', LogisticRegression(C=10000, class_weight='None', dual=False,\n",
              "          fit_intercept=True, intercept_scaling=1, max_iter=12345,\n",
              "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
              "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "metadata": {
        "id": "JQjjBeGXL51R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "efa9bd82-b0d2-4d16-dcfb-235a9eb8aad0"
      },
      "cell_type": "code",
      "source": [
        "best_k_2 = 38\n",
        "best_classweight_2 = 'None'\n",
        "best_C_2 = 10000\n",
        "\n",
        "report32 = f'According to my 15-fold gridsearch after generating polynomial features of degree 4: \\n\\tthe best number of ' + \\\n",
        "          f'features to select is {best_k_2}\\n\\tthe best class-weighing ' + \\\n",
        "          f'is {best_classweight_2}\\n\\tthe best regularization ' +\\\n",
        "          f'strength is {best_C_2}' \n",
        "\n",
        "\n",
        "pipe2_cm = confusionmatrix(gs2.best_estimator_, dat=X_test2, target=y_test2)\n",
        "\n",
        "\n",
        "second_pipeline_performance = (report32, confusion_report(pipe2_cm), pipe2_cm)\n",
        "\n",
        "print(second_pipeline_performance[0])\n",
        "print(second_pipeline_performance[1])\n",
        "second_pipeline_performance[2]"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "at an implicit decision rule of 0.5, i.e., if model(dat)>=0.5 then model(dat)=1\n",
            "According to my 15-fold gridsearch after generating polynomial features of degree 4: \n",
            "\tthe best number of features to select is 38\n",
            "\tthe best class-weighing is None\n",
            "\tthe best regularization strength is 10000\n",
            "this model got a precision score of 0.5\n",
            "a recall score of 0.278\n",
            "an F1 score of 0.357\n",
            "and 10 Type I errors\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Negative</th>\n",
              "      <th>Predicted Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual Negative</th>\n",
              "      <td>141.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual Positive</th>\n",
              "      <td>26.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Predicted Negative  Predicted Positive\n",
              "Actual Negative               141.0                10.0\n",
              "Actual Positive                26.0                10.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "metadata": {
        "id": "Z6K-IqByS1BX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I ran it at `cv=5` and got an improvement. \n",
        "It took under 2 minutes, so I knew setting `cv=15` would take no more than 6 minutes. To be sure, i reduced the amount of \"best ks\" it would try. \n",
        "\n",
        "My hypothesis is that higher cv makes it slightly better. \n",
        "\n",
        "# At cv=5\n",
        "- Precision went up from 2/3 to 0.741 --- an improvement! \n",
        "- recall went up from 0.095 to 0.377 --- an improvement! \n",
        "- F1 went up from 0.167 to 0.377 --- and improvement! \n",
        "- we got more false-positives, up from 2 to 7, tho. \n",
        "\n",
        "\n",
        "# at cv=15\n",
        "- precision is worse than `cv=5` (0.5)\n",
        "- recall is worse (0.278)\n",
        "- f1 score slightly worst (0.357)\n",
        "- more type1 errors, up to 10. \n",
        "\n",
        "Should have kept it at `cv=5`!"
      ]
    }
  ]
}