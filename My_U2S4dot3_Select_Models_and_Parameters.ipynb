{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "My_U2S4dot3_Select_Models_and_Parameters.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wel51x/DS-Unit-2-Sprint-4-Model-Validation/blob/master/My_U2S4dot3_Select_Models_and_Parameters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O67uhlT4MExK",
        "colab_type": "text"
      },
      "source": [
        "_Lambda School Data Science — Model Validation_\n",
        "\n",
        "# Select models and parameters\n",
        "\n",
        "Objectives\n",
        "- Hyperparameter optimization\n",
        "- Model selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE4rfZd4NUGA",
        "colab_type": "text"
      },
      "source": [
        "Today we'll use this process:\n",
        "\n",
        "## \"A universal workflow of machine learning\"\n",
        "\n",
        "_Excerpt from Francois Chollet, [Deep Learning with Python](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/README.md), Chapter 4: Fundamentals of machine learning_\n",
        " \n",
        "**1. Define the problem at hand and the data on which you’ll train.** Collect this data, or annotate it with labels if need be.\n",
        "\n",
        "**2. Choose how you’ll measure success on your problem.** Which metrics will you monitor on your validation data?\n",
        "\n",
        "**3. Determine your evaluation protocol:** hold-out validation? K-fold validation? Which portion of the data should you use for validation?\n",
        "\n",
        "**4. Develop a first model that does better than a basic baseline:** a model with statistical power.\n",
        "\n",
        "**5. Develop a model that overfits.** The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\n",
        "\n",
        "**6. Regularize your model and tune its hyperparameters, based on performance on the validation data.** Repeatedly modify your model, train it, evaluate on your validation data (not the test data, at this point), modify it again, and repeat, until the model is as good as it can get. \n",
        "\n",
        "Iterate on feature engineering: add new features, or remove features that don’t seem to be informative. Once you’ve developed a satisfactory model configuration, you can train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kt6bzEcOIaa",
        "colab_type": "text"
      },
      "source": [
        "## 1. Define the problem at hand and the data on which you'll train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di16k7vpRg67",
        "colab_type": "text"
      },
      "source": [
        "We'll apply the workflow to a [project from _Python Data Science Handbook_](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic) by Jake VanderPlas:\n",
        "\n",
        "> **Predicting Bicycle Traffic**\n",
        "\n",
        "> As an example, let's take a look at whether we can predict the number of bicycle trips across Seattle's Fremont Bridge based on weather, season, and other factors.\n",
        "\n",
        "> We will join the bike data with another dataset, and try to determine the extent to which weather and seasonal factors—temperature, precipitation, and daylight hours—affect the volume of bicycle traffic through this corridor. Fortunately, the NOAA makes available their daily [weather station data](http://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND) (I used station ID USW00024233) and we can easily use Pandas to join the two data sources.\n",
        "\n",
        "> Let's start by loading the two datasets, indexing by date:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19dpb_d0R1A6",
        "colab_type": "text"
      },
      "source": [
        "So this is a regression problem, not a classification problem. We'll define the target, choose an evaluation metric, and choose models that are appropriate for regression problems.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os1zruXQ30KM",
        "colab_type": "text"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XVu-HSeMDtV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "4fcf6cdc-d2c2-4c74-b263-d4ff0f34d939"
      },
      "source": [
        "!curl -o FremontBridge.csv https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1679k    0 1679k    0     0  1279k      0 --:--:--  0:00:01 --:--:-- 1278k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sih_7mTzMdfr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "cd053383-1d77-42a2-bd0a-14ab25358192"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-04 06:08:07--  https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 234945 (229K) [text/plain]\n",
            "Saving to: ‘BicycleWeather.csv’\n",
            "\n",
            "\rBicycleWeather.csv    0%[                    ]       0  --.-KB/s               \rBicycleWeather.csv  100%[===================>] 229.44K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-08-04 06:08:07 (4.48 MB/s) - ‘BicycleWeather.csv’ saved [234945/234945]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GYm74kD34OQ",
        "colab_type": "text"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfQ7gE28MNdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modified from cells 15, 16, and 20, at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "counts = pd.read_csv('FremontBridge.csv', index_col='Date', parse_dates=True, \n",
        "                     infer_datetime_format=True)\n",
        "\n",
        "weather = pd.read_csv('BicycleWeather.csv', index_col='DATE', parse_dates=True, \n",
        "                      infer_datetime_format=False)\n",
        "\n",
        "daily = counts.resample('d').sum()\n",
        "daily['Total'] = daily.sum(axis=1)\n",
        "daily = daily[['Total']] # remove other columns\n",
        "\n",
        "weather_columns = ['PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND']\n",
        "daily = daily.join(weather[weather_columns], how='inner')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0YYD6rvypb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a feature for yesterday's total\n",
        "daily['Total_yesterday'] = daily.Total.shift(1)\n",
        "\n",
        "daily = daily.drop(index=daily.index[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVB3g4704An5",
        "colab_type": "text"
      },
      "source": [
        "### First fast look at the data\n",
        "- What's the shape?\n",
        "- What's the date range?\n",
        "- What's the target and the features?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t50E2fTUWBBU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "910e7bf4-dbc6-4b32-929a-4c8e213c8c44"
      },
      "source": [
        "# TODO\n",
        "print(daily.shape)\n",
        "daily.sample(8)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1063, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-11-13</th>\n",
              "      <td>3067.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>139</td>\n",
              "      <td>106</td>\n",
              "      <td>38</td>\n",
              "      <td>2416.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-09-26</th>\n",
              "      <td>3613.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>72</td>\n",
              "      <td>22</td>\n",
              "      <td>3102.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-03-05</th>\n",
              "      <td>2398.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>94</td>\n",
              "      <td>61</td>\n",
              "      <td>24</td>\n",
              "      <td>2791.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-03-13</th>\n",
              "      <td>3313.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>139</td>\n",
              "      <td>50</td>\n",
              "      <td>25</td>\n",
              "      <td>3665.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-03-29</th>\n",
              "      <td>571.0</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>117</td>\n",
              "      <td>72</td>\n",
              "      <td>51</td>\n",
              "      <td>1525.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-05-05</th>\n",
              "      <td>3301.0</td>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>156</td>\n",
              "      <td>94</td>\n",
              "      <td>38</td>\n",
              "      <td>620.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-19</th>\n",
              "      <td>1977.0</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>94</td>\n",
              "      <td>53</td>\n",
              "      <td>2923.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-05-11</th>\n",
              "      <td>2376.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>189</td>\n",
              "      <td>83</td>\n",
              "      <td>17</td>\n",
              "      <td>1725.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Total  PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
              "2013-11-13  3067.0     0     0     0   139   106    38           2416.0\n",
              "2013-09-26  3613.0     0     0     0   172    72    22           3102.0\n",
              "2013-03-05  2398.0     0     0     0    94    61    24           2791.0\n",
              "2014-03-13  3313.0     5     0     0   139    50    25           3665.0\n",
              "2014-03-29   571.0   140     0     0   117    72    51           1525.0\n",
              "2014-05-05  3301.0    51     0     0   156    94    38            620.0\n",
              "2012-10-19  1977.0    48     0     0   150    94    53           2923.0\n",
              "2014-05-11  2376.0     0     0     0   189    83    17           1725.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgMvCsaWJR7Q",
        "colab_type": "text"
      },
      "source": [
        "Target\n",
        "- Total : Daily total number of bicycle trips across Seattle's Fremont Bridge\n",
        "\n",
        "Features\n",
        "- Date (index) : from 2012-10-04 to 2015-09-01\n",
        "- Total_yesterday : Total trips yesterday\n",
        "- PRCP : Precipitation (1/10 mm)\n",
        "- SNOW : Snowfall (1/10 mm)\n",
        "- SNWD : Snow depth (1/10 mm)\n",
        "- TMAX : Maximum temperature (1/10 Celsius)\n",
        "- TMIN : Minimum temperature (1/10 Celsius)\n",
        "- AWND : Average daily wind speed (1/10 meters per second)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lenL-przSYCo",
        "colab_type": "text"
      },
      "source": [
        "## 2. Choose how you’ll measure success on your problem.\n",
        "\n",
        "Which metrics will you monitor on your validation data?\n",
        "\n",
        "This is a regression problem, so we need to choose a regression [metric](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values).\n",
        "\n",
        "\n",
        "\n",
        "I'll choose mean absolute error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TqbomapSyRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO\n",
        "from sklearn.metrics import mean_absolute_error  # could import mean_square_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRHrB3rsS5hF",
        "colab_type": "text"
      },
      "source": [
        "## 3. Determine your evaluation protocol \n",
        "\n",
        "We're doing model selection, hyperparameter optimization, and performance estimation. So generally we have two ideal [options](https://sebastianraschka.com/images/blog/2018/model-evaluation-selection-part4/model-eval-conclusions.jpg) to choose from:\n",
        "\n",
        "- 3-way holdout method (train/validation/test split)\n",
        "- Cross-validation with independent test set\n",
        "\n",
        "I'll choose cross-validation with independent test set. Scikit-learn makes cross-validation convenient for us!\n",
        "\n",
        "Specifically, I will use random shuffled cross validation to train and validate, but I will hold out an \"out-of-time\" test set, from the last 100 days of data:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3xo6HgbPMFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8ae97ff-b690-4a93-a704-f76d5e96401a"
      },
      "source": [
        "# TODO\n",
        "train = daily[:-100]\n",
        "test = daily[-100:]\n",
        "train.shape, test.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((963, 8), (100, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8-ntrs0Qjdc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "860081a0-a994-47cd-bf76-66f71e2dab9e"
      },
      "source": [
        "X_train = train.drop(columns='Total')\n",
        "y_train = train['Total']\n",
        "\n",
        "X_test = test.drop(columns='Total')\n",
        "y_test = test['Total']\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((963, 7), (963,), (100, 7), (100,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH6IsORQTvTU",
        "colab_type": "text"
      },
      "source": [
        "## 4. Develop a first model that does better than a basic baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJBs2nQkj7oB",
        "colab_type": "text"
      },
      "source": [
        "### Look at the target's distribution and descriptive stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5peakv9Zs71",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "7d8dd591-9b02-4e59-9c47-8588d414d995"
      },
      "source": [
        "# TODO\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.distplot(y_train);"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUCoUIiIS1P8Hd41s336jLrkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RedBdg_nQ0Sv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "8914f40c-3a87-4725-d76b-98810e7751f5"
      },
      "source": [
        "y_train.describe()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     963.000000\n",
              "mean     2534.329180\n",
              "std      1224.065027\n",
              "min        98.000000\n",
              "25%      1755.000000\n",
              "50%      2381.000000\n",
              "75%      3317.500000\n",
              "max      6088.000000\n",
              "Name: Total, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEjxxgV9kExY",
        "colab_type": "text"
      },
      "source": [
        "### Basic baseline 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GepKdQjYcEP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c47ecaa8-e99d-41a6-e945-737693a1208a"
      },
      "source": [
        "# TODO\n",
        "y_pred = [y_train.mean()] * len(y_train)\n",
        "mean_absolute_error(y_train, y_pred)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "980.8981106765484"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN2I_F3FkIHb",
        "colab_type": "text"
      },
      "source": [
        "### Basic baseline 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW8bhZFtTunV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "007ebc8b-656f-41b0-89a6-57150f0e33c0"
      },
      "source": [
        "# TODO\n",
        "y_pred = X_train['Total_yesterday']\n",
        "mean_absolute_error(y_train, y_pred)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "708.061266874351"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MejJrLixRDCt",
        "colab_type": "text"
      },
      "source": [
        "==>> bit of an improvement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggf3VpxwkJ0T",
        "colab_type": "text"
      },
      "source": [
        "### First model that does better than a basic baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfaqL1Ezer2-",
        "colab_type": "text"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeBtU68skfW-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "0f49c175-b261-4f2f-fe62-1123a8f71a2b"
      },
      "source": [
        "# TODO\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "scores = cross_validate(LinearRegression(), X_train, y_train, \n",
        "                        scoring='neg_mean_absolute_error', cv=3, # neg 'cause of scikit kludge'\n",
        "                        return_train_score=True, return_estimator=True)\n",
        "pd.set_option('max_colwidth', 46)\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.006372</td>\n",
              "      <td>0.002695</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercep...</td>\n",
              "      <td>-555.186275</td>\n",
              "      <td>-619.509206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.003700</td>\n",
              "      <td>0.001628</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercep...</td>\n",
              "      <td>-651.126513</td>\n",
              "      <td>-583.427702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002870</td>\n",
              "      <td>0.001179</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercep...</td>\n",
              "      <td>-615.965800</td>\n",
              "      <td>-589.341301</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time  ...  test_score  train_score\n",
              "0  0.006372    0.002695  ... -555.186275  -619.509206\n",
              "1  0.003700    0.001628  ... -651.126513  -583.427702\n",
              "2  0.002870    0.001179  ... -615.965800  -589.341301\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2P8732NROdi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da7fdc97-9e22-4119-cd31-ea4e464ba0a2"
      },
      "source": [
        "scores['test_score'].mean()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-607.4261958631806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VMMl_9xRpCF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "eb0b9d8a-4596-4c12-f40a-3a51559a9d49"
      },
      "source": [
        "for i, model in enumerate(scores['estimator']):\n",
        "    coefficients = model.coef_\n",
        "    intercept = model.intercept_\n",
        "    feature_names = X_train.columns\n",
        "    \n",
        "    print('Model from cross-validaton fold #', i)\n",
        "    print('Intercept', intercept)\n",
        "    print(pd.Series(coefficients, feature_names).to_string())\n",
        "    print('\\n')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model from cross-validaton fold # 0\n",
            "Intercept 566.7766337283679\n",
            "PRCP               -3.525103\n",
            "SNOW               -0.082029\n",
            "SNWD              -12.045027\n",
            "TMAX                9.475238\n",
            "TMIN               -4.607775\n",
            "AWND               -2.745191\n",
            "Total_yesterday     0.417360\n",
            "\n",
            "\n",
            "Model from cross-validaton fold # 1\n",
            "Intercept 671.9064515706045\n",
            "PRCP               -2.772253\n",
            "SNOW               -0.000995\n",
            "SNWD               20.800688\n",
            "TMAX                8.804948\n",
            "TMIN               -3.741386\n",
            "AWND               -6.108300\n",
            "Total_yesterday     0.405074\n",
            "\n",
            "\n",
            "Model from cross-validaton fold # 2\n",
            "Intercept 465.84525362296563\n",
            "PRCP               -2.876196\n",
            "SNOW               -0.016432\n",
            "SNWD               -8.809696\n",
            "TMAX               10.419441\n",
            "TMIN               -5.862868\n",
            "AWND               -2.398991\n",
            "Total_yesterday     0.423493\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8ecyGffRz4D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "outputId": "9c49d0f4-4b4b-4748-f747-7fefd4ef10b7"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "model = sm.OLS(y_train, sm.add_constant(X_train))\n",
        "model.fit().summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
            "  return ptp(axis=axis, out=out, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>          <td>Total</td>      <th>  R-squared:         </th> <td>   0.628</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.625</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   230.2</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sun, 04 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>4.80e-200</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>06:18:24</td>     <th>  Log-Likelihood:    </th> <td> -7736.8</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   963</td>      <th>  AIC:               </th> <td>1.549e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   955</td>      <th>  BIC:               </th> <td>1.553e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>           <td>  571.7691</td> <td>   93.165</td> <td>    6.137</td> <td> 0.000</td> <td>  388.937</td> <td>  754.601</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>PRCP</th>            <td>   -3.0616</td> <td>    0.396</td> <td>   -7.726</td> <td> 0.000</td> <td>   -3.839</td> <td>   -2.284</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>SNOW</th>            <td>   -0.0271</td> <td>    0.038</td> <td>   -0.721</td> <td> 0.471</td> <td>   -0.101</td> <td>    0.047</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>SNWD</th>            <td>   -9.1379</td> <td>    8.974</td> <td>   -1.018</td> <td> 0.309</td> <td>  -26.748</td> <td>    8.472</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>TMAX</th>            <td>    9.4823</td> <td>    0.774</td> <td>   12.258</td> <td> 0.000</td> <td>    7.964</td> <td>   11.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>TMIN</th>            <td>   -4.6742</td> <td>    1.026</td> <td>   -4.555</td> <td> 0.000</td> <td>   -6.688</td> <td>   -2.660</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>AWND</th>            <td>   -3.7006</td> <td>    1.747</td> <td>   -2.119</td> <td> 0.034</td> <td>   -7.128</td> <td>   -0.273</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total_yesterday</th> <td>    0.4165</td> <td>    0.025</td> <td>   16.460</td> <td> 0.000</td> <td>    0.367</td> <td>    0.466</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 6.601</td> <th>  Durbin-Watson:     </th> <td>   1.571</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.037</td> <th>  Jarque-Bera (JB):  </th> <td>   6.648</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.187</td> <th>  Prob(JB):          </th> <td>  0.0360</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.841</td> <th>  Cond. No.          </th> <td>1.09e+04</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.09e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                  Total   R-squared:                       0.628\n",
              "Model:                            OLS   Adj. R-squared:                  0.625\n",
              "Method:                 Least Squares   F-statistic:                     230.2\n",
              "Date:                Sun, 04 Aug 2019   Prob (F-statistic):          4.80e-200\n",
              "Time:                        06:18:24   Log-Likelihood:                -7736.8\n",
              "No. Observations:                 963   AIC:                         1.549e+04\n",
              "Df Residuals:                     955   BIC:                         1.553e+04\n",
              "Df Model:                           7                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "===================================================================================\n",
              "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
              "-----------------------------------------------------------------------------------\n",
              "const             571.7691     93.165      6.137      0.000     388.937     754.601\n",
              "PRCP               -3.0616      0.396     -7.726      0.000      -3.839      -2.284\n",
              "SNOW               -0.0271      0.038     -0.721      0.471      -0.101       0.047\n",
              "SNWD               -9.1379      8.974     -1.018      0.309     -26.748       8.472\n",
              "TMAX                9.4823      0.774     12.258      0.000       7.964      11.000\n",
              "TMIN               -4.6742      1.026     -4.555      0.000      -6.688      -2.660\n",
              "AWND               -3.7006      1.747     -2.119      0.034      -7.128      -0.273\n",
              "Total_yesterday     0.4165      0.025     16.460      0.000       0.367       0.466\n",
              "==============================================================================\n",
              "Omnibus:                        6.601   Durbin-Watson:                   1.571\n",
              "Prob(Omnibus):                  0.037   Jarque-Bera (JB):                6.648\n",
              "Skew:                          -0.187   Prob(JB):                       0.0360\n",
              "Kurtosis:                       2.841   Cond. No.                     1.09e+04\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 1.09e+04. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c5fwGs8R4R2",
        "colab_type": "text"
      },
      "source": [
        "==>> appears to be underfit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg1YI4X8n9nI",
        "colab_type": "text"
      },
      "source": [
        "## 5. Develop a model that overfits. \n",
        "\n",
        "\"The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\" —Chollet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lodd6UPOoy89",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://jakevdp.github.io/PythonDataScienceHandbook/figures/05.03-validation-curve.png\">\n",
        "\n",
        "Diagram source: https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrmQ3RM0w2JE",
        "colab_type": "text"
      },
      "source": [
        "### Polynomial Regression?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uctwo0X3pTw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copied from cell 10 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "def PolynomialRegression(degree=2, **kwargs):\n",
        "    return make_pipeline(PolynomialFeatures(degree),\n",
        "                         LinearRegression(**kwargs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvY4HOXVw7Mj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "8529d17a-c507-44c3-ad40-4055851f818c"
      },
      "source": [
        "for degree in [0, 1, 2, 3]:\n",
        "    features = PolynomialFeatures(degree).fit(X_train).get_feature_names(X_train.columns)\n",
        "    print(f'{degree} degree polynomial has {len(features)} features')\n",
        "    print(features)\n",
        "    print('\\n')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 degree polynomial has 1 features\n",
            "['1']\n",
            "\n",
            "\n",
            "1 degree polynomial has 8 features\n",
            "['1', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND', 'Total_yesterday']\n",
            "\n",
            "\n",
            "2 degree polynomial has 36 features\n",
            "['1', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND', 'Total_yesterday', 'PRCP^2', 'PRCP SNOW', 'PRCP SNWD', 'PRCP TMAX', 'PRCP TMIN', 'PRCP AWND', 'PRCP Total_yesterday', 'SNOW^2', 'SNOW SNWD', 'SNOW TMAX', 'SNOW TMIN', 'SNOW AWND', 'SNOW Total_yesterday', 'SNWD^2', 'SNWD TMAX', 'SNWD TMIN', 'SNWD AWND', 'SNWD Total_yesterday', 'TMAX^2', 'TMAX TMIN', 'TMAX AWND', 'TMAX Total_yesterday', 'TMIN^2', 'TMIN AWND', 'TMIN Total_yesterday', 'AWND^2', 'AWND Total_yesterday', 'Total_yesterday^2']\n",
            "\n",
            "\n",
            "3 degree polynomial has 120 features\n",
            "['1', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND', 'Total_yesterday', 'PRCP^2', 'PRCP SNOW', 'PRCP SNWD', 'PRCP TMAX', 'PRCP TMIN', 'PRCP AWND', 'PRCP Total_yesterday', 'SNOW^2', 'SNOW SNWD', 'SNOW TMAX', 'SNOW TMIN', 'SNOW AWND', 'SNOW Total_yesterday', 'SNWD^2', 'SNWD TMAX', 'SNWD TMIN', 'SNWD AWND', 'SNWD Total_yesterday', 'TMAX^2', 'TMAX TMIN', 'TMAX AWND', 'TMAX Total_yesterday', 'TMIN^2', 'TMIN AWND', 'TMIN Total_yesterday', 'AWND^2', 'AWND Total_yesterday', 'Total_yesterday^2', 'PRCP^3', 'PRCP^2 SNOW', 'PRCP^2 SNWD', 'PRCP^2 TMAX', 'PRCP^2 TMIN', 'PRCP^2 AWND', 'PRCP^2 Total_yesterday', 'PRCP SNOW^2', 'PRCP SNOW SNWD', 'PRCP SNOW TMAX', 'PRCP SNOW TMIN', 'PRCP SNOW AWND', 'PRCP SNOW Total_yesterday', 'PRCP SNWD^2', 'PRCP SNWD TMAX', 'PRCP SNWD TMIN', 'PRCP SNWD AWND', 'PRCP SNWD Total_yesterday', 'PRCP TMAX^2', 'PRCP TMAX TMIN', 'PRCP TMAX AWND', 'PRCP TMAX Total_yesterday', 'PRCP TMIN^2', 'PRCP TMIN AWND', 'PRCP TMIN Total_yesterday', 'PRCP AWND^2', 'PRCP AWND Total_yesterday', 'PRCP Total_yesterday^2', 'SNOW^3', 'SNOW^2 SNWD', 'SNOW^2 TMAX', 'SNOW^2 TMIN', 'SNOW^2 AWND', 'SNOW^2 Total_yesterday', 'SNOW SNWD^2', 'SNOW SNWD TMAX', 'SNOW SNWD TMIN', 'SNOW SNWD AWND', 'SNOW SNWD Total_yesterday', 'SNOW TMAX^2', 'SNOW TMAX TMIN', 'SNOW TMAX AWND', 'SNOW TMAX Total_yesterday', 'SNOW TMIN^2', 'SNOW TMIN AWND', 'SNOW TMIN Total_yesterday', 'SNOW AWND^2', 'SNOW AWND Total_yesterday', 'SNOW Total_yesterday^2', 'SNWD^3', 'SNWD^2 TMAX', 'SNWD^2 TMIN', 'SNWD^2 AWND', 'SNWD^2 Total_yesterday', 'SNWD TMAX^2', 'SNWD TMAX TMIN', 'SNWD TMAX AWND', 'SNWD TMAX Total_yesterday', 'SNWD TMIN^2', 'SNWD TMIN AWND', 'SNWD TMIN Total_yesterday', 'SNWD AWND^2', 'SNWD AWND Total_yesterday', 'SNWD Total_yesterday^2', 'TMAX^3', 'TMAX^2 TMIN', 'TMAX^2 AWND', 'TMAX^2 Total_yesterday', 'TMAX TMIN^2', 'TMAX TMIN AWND', 'TMAX TMIN Total_yesterday', 'TMAX AWND^2', 'TMAX AWND Total_yesterday', 'TMAX Total_yesterday^2', 'TMIN^3', 'TMIN^2 AWND', 'TMIN^2 Total_yesterday', 'TMIN AWND^2', 'TMIN AWND Total_yesterday', 'TMIN Total_yesterday^2', 'AWND^3', 'AWND^2 Total_yesterday', 'AWND Total_yesterday^2', 'Total_yesterday^3']\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEUdG9-ktHoa",
        "colab_type": "text"
      },
      "source": [
        "### Validation curve (with Polynomial Regression)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ryO1hVKr-6f",
        "colab_type": "text"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html\n",
        "\n",
        "> Validation curve. Determine training and test scores for varying parameter values. This is similar to grid search with one parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znJgKqPcqBh-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "b135ab49-0e35-4813-bce5-55e5cfba5470"
      },
      "source": [
        "# Modified from cell 13 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import validation_curve\n",
        "\n",
        "degree = [0, 1, 2]\n",
        "train_score, val_score = validation_curve(\n",
        "    PolynomialRegression(), X_train, y_train,\n",
        "    param_name='polynomialfeatures__degree', param_range=degree, \n",
        "    scoring='neg_mean_absolute_error', cv=3)\n",
        "plt.gcf().set_size_inches(10, 6)\n",
        "plt.plot(degree, np.median(train_score, 1), color='blue', label='training score')\n",
        "plt.plot(degree, np.median(val_score, 1), color='red', label='validation score')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('degree');"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAF3CAYAAAARh7eaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkvkP+zuyNudM4ogAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUdGHWhvtVnV",
        "colab_type": "text"
      },
      "source": [
        "### Grid Search (with Polynomial Regression)\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/grid_search.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GziXyq8Is6dL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "97bf21ac-81d1-419f-c33d-44372d87563f"
      },
      "source": [
        "# TODO\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'polynomialfeatures__degree': [0, 1, 2, 3]\n",
        "}\n",
        "\n",
        "gridsearch = GridSearchCV(PolynomialRegression(), param_grid=param_grid, \n",
        "                          scoring='neg_mean_absolute_error', cv=3, # 3 folds x 4 degrees = 12 outputs\n",
        "                          return_train_score=True, verbose=10)\n",
        "\n",
        "gridsearch.fit(X_train, y_train)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "[CV] polynomialfeatures__degree=0 ....................................\n",
            "[CV]  polynomialfeatures__degree=0, score=(train=-968.880, test=-1026.353), total=   0.0s\n",
            "[CV] polynomialfeatures__degree=0 ....................................\n",
            "[CV]  polynomialfeatures__degree=0, score=(train=-970.755, test=-1001.615), total=   0.0s\n",
            "[CV] polynomialfeatures__degree=0 ....................................\n",
            "[CV]  polynomialfeatures__degree=0, score=(train=-999.897, test=-927.071), total=   0.0s\n",
            "[CV] polynomialfeatures__degree=1 ....................................\n",
            "[CV]  polynomialfeatures__degree=1, score=(train=-619.509, test=-555.186), total=   0.0s\n",
            "[CV] polynomialfeatures__degree=1 ....................................\n",
            "[CV]  polynomialfeatures__degree=1, score=(train=-583.428, test=-651.127), total=   0.0s\n",
            "[CV] polynomialfeatures__degree=1 ....................................\n",
            "[CV]  polynomialfeatures__degree=1, score=(train=-589.341, test=-615.966), total=   0.0s\n",
            "[CV] polynomialfeatures__degree=2 ....................................\n",
            "[CV]  polynomialfeatures__degree=2, score=(train=-595.090, test=-7553.674), total=   0.0s\n",
            "[CV] polynomialfeatures__degree=2 ....................................\n",
            "[CV]  polynomialfeatures__degree=2, score=(train=-568.151, test=-1439.192), total=   0.0s\n",
            "[CV] polynomialfeatures__degree=2 ....................................\n",
            "[CV]  polynomialfeatures__degree=2, score=(train=-565.761, test=-644.123), total=   0.0s\n",
            "[CV] polynomialfeatures__degree=3 ....................................\n",
            "[CV]  polynomialfeatures__degree=3, score=(train=-565.788, test=-2487.209), total=   0.0s\n",
            "[CV] polynomialfeatures__degree=3 ....................................\n",
            "[CV]  polynomialfeatures__degree=3, score=(train=-663.520, test=-97950.224), total=   0.0s\n",
            "[CV] polynomialfeatures__degree=3 ....................................\n",
            "[CV]  polynomialfeatures__degree=3, score=(train=-576.086, test=-1835.249), total=   0.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('polynomialfeatures',\n",
              "                                        PolynomialFeatures(degree=2,\n",
              "                                                           include_bias=True,\n",
              "                                                           interaction_only=False,\n",
              "                                                           order='C')),\n",
              "                                       ('linearregression',\n",
              "                                        LinearRegression(copy_X=True,\n",
              "                                                         fit_intercept=True,\n",
              "                                                         n_jobs=None,\n",
              "                                                         normalize=False))],\n",
              "                                verbose=False),\n",
              "             iid='warn', n_jobs=None,\n",
              "             param_grid={'polynomialfeatures__degree': [0, 1, 2, 3]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='neg_mean_absolute_error', verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqSgAIwMSxYI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "86197d9e-3d96-44cc-c63e-1916bc3be77d"
      },
      "source": [
        "pd.DataFrame(gridsearch.cv_results_)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_polynomialfeatures__degree</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.006133</td>\n",
              "      <td>0.002356</td>\n",
              "      <td>0.001435</td>\n",
              "      <td>0.000326</td>\n",
              "      <td>0</td>\n",
              "      <td>{'polynomialfeatures__degree': 0}</td>\n",
              "      <td>-1026.352986</td>\n",
              "      <td>-1001.614925</td>\n",
              "      <td>-927.070705</td>\n",
              "      <td>-985.012872</td>\n",
              "      <td>42.197661</td>\n",
              "      <td>2</td>\n",
              "      <td>-968.880368</td>\n",
              "      <td>-970.755413</td>\n",
              "      <td>-999.896701</td>\n",
              "      <td>-979.844161</td>\n",
              "      <td>14.199935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.005057</td>\n",
              "      <td>0.000184</td>\n",
              "      <td>0.001414</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>1</td>\n",
              "      <td>{'polynomialfeatures__degree': 1}</td>\n",
              "      <td>-555.186275</td>\n",
              "      <td>-651.126513</td>\n",
              "      <td>-615.965800</td>\n",
              "      <td>-607.426196</td>\n",
              "      <td>39.630174</td>\n",
              "      <td>1</td>\n",
              "      <td>-619.509206</td>\n",
              "      <td>-583.427702</td>\n",
              "      <td>-589.341301</td>\n",
              "      <td>-597.426070</td>\n",
              "      <td>15.800661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.005868</td>\n",
              "      <td>0.000258</td>\n",
              "      <td>0.001717</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>2</td>\n",
              "      <td>{'polynomialfeatures__degree': 2}</td>\n",
              "      <td>-7553.673678</td>\n",
              "      <td>-1439.191570</td>\n",
              "      <td>-644.122834</td>\n",
              "      <td>-3212.329361</td>\n",
              "      <td>3086.906373</td>\n",
              "      <td>3</td>\n",
              "      <td>-595.089615</td>\n",
              "      <td>-568.150803</td>\n",
              "      <td>-565.761032</td>\n",
              "      <td>-576.333816</td>\n",
              "      <td>13.298189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.016661</td>\n",
              "      <td>0.001457</td>\n",
              "      <td>0.003307</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>3</td>\n",
              "      <td>{'polynomialfeatures__degree': 3}</td>\n",
              "      <td>-2487.208724</td>\n",
              "      <td>-97950.223989</td>\n",
              "      <td>-1835.249043</td>\n",
              "      <td>-34090.893919</td>\n",
              "      <td>45156.149752</td>\n",
              "      <td>4</td>\n",
              "      <td>-565.787908</td>\n",
              "      <td>-663.520180</td>\n",
              "      <td>-576.085609</td>\n",
              "      <td>-601.797899</td>\n",
              "      <td>43.846251</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  mean_train_score  std_train_score\n",
              "0       0.006133      0.002356  ...       -979.844161        14.199935\n",
              "1       0.005057      0.000184  ...       -597.426070        15.800661\n",
              "2       0.005868      0.000258  ...       -576.333816        13.298189\n",
              "3       0.016661      0.001457  ...       -601.797899        43.846251\n",
              "\n",
              "[4 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj82P0VdwYlh",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest?\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yYXpk99C4cM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "2d870190-fb31-46e7-a325-c64b360e4a0f"
      },
      "source": [
        "# TODO\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100, max_depth=20)\n",
        "\n",
        "scores = cross_validate(model, X_train, y_train, \n",
        "                        scoring='neg_mean_absolute_error', \n",
        "                        cv=3, return_train_score=True, \n",
        "                        return_estimator=True)\n",
        "\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.212676</td>\n",
              "      <td>0.010320</td>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', ma...</td>\n",
              "      <td>-561.900768</td>\n",
              "      <td>-243.758782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.211026</td>\n",
              "      <td>0.010150</td>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', ma...</td>\n",
              "      <td>-638.601122</td>\n",
              "      <td>-227.210035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.212077</td>\n",
              "      <td>0.010241</td>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', ma...</td>\n",
              "      <td>-646.784760</td>\n",
              "      <td>-223.423860</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time  ...  test_score  train_score\n",
              "0  0.212676    0.010320  ... -561.900768  -243.758782\n",
              "1  0.211026    0.010150  ... -638.601122  -227.210035\n",
              "2  0.212077    0.010241  ... -646.784760  -223.423860\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vofwgIpSweEb",
        "colab_type": "text"
      },
      "source": [
        "### Validation Curve (with Random Forest)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apKk4vKiwgtM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "ce92d79d-326c-46d6-caec-b153f247bf55"
      },
      "source": [
        "# Modified from cell 13 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import validation_curve\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100)\n",
        "\n",
        "depth = [2, 3, 4, 5, 6]\n",
        "train_score, val_score = validation_curve(\n",
        "    model, X_train, y_train,\n",
        "    param_name='max_depth', param_range=depth, \n",
        "    scoring='neg_mean_absolute_error', cv=3)\n",
        "plt.gcf().set_size_inches(10, 6)\n",
        "plt.plot(depth, np.median(train_score, 1), color='blue', label='training score')\n",
        "plt.plot(depth, np.median(val_score, 1), color='red', label='validation score')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('depth');"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAAF3CAYAAAAGpSdTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRT2J7wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQoMvZ7-yCAQ",
        "colab_type": "text"
      },
      "source": [
        "### Grid Search (with Random Forest)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk_dX_mByKm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO\n",
        "# set Grid Search params\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200], \n",
        "    'max_depth': [4, 5], \n",
        "    'criterion': ['mse', 'mae']\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xiB718UTj4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8ff013c-34c0-4cdb-d4e8-147343d9d660"
      },
      "source": [
        "gridsearch = GridSearchCV(RandomForestRegressor(), param_grid=param_grid, cv=3, \n",
        "                          scoring='neg_mean_absolute_error', verbose=10, \n",
        "                          return_train_score=True)\n",
        "\n",
        "gridsearch.fit(X_train, y_train)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "[CV] criterion=mse, max_depth=4, n_estimators=100 ....................\n",
            "[CV]  criterion=mse, max_depth=4, n_estimators=100, score=(train=-570.089, test=-555.262), total=   0.1s\n",
            "[CV] criterion=mse, max_depth=4, n_estimators=100 ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mse, max_depth=4, n_estimators=100, score=(train=-530.127, test=-643.794), total=   0.1s\n",
            "[CV] criterion=mse, max_depth=4, n_estimators=100 ....................\n",
            "[CV]  criterion=mse, max_depth=4, n_estimators=100, score=(train=-535.104, test=-623.741), total=   0.1s\n",
            "[CV] criterion=mse, max_depth=4, n_estimators=200 ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mse, max_depth=4, n_estimators=200, score=(train=-571.396, test=-553.090), total=   0.2s\n",
            "[CV] criterion=mse, max_depth=4, n_estimators=200 ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mse, max_depth=4, n_estimators=200, score=(train=-530.958, test=-645.037), total=   0.2s\n",
            "[CV] criterion=mse, max_depth=4, n_estimators=200 ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mse, max_depth=4, n_estimators=200, score=(train=-534.200, test=-622.992), total=   0.2s\n",
            "[CV] criterion=mse, max_depth=5, n_estimators=100 ....................\n",
            "[CV]  criterion=mse, max_depth=5, n_estimators=100, score=(train=-527.614, test=-546.697), total=   0.1s\n",
            "[CV] criterion=mse, max_depth=5, n_estimators=100 ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    1.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    1.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mse, max_depth=5, n_estimators=100, score=(train=-490.582, test=-636.966), total=   0.1s\n",
            "[CV] criterion=mse, max_depth=5, n_estimators=100 ....................\n",
            "[CV]  criterion=mse, max_depth=5, n_estimators=100, score=(train=-491.767, test=-631.985), total=   0.1s\n",
            "[CV] criterion=mse, max_depth=5, n_estimators=200 ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    1.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    1.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mse, max_depth=5, n_estimators=200, score=(train=-523.354, test=-542.620), total=   0.3s\n",
            "[CV] criterion=mse, max_depth=5, n_estimators=200 ....................\n",
            "[CV]  criterion=mse, max_depth=5, n_estimators=200, score=(train=-489.228, test=-637.244), total=   0.3s\n",
            "[CV] criterion=mse, max_depth=5, n_estimators=200 ....................\n",
            "[CV]  criterion=mse, max_depth=5, n_estimators=200, score=(train=-489.454, test=-625.293), total=   0.3s\n",
            "[CV] criterion=mae, max_depth=4, n_estimators=100 ....................\n",
            "[CV]  criterion=mae, max_depth=4, n_estimators=100, score=(train=-555.986, test=-544.562), total=   0.7s\n",
            "[CV] criterion=mae, max_depth=4, n_estimators=100 ....................\n",
            "[CV]  criterion=mae, max_depth=4, n_estimators=100, score=(train=-517.538, test=-641.038), total=   0.6s\n",
            "[CV] criterion=mae, max_depth=4, n_estimators=100 ....................\n",
            "[CV]  criterion=mae, max_depth=4, n_estimators=100, score=(train=-524.301, test=-613.735), total=   0.6s\n",
            "[CV] criterion=mae, max_depth=4, n_estimators=200 ....................\n",
            "[CV]  criterion=mae, max_depth=4, n_estimators=200, score=(train=-555.168, test=-543.490), total=   1.3s\n",
            "[CV] criterion=mae, max_depth=4, n_estimators=200 ....................\n",
            "[CV]  criterion=mae, max_depth=4, n_estimators=200, score=(train=-517.337, test=-635.003), total=   1.3s\n",
            "[CV] criterion=mae, max_depth=4, n_estimators=200 ....................\n",
            "[CV]  criterion=mae, max_depth=4, n_estimators=200, score=(train=-523.085, test=-611.699), total=   1.3s\n",
            "[CV] criterion=mae, max_depth=5, n_estimators=100 ....................\n",
            "[CV]  criterion=mae, max_depth=5, n_estimators=100, score=(train=-515.401, test=-540.385), total=   0.7s\n",
            "[CV] criterion=mae, max_depth=5, n_estimators=100 ....................\n",
            "[CV]  criterion=mae, max_depth=5, n_estimators=100, score=(train=-479.727, test=-638.676), total=   0.7s\n",
            "[CV] criterion=mae, max_depth=5, n_estimators=100 ....................\n",
            "[CV]  criterion=mae, max_depth=5, n_estimators=100, score=(train=-483.613, test=-616.095), total=   0.7s\n",
            "[CV] criterion=mae, max_depth=5, n_estimators=200 ....................\n",
            "[CV]  criterion=mae, max_depth=5, n_estimators=200, score=(train=-515.208, test=-537.745), total=   1.5s\n",
            "[CV] criterion=mae, max_depth=5, n_estimators=200 ....................\n",
            "[CV]  criterion=mae, max_depth=5, n_estimators=200, score=(train=-474.203, test=-637.628), total=   1.4s\n",
            "[CV] criterion=mae, max_depth=5, n_estimators=200 ....................\n",
            "[CV]  criterion=mae, max_depth=5, n_estimators=200, score=(train=-483.940, test=-614.309), total=   1.6s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   14.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
              "             estimator=RandomForestRegressor(bootstrap=True, criterion='mse',\n",
              "                                             max_depth=None,\n",
              "                                             max_features='auto',\n",
              "                                             max_leaf_nodes=None,\n",
              "                                             min_impurity_decrease=0.0,\n",
              "                                             min_impurity_split=None,\n",
              "                                             min_samples_leaf=1,\n",
              "                                             min_samples_split=2,\n",
              "                                             min_weight_fraction_leaf=0.0,\n",
              "                                             n_estimators='warn', n_jobs=None,\n",
              "                                             oob_score=False, random_state=None,\n",
              "                                             verbose=0, warm_start=False),\n",
              "             iid='warn', n_jobs=None,\n",
              "             param_grid={'criterion': ['mse', 'mae'], 'max_depth': [4, 5],\n",
              "                         'n_estimators': [100, 200]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='neg_mean_absolute_error', verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIqNWU0aT35u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "e4a35ee1-7131-4d57-9ef8-f4c423c8c73a"
      },
      "source": [
        "results = pd.DataFrame(gridsearch.cv_results_)\n",
        "print(f'===>>>Best five results from grid search of {len(results)} parameter combinations<<<===')\n",
        "results.sort_values(by='rank_test_score').head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===>>>Best five results from grid search of 8 parameter combinations<<<===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.470901</td>\n",
              "      <td>0.059150</td>\n",
              "      <td>0.012187</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>mae</td>\n",
              "      <td>5</td>\n",
              "      <td>200</td>\n",
              "      <td>{'criterion': 'mae', 'max_depth': 5, 'n_es...</td>\n",
              "      <td>-537.744509</td>\n",
              "      <td>-637.627921</td>\n",
              "      <td>-614.308723</td>\n",
              "      <td>-596.560384</td>\n",
              "      <td>42.664791</td>\n",
              "      <td>1</td>\n",
              "      <td>-515.207675</td>\n",
              "      <td>-474.203057</td>\n",
              "      <td>-483.939965</td>\n",
              "      <td>-491.116899</td>\n",
              "      <td>17.492398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.268875</td>\n",
              "      <td>0.018624</td>\n",
              "      <td>0.011533</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>mae</td>\n",
              "      <td>4</td>\n",
              "      <td>200</td>\n",
              "      <td>{'criterion': 'mae', 'max_depth': 4, 'n_es...</td>\n",
              "      <td>-543.490195</td>\n",
              "      <td>-635.003022</td>\n",
              "      <td>-611.698676</td>\n",
              "      <td>-596.730631</td>\n",
              "      <td>38.830239</td>\n",
              "      <td>2</td>\n",
              "      <td>-555.167753</td>\n",
              "      <td>-517.336663</td>\n",
              "      <td>-523.084949</td>\n",
              "      <td>-531.863122</td>\n",
              "      <td>16.645121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.720088</td>\n",
              "      <td>0.014169</td>\n",
              "      <td>0.007078</td>\n",
              "      <td>0.000157</td>\n",
              "      <td>mae</td>\n",
              "      <td>5</td>\n",
              "      <td>100</td>\n",
              "      <td>{'criterion': 'mae', 'max_depth': 5, 'n_es...</td>\n",
              "      <td>-540.384704</td>\n",
              "      <td>-638.675857</td>\n",
              "      <td>-616.095312</td>\n",
              "      <td>-598.385291</td>\n",
              "      <td>42.035868</td>\n",
              "      <td>3</td>\n",
              "      <td>-515.400841</td>\n",
              "      <td>-479.727259</td>\n",
              "      <td>-483.612804</td>\n",
              "      <td>-492.913634</td>\n",
              "      <td>15.979783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.633817</td>\n",
              "      <td>0.015449</td>\n",
              "      <td>0.006807</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>mae</td>\n",
              "      <td>4</td>\n",
              "      <td>100</td>\n",
              "      <td>{'criterion': 'mae', 'max_depth': 4, 'n_es...</td>\n",
              "      <td>-544.561511</td>\n",
              "      <td>-641.038100</td>\n",
              "      <td>-613.734688</td>\n",
              "      <td>-599.778100</td>\n",
              "      <td>40.603964</td>\n",
              "      <td>4</td>\n",
              "      <td>-555.985849</td>\n",
              "      <td>-517.537640</td>\n",
              "      <td>-524.300545</td>\n",
              "      <td>-532.608011</td>\n",
              "      <td>16.759608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.243601</td>\n",
              "      <td>0.004866</td>\n",
              "      <td>0.012125</td>\n",
              "      <td>0.000125</td>\n",
              "      <td>mse</td>\n",
              "      <td>5</td>\n",
              "      <td>200</td>\n",
              "      <td>{'criterion': 'mse', 'max_depth': 5, 'n_es...</td>\n",
              "      <td>-542.619890</td>\n",
              "      <td>-637.244147</td>\n",
              "      <td>-625.293112</td>\n",
              "      <td>-601.719049</td>\n",
              "      <td>42.073268</td>\n",
              "      <td>5</td>\n",
              "      <td>-523.354167</td>\n",
              "      <td>-489.228479</td>\n",
              "      <td>-489.454345</td>\n",
              "      <td>-500.678997</td>\n",
              "      <td>16.034032</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  mean_train_score  std_train_score\n",
              "7       1.470901      0.059150  ...       -491.116899        17.492398\n",
              "5       1.268875      0.018624  ...       -531.863122        16.645121\n",
              "6       0.720088      0.014169  ...       -492.913634        15.979783\n",
              "4       0.633817      0.015449  ...       -532.608011        16.759608\n",
              "3       0.243601      0.004866  ...       -500.678997        16.034032\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW5HfYtU0GW2",
        "colab_type": "text"
      },
      "source": [
        "## FEATURE ENGINEERING!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ms-eoOHFvPG",
        "colab_type": "text"
      },
      "source": [
        "Jake VanderPlas demonstrates this feature engineering: \n",
        "https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEwME8wR3A5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modified from code cells 17-21 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
        "\n",
        "\n",
        "# patterns of use generally vary from day to day; \n",
        "# let's add binary columns that indicate the day of the week:\n",
        "days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "for i, day in enumerate(days):\n",
        "    X_train[day] = (X_train.index.dayofweek == i).astype(float)\n",
        "\n",
        "\n",
        "    \n",
        "# we might expect riders to behave differently on holidays; \n",
        "# let's add an indicator of this as well:\n",
        "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "cal = USFederalHolidayCalendar()\n",
        "holidays = cal.holidays('2012', '2016')\n",
        "X_train = X_train.join(pd.Series(1, index=holidays, name='holiday'))\n",
        "X_train['holiday'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# We also might suspect that the hours of daylight would affect \n",
        "# how many people ride; let's use the standard astronomical calculation \n",
        "# to add this information:\n",
        "def hours_of_daylight(date, axis=23.44, latitude=47.61):\n",
        "    \"\"\"Compute the hours of daylight for the given date\"\"\"\n",
        "    days = (date - pd.datetime(2000, 12, 21)).days\n",
        "    m = (1. - np.tan(np.radians(latitude))\n",
        "         * np.tan(np.radians(axis) * np.cos(days * 2 * np.pi / 365.25)))\n",
        "    return 24. * np.degrees(np.arccos(1 - np.clip(m, 0, 2))) / 180.\n",
        "\n",
        "X_train['daylight_hrs'] = list(map(hours_of_daylight, X_train.index))\n",
        "\n",
        "\n",
        "\n",
        "# temperatures are in 1/10 deg C; convert to C\n",
        "X_train['TMIN'] /= 10\n",
        "X_train['TMAX'] /= 10\n",
        "\n",
        "# We can also calcuate the average temperature.\n",
        "X_train['Temp (C)'] = 0.5 * (X_train['TMIN'] + X_train['TMAX'])\n",
        "\n",
        "\n",
        "\n",
        "# precip is in 1/10 mm; convert to inches\n",
        "X_train['PRCP'] /= 254\n",
        "\n",
        "# In addition to the inches of precipitation, let's add a flag that \n",
        "# indicates whether a day is dry (has zero precipitation):\n",
        "X_train['dry day'] = (X_train['PRCP'] == 0).astype(int)\n",
        "\n",
        "\n",
        "\n",
        "# Let's add a counter that increases from day 1, and measures how many \n",
        "# years have passed. This will let us measure any observed annual increase \n",
        "# or decrease in daily crossings:\n",
        "X_train['annual'] = (X_train.index - X_train.index[0]).days / 365."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDGkAv813Wtj",
        "colab_type": "text"
      },
      "source": [
        "### Linear Regression (with new features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj3HTM6p5F1A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "ef47d3b7-b5dc-4be5-fee3-244965c7fef8"
      },
      "source": [
        "# TODO\n",
        "scores = cross_validate(LinearRegression(), X_train, y_train, \n",
        "                        scoring='neg_mean_absolute_error', cv=3, \n",
        "                        return_train_score=True, return_estimator=True)\n",
        "\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.012846</td>\n",
              "      <td>0.003580</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercep...</td>\n",
              "      <td>-297.692524</td>\n",
              "      <td>-294.532315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.003195</td>\n",
              "      <td>0.001220</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercep...</td>\n",
              "      <td>-300.419037</td>\n",
              "      <td>-283.779461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.003093</td>\n",
              "      <td>0.001272</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercep...</td>\n",
              "      <td>-322.640378</td>\n",
              "      <td>-283.509114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time  ...  test_score  train_score\n",
              "0  0.012846    0.003580  ... -297.692524  -294.532315\n",
              "1  0.003195    0.001220  ... -300.419037  -283.779461\n",
              "2  0.003093    0.001272  ... -322.640378  -283.509114\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-QqPZDqUZXH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99513b57-e3ce-4937-9a7c-f26535073832"
      },
      "source": [
        "-scores['test_score'].mean()  # neg_mean_absolute_error"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "306.9173130794428"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6zxN2xB3bX_",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest (with new features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sWUDZIz1-kk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "d7578632-dbd3-40d1-8b77-3d679c9fd20d"
      },
      "source": [
        "# TODO\n",
        "param_grid = {\n",
        "    'n_estimators': [100], \n",
        "    'max_depth': [5, 10, 15], \n",
        "    'criterion': ['mae']\n",
        "}\n",
        "\n",
        "gridsearch = GridSearchCV(RandomForestRegressor(), param_grid=param_grid, \n",
        "                          cv=3, scoring='neg_mean_absolute_error', \n",
        "                          return_train_score=True, verbose=10)\n",
        "\n",
        "gridsearch.fit(X_train, y_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "[CV] criterion=mae, max_depth=5, n_estimators=100 ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mae, max_depth=5, n_estimators=100, score=(train=-300.113, test=-351.836), total=   1.6s\n",
            "[CV] criterion=mae, max_depth=5, n_estimators=100 ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mae, max_depth=5, n_estimators=100, score=(train=-264.993, test=-381.878), total=   1.5s\n",
            "[CV] criterion=mae, max_depth=5, n_estimators=100 ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mae, max_depth=5, n_estimators=100, score=(train=-296.482, test=-340.005), total=   1.6s\n",
            "[CV] criterion=mae, max_depth=10, n_estimators=100 ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mae, max_depth=10, n_estimators=100, score=(train=-141.955, test=-347.630), total=   2.2s\n",
            "[CV] criterion=mae, max_depth=10, n_estimators=100 ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    6.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mae, max_depth=10, n_estimators=100, score=(train=-128.514, test=-332.039), total=   2.1s\n",
            "[CV] criterion=mae, max_depth=10, n_estimators=100 ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mae, max_depth=10, n_estimators=100, score=(train=-146.210, test=-304.385), total=   2.2s\n",
            "[CV] criterion=mae, max_depth=15, n_estimators=100 ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   11.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mae, max_depth=15, n_estimators=100, score=(train=-110.021, test=-352.236), total=   2.4s\n",
            "[CV] criterion=mae, max_depth=15, n_estimators=100 ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   13.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mae, max_depth=15, n_estimators=100, score=(train=-102.966, test=-323.417), total=   2.3s\n",
            "[CV] criterion=mae, max_depth=15, n_estimators=100 ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   16.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=mae, max_depth=15, n_estimators=100, score=(train=-117.792, test=-297.278), total=   2.4s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   18.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   18.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
              "             estimator=RandomForestRegressor(bootstrap=True, criterion='mse',\n",
              "                                             max_depth=None,\n",
              "                                             max_features='auto',\n",
              "                                             max_leaf_nodes=None,\n",
              "                                             min_impurity_decrease=0.0,\n",
              "                                             min_impurity_split=None,\n",
              "                                             min_samples_leaf=1,\n",
              "                                             min_samples_split=2,\n",
              "                                             min_weight_fraction_leaf=0.0,\n",
              "                                             n_estimators='warn', n_jobs=None,\n",
              "                                             oob_score=False, random_state=None,\n",
              "                                             verbose=0, warm_start=False),\n",
              "             iid='warn', n_jobs=None,\n",
              "             param_grid={'criterion': ['mae'], 'max_depth': [5, 10, 15],\n",
              "                         'n_estimators': [100]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='neg_mean_absolute_error', verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ7EuDisU1f7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "7aaa2554-620b-48e0-80e5-c55d84fdc95a"
      },
      "source": [
        "results = pd.DataFrame(gridsearch.cv_results_)\n",
        "results.sort_values(by='rank_test_score').head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.360482</td>\n",
              "      <td>0.050674</td>\n",
              "      <td>0.010652</td>\n",
              "      <td>0.000544</td>\n",
              "      <td>mae</td>\n",
              "      <td>15</td>\n",
              "      <td>100</td>\n",
              "      <td>{'criterion': 'mae', 'max_depth': 15, 'n_e...</td>\n",
              "      <td>-352.236075</td>\n",
              "      <td>-323.417118</td>\n",
              "      <td>-297.278271</td>\n",
              "      <td>-324.310488</td>\n",
              "      <td>22.445321</td>\n",
              "      <td>1</td>\n",
              "      <td>-110.020942</td>\n",
              "      <td>-102.966417</td>\n",
              "      <td>-117.792469</td>\n",
              "      <td>-110.259943</td>\n",
              "      <td>6.055069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.153070</td>\n",
              "      <td>0.032743</td>\n",
              "      <td>0.009059</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>mae</td>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>{'criterion': 'mae', 'max_depth': 10, 'n_e...</td>\n",
              "      <td>-347.630265</td>\n",
              "      <td>-332.038925</td>\n",
              "      <td>-304.384735</td>\n",
              "      <td>-328.017975</td>\n",
              "      <td>17.882393</td>\n",
              "      <td>2</td>\n",
              "      <td>-141.955366</td>\n",
              "      <td>-128.514128</td>\n",
              "      <td>-146.210327</td>\n",
              "      <td>-138.893274</td>\n",
              "      <td>7.541935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.546442</td>\n",
              "      <td>0.029804</td>\n",
              "      <td>0.006979</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>mae</td>\n",
              "      <td>5</td>\n",
              "      <td>100</td>\n",
              "      <td>{'criterion': 'mae', 'max_depth': 5, 'n_es...</td>\n",
              "      <td>-351.836153</td>\n",
              "      <td>-381.878084</td>\n",
              "      <td>-340.004517</td>\n",
              "      <td>-357.906251</td>\n",
              "      <td>17.625426</td>\n",
              "      <td>3</td>\n",
              "      <td>-300.112687</td>\n",
              "      <td>-264.993403</td>\n",
              "      <td>-296.481768</td>\n",
              "      <td>-287.195953</td>\n",
              "      <td>15.769396</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  mean_train_score  std_train_score\n",
              "2       2.360482      0.050674  ...       -110.259943         6.055069\n",
              "1       2.153070      0.032743  ...       -138.893274         7.541935\n",
              "0       1.546442      0.029804  ...       -287.195953        15.769396\n",
              "\n",
              "[3 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QEBUVR13kcb",
        "colab_type": "text"
      },
      "source": [
        "### Ridge Regression (with new features)\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4voLbIxU8r6r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "7b8cb045-afb1-4153-bee0-f0b8590d36d4"
      },
      "source": [
        "# TODO\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "param_grid = {\n",
        "    'alpha': [0.1, 1.0, 10.0]\n",
        "}\n",
        "\n",
        "gridsearch = GridSearchCV(Ridge(), param_grid=param_grid,\n",
        "                          scoring='neg_mean_absolute_error',\n",
        "                          cv=3, return_train_score=True, verbose=2)\n",
        "\n",
        "gridsearch.fit(X_train, y_train)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ........................................ alpha=0.1, total=   0.0s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ........................................ alpha=0.1, total=   0.0s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ........................................ alpha=0.1, total=   0.0s\n",
            "[CV] alpha=1.0 .......................................................\n",
            "[CV] ........................................ alpha=1.0, total=   0.0s\n",
            "[CV] alpha=1.0 .......................................................\n",
            "[CV] ........................................ alpha=1.0, total=   0.0s\n",
            "[CV] alpha=1.0 .......................................................\n",
            "[CV] ........................................ alpha=1.0, total=   0.0s\n",
            "[CV] alpha=10.0 ......................................................\n",
            "[CV] ....................................... alpha=10.0, total=   0.0s\n",
            "[CV] alpha=10.0 ......................................................\n",
            "[CV] ....................................... alpha=10.0, total=   0.0s\n",
            "[CV] alpha=10.0 ......................................................\n",
            "[CV] ....................................... alpha=10.0, total=   0.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
              "             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
              "                             max_iter=None, normalize=False, random_state=None,\n",
              "                             solver='auto', tol=0.001),\n",
              "             iid='warn', n_jobs=None, param_grid={'alpha': [0.1, 1.0, 10.0]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='neg_mean_absolute_error', verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cP3DmiZVIvc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "031d8192-0f3f-4da1-a2be-fcf77def4cca"
      },
      "source": [
        "results = pd.DataFrame(gridsearch.cv_results_)\n",
        "results.sort_values(by='rank_test_score').head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_alpha</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.002746</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>0.001168</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>1</td>\n",
              "      <td>{'alpha': 1.0}</td>\n",
              "      <td>-295.097222</td>\n",
              "      <td>-301.453949</td>\n",
              "      <td>-322.891834</td>\n",
              "      <td>-306.481001</td>\n",
              "      <td>11.890853</td>\n",
              "      <td>1</td>\n",
              "      <td>-294.519125</td>\n",
              "      <td>-283.740595</td>\n",
              "      <td>-283.291836</td>\n",
              "      <td>-287.183852</td>\n",
              "      <td>5.190056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.006219</td>\n",
              "      <td>0.004693</td>\n",
              "      <td>0.001323</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'alpha': 0.1}</td>\n",
              "      <td>-297.398383</td>\n",
              "      <td>-300.510934</td>\n",
              "      <td>-322.661427</td>\n",
              "      <td>-306.856914</td>\n",
              "      <td>11.247487</td>\n",
              "      <td>2</td>\n",
              "      <td>-294.519201</td>\n",
              "      <td>-283.762475</td>\n",
              "      <td>-283.474873</td>\n",
              "      <td>-287.252183</td>\n",
              "      <td>5.139899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.003142</td>\n",
              "      <td>0.000336</td>\n",
              "      <td>0.001168</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>10</td>\n",
              "      <td>{'alpha': 10.0}</td>\n",
              "      <td>-283.734177</td>\n",
              "      <td>-314.574979</td>\n",
              "      <td>-331.635292</td>\n",
              "      <td>-309.981483</td>\n",
              "      <td>19.823460</td>\n",
              "      <td>3</td>\n",
              "      <td>-301.203378</td>\n",
              "      <td>-289.669103</td>\n",
              "      <td>-287.848116</td>\n",
              "      <td>-292.906866</td>\n",
              "      <td>5.913436</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  mean_train_score  std_train_score\n",
              "1       0.002746      0.000068  ...       -287.183852         5.190056\n",
              "0       0.006219      0.004693  ...       -287.252183         5.139899\n",
              "2       0.003142      0.000336  ...       -292.906866         5.913436\n",
              "\n",
              "[3 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlNMcuuZVZ6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "394c75f8-a081-49fd-84c3-9bd40dfcf5e7"
      },
      "source": [
        "model = gridsearch.best_estimator_\n",
        "\n",
        "print(\"Model type:\", type(model))\n",
        "\n",
        "print(\"\\nIntercept:\", model.intercept_)\n",
        "print(\"\\nCoefficients:\")\n",
        "print(pd.Series(model.coef_, X_train.columns).to_string())"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model type: <class 'sklearn.linear_model.ridge.Ridge'>\n",
            "\n",
            "Intercept: 33.741779570641484\n",
            "\n",
            "Coefficients:\n",
            "PRCP               -553.070741\n",
            "SNOW                 -0.002829\n",
            "SNWD                 -1.877519\n",
            "TMAX                 63.833062\n",
            "TMIN                -37.450291\n",
            "AWND                 -1.900084\n",
            "Total_yesterday       0.296029\n",
            "Mon                 779.221395\n",
            "Tue                 432.700039\n",
            "Wed                 368.367626\n",
            "Thu                 274.054021\n",
            "Fri                  47.251356\n",
            "Sat               -1099.692199\n",
            "Sun                -801.902237\n",
            "holiday            -939.301546\n",
            "daylight_hrs         70.256463\n",
            "Temp (C)             13.191386\n",
            "dry day             298.475434\n",
            "annual               44.518889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dofdwyTf3pm0",
        "colab_type": "text"
      },
      "source": [
        "### Compare to statsmodels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Qt4mDk_yBY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        },
        "outputId": "4a143329-2b77-4bf2-a33a-fdf157075d49"
      },
      "source": [
        "# TODO\n",
        "model = sm.OLS(y_train, sm.add_constant(X_train))\n",
        "model.fit().summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
            "  return ptp(axis=axis, out=out, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>          <td>Total</td>      <th>  R-squared:         </th> <td>   0.902</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.901</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   513.8</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sun, 04 Aug 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>06:34:35</td>     <th>  Log-Likelihood:    </th> <td> -7092.6</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   963</td>      <th>  AIC:               </th> <td>1.422e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   945</td>      <th>  BIC:               </th> <td>1.431e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    17</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>           <td>   33.0481</td> <td>   66.293</td> <td>    0.499</td> <td> 0.618</td> <td>  -97.051</td> <td>  163.147</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>PRCP</th>            <td> -562.6226</td> <td>   56.568</td> <td>   -9.946</td> <td> 0.000</td> <td> -673.636</td> <td> -451.609</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>SNOW</th>            <td>   -0.0025</td> <td>    0.020</td> <td>   -0.129</td> <td> 0.897</td> <td>   -0.041</td> <td>    0.036</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>SNWD</th>            <td>   -1.8308</td> <td>    4.642</td> <td>   -0.394</td> <td> 0.693</td> <td>  -10.941</td> <td>    7.279</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>TMAX</th>            <td>   63.6645</td> <td>    4.785</td> <td>   13.306</td> <td> 0.000</td> <td>   54.275</td> <td>   73.054</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>TMIN</th>            <td>  -37.1413</td> <td>    5.413</td> <td>   -6.862</td> <td> 0.000</td> <td>  -47.763</td> <td>  -26.519</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>AWND</th>            <td>   -1.8502</td> <td>    0.910</td> <td>   -2.033</td> <td> 0.042</td> <td>   -3.637</td> <td>   -0.064</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total_yesterday</th> <td>    0.2934</td> <td>    0.022</td> <td>   13.630</td> <td> 0.000</td> <td>    0.251</td> <td>    0.336</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Mon</th>             <td>  790.2012</td> <td>   41.051</td> <td>   19.249</td> <td> 0.000</td> <td>  709.640</td> <td>  870.763</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Tue</th>             <td>  441.4649</td> <td>   32.982</td> <td>   13.385</td> <td> 0.000</td> <td>  376.739</td> <td>  506.191</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Wed</th>             <td>  376.8835</td> <td>   33.935</td> <td>   11.106</td> <td> 0.000</td> <td>  310.287</td> <td>  443.480</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Thu</th>             <td>  282.8744</td> <td>   33.665</td> <td>    8.403</td> <td> 0.000</td> <td>  216.808</td> <td>  348.941</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fri</th>             <td>   52.4558</td> <td>   32.802</td> <td>    1.599</td> <td> 0.110</td> <td>  -11.918</td> <td>  116.829</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Sat</th>             <td>-1103.8595</td> <td>   32.242</td> <td>  -34.237</td> <td> 0.000</td> <td>-1167.133</td> <td>-1040.586</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Sun</th>             <td> -806.9722</td> <td>   40.114</td> <td>  -20.117</td> <td> 0.000</td> <td> -885.695</td> <td> -728.250</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>holiday</th>         <td> -983.4044</td> <td>   78.191</td> <td>  -12.577</td> <td> 0.000</td> <td>-1136.853</td> <td> -829.955</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>daylight_hrs</th>    <td>   70.3750</td> <td>    8.400</td> <td>    8.378</td> <td> 0.000</td> <td>   53.890</td> <td>   86.860</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Temp (C)</th>        <td>   13.2616</td> <td>    1.252</td> <td>   10.591</td> <td> 0.000</td> <td>   10.804</td> <td>   15.719</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>dry day</th>         <td>  301.0276</td> <td>   33.915</td> <td>    8.876</td> <td> 0.000</td> <td>  234.471</td> <td>  367.584</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>annual</th>          <td>   44.6618</td> <td>   16.620</td> <td>    2.687</td> <td> 0.007</td> <td>   12.045</td> <td>   77.279</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>35.650</td> <th>  Durbin-Watson:     </th> <td>   1.665</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  78.276</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.188</td> <th>  Prob(JB):          </th> <td>1.01e-17</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 4.345</td> <th>  Cond. No.          </th> <td>2.64e+19</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.09e-29. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                  Total   R-squared:                       0.902\n",
              "Model:                            OLS   Adj. R-squared:                  0.901\n",
              "Method:                 Least Squares   F-statistic:                     513.8\n",
              "Date:                Sun, 04 Aug 2019   Prob (F-statistic):               0.00\n",
              "Time:                        06:34:35   Log-Likelihood:                -7092.6\n",
              "No. Observations:                 963   AIC:                         1.422e+04\n",
              "Df Residuals:                     945   BIC:                         1.431e+04\n",
              "Df Model:                          17                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "===================================================================================\n",
              "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
              "-----------------------------------------------------------------------------------\n",
              "const              33.0481     66.293      0.499      0.618     -97.051     163.147\n",
              "PRCP             -562.6226     56.568     -9.946      0.000    -673.636    -451.609\n",
              "SNOW               -0.0025      0.020     -0.129      0.897      -0.041       0.036\n",
              "SNWD               -1.8308      4.642     -0.394      0.693     -10.941       7.279\n",
              "TMAX               63.6645      4.785     13.306      0.000      54.275      73.054\n",
              "TMIN              -37.1413      5.413     -6.862      0.000     -47.763     -26.519\n",
              "AWND               -1.8502      0.910     -2.033      0.042      -3.637      -0.064\n",
              "Total_yesterday     0.2934      0.022     13.630      0.000       0.251       0.336\n",
              "Mon               790.2012     41.051     19.249      0.000     709.640     870.763\n",
              "Tue               441.4649     32.982     13.385      0.000     376.739     506.191\n",
              "Wed               376.8835     33.935     11.106      0.000     310.287     443.480\n",
              "Thu               282.8744     33.665      8.403      0.000     216.808     348.941\n",
              "Fri                52.4558     32.802      1.599      0.110     -11.918     116.829\n",
              "Sat             -1103.8595     32.242    -34.237      0.000   -1167.133   -1040.586\n",
              "Sun              -806.9722     40.114    -20.117      0.000    -885.695    -728.250\n",
              "holiday          -983.4044     78.191    -12.577      0.000   -1136.853    -829.955\n",
              "daylight_hrs       70.3750      8.400      8.378      0.000      53.890      86.860\n",
              "Temp (C)           13.2616      1.252     10.591      0.000      10.804      15.719\n",
              "dry day           301.0276     33.915      8.876      0.000     234.471     367.584\n",
              "annual             44.6618     16.620      2.687      0.007      12.045      77.279\n",
              "==============================================================================\n",
              "Omnibus:                       35.650   Durbin-Watson:                   1.665\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               78.276\n",
              "Skew:                           0.188   Prob(JB):                     1.01e-17\n",
              "Kurtosis:                       4.345   Cond. No.                     2.64e+19\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The smallest eigenvalue is 1.09e-29. This might indicate that there are\n",
              "strong multicollinearity problems or that the design matrix is singular.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edpJ87A8A8sd",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Feature engineering, explained by Francois Chollet\n",
        "\n",
        "> _Feature engineering_ is the process of using your own knowledge about the data and about the machine learning algorithm at hand to make the algorithm work better by applying hardcoded (nonlearned) transformations to the data before it goes into the model. In many cases, it isn’t reasonable to expect a machine-learning model to be able to learn from completely arbitrary data. The data needs to be presented to the model in a way that will make the model’s job easier.\n",
        "\n",
        "> Let’s look at an intuitive example. Suppose you’re trying to develop a model that can take as input an image of a clock and can output the time of day.\n",
        "\n",
        "> If you choose to use the raw pixels of the image as input data, then you have a difficult machine-learning problem on your hands. You’ll need a convolutional neural network to solve it, and you’ll have to expend quite a bit of computational resources to train the network.\n",
        "\n",
        "> But if you already understand the problem at a high level (you understand how humans read time on a clock face), then you can come up with much better input features for a machine-learning algorithm: for instance, write a Python script to follow the black pixels of the clock hands and output the (x, y) coordinates of the tip of each hand. Then a simple machine-learning algorithm can learn to associate these coordinates with the appropriate time of day.\n",
        "\n",
        "> You can go even further: do a coordinate change, and express the (x, y) coordinates as polar coordinates with regard to the center of the image. Your input will become the angle theta of each clock hand. At this point, your features are making the problem so easy that no machine learning is required; a simple rounding operation and dictionary lookup are enough to recover the approximate time of day.\n",
        "\n",
        "> That’s the essence of feature engineering: making a problem easier by expressing it in a simpler way. It usually requires understanding the problem in depth.\n",
        "\n",
        "> Before convolutional neural networks became successful on the MNIST digit-classification problem, solutions were typically based on hardcoded features such as the number of loops in a digit image, the height of each digit in an image, a histogram of pixel values, and so on.\n",
        "\n",
        "> Neural networks are capable of automatically extracting useful features from raw data. Does this mean you don’t have to worry about feature engineering as long as you’re using deep neural networks? No, for two reasons:\n",
        "\n",
        "> - Good features still allow you to solve problems more elegantly while using fewer resources. For instance, it would be ridiculous to solve the problem of reading a clock face using a convolutional neural network.\n",
        "> - Good features let you solve a problem with far less data. The ability of deep-learning models to learn features on their own relies on having lots of training data available; if you have only a few samples, then the information value in their features becomes critical.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oux-dd-5FD6p",
        "colab_type": "text"
      },
      "source": [
        "# ASSIGNMENT\n",
        "\n",
        "### Core assignment\n",
        "\n",
        "Complete the notebook cells that were originally commented **`TODO`**. \n",
        "\n",
        "Then, focus on feature engineering to improve your cross validation scores. Collaborate with your cohort on Slack. You could start with the ideas [Jake VanderPlas suggests:](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic)\n",
        "\n",
        "> Our model is almost certainly missing some relevant information. For example, nonlinear effects (such as effects of precipitation and cold temperature) and nonlinear trends within each variable (such as disinclination to ride at very cold and very hot temperatures) cannot be accounted for in this model. Additionally, we have thrown away some of the finer-grained information (such as the difference between a rainy morning and a rainy afternoon), and we have ignored correlations between days (such as the possible effect of a rainy Tuesday on Wednesday's numbers, or the effect of an unexpected sunny day after a streak of rainy days). These are all potentially interesting effects, and you now have the tools to begin exploring them if you wish!\n",
        "\n",
        "At the end of the day, take the last step in the \"universal workflow of machine learning\" — \"You can train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.\"\n",
        "\n",
        "See the [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) documentation for the `refit` parameter, `best_estimator_` attribute, and `predict` method:\n",
        "\n",
        "> **refit : boolean, or string, default=True**\n",
        "\n",
        "> Refit an estimator using the best found parameters on the whole dataset.\n",
        "\n",
        "> The refitted estimator is made available at the `best_estimator_` attribute and permits using `predict` directly on this `GridSearchCV` instance.\n",
        "\n",
        "### More options\n",
        "\n",
        "**A.** Apply this lesson to other datasets.\n",
        "\n",
        "**B.** We predicted the number of bicycle trips based on that day's weather. But imagine you were asked to predict trips at the beginning of each day, based only on data known at the time of prediction or before — so you cannot use the current day's weather. How would you wrangle the features to handle this new requirement? How does this impact the predictive accuracy and coefficients of your models?\n",
        "\n",
        "**C.** In additon to `GridSearchCV`, scikit-learn has [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html), which is sometimes even better. Another library called scikit-optimize has [`BayesSearchCV`](https://scikit-optimize.github.io/notebooks/sklearn-gridsearchcv-replacement.html). Experiment with these alternatives.\n",
        "\n",
        "**D.** _[Introduction to Machine Learning with Python](http://shop.oreilly.com/product/0636920030515.do)_ discusses options for \"Grid-Searching Which Model To Use\" in Chapter 6:\n",
        "\n",
        "> You can even go further in combining GridSearchCV and Pipeline: it is also possible to search over the actual steps being performed in the pipeline (say whether to use StandardScaler or MinMaxScaler). This leads to an even bigger search space and should be considered carefully. Trying all possible solutions is usually not a viable machine learning strategy. However, here is an example comparing a RandomForestClassifier and an SVC ...\n",
        "\n",
        "The example is shown in [the accompanying notebook](https://github.com/amueller/introduction_to_ml_with_python/blob/master/06-algorithm-chains-and-pipelines.ipynb), code cells 35-37. Could you apply this concept to your own pipelines?\n",
        "\n",
        "\n"
      ]
    }
  ]
}