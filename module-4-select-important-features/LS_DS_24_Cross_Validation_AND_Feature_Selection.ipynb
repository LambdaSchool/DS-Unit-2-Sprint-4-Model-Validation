{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ctjQBseh0Cw"
   },
   "source": [
    "_Lambda School Data Science - Model Validation_\n",
    "\n",
    "## Example solution to the Cross-Validation assignment — plus Feature Selection!\n",
    "\n",
    "See also Sebastian Raschka's example, [Basic Pipeline and Grid Search Setup](https://github.com/rasbt/python-machine-learning-book/blob/master/code/bonus/svm_iris_pipeline_and_gridsearch.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHUVU_AMBKs0"
   },
   "outputs": [],
   "source": [
    "# We'll modify a project from Python Data Science Handbook by Jake VanderPlas\n",
    "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
    "    \n",
    "# Predicting Bicycle Traffic\n",
    "\n",
    "# As an example, let's take a look at whether we can predict the number of \n",
    "# bicycle trips across Seattle's Fremont Bridge based on weather, season, \n",
    "# and other factors.\n",
    "\n",
    "# We will join the bike data with another dataset, and try to determine the \n",
    "# extent to which weather and seasonal factors—temperature, precipitation, \n",
    "# and daylight hours—affect the volume of bicycle traffic through this corridor. \n",
    "# Fortunately, the NOAA makes available their daily weather station data \n",
    "# (I used station ID USW00024233) and we can easily use Pandas to join \n",
    "# the two data sources.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "def load(): \n",
    "    fremont_bridge = 'https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD'\n",
    "    \n",
    "    bicycle_weather = 'https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv'\n",
    "\n",
    "    counts = pd.read_csv(fremont_bridge, index_col='Date', parse_dates=True, \n",
    "                         infer_datetime_format=True)\n",
    "\n",
    "    weather = pd.read_csv(bicycle_weather, index_col='DATE', parse_dates=True, \n",
    "                          infer_datetime_format=True)\n",
    "\n",
    "    daily = counts.resample('d').sum()\n",
    "    daily['Total'] = daily.sum(axis=1)\n",
    "    daily = daily[['Total']] # remove other columns\n",
    "\n",
    "    weather_columns = ['PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND']\n",
    "    daily = daily.join(weather[weather_columns], how='inner')\n",
    "    \n",
    "    # Make a feature for yesterday's total\n",
    "    daily['Total_yesterday'] = daily.Total.shift(1)\n",
    "    daily = daily.drop(index=daily.index[0])\n",
    "    \n",
    "    return daily\n",
    "\n",
    "    \n",
    "def split(daily):\n",
    "    # Hold out an \"out-of-time\" test set, from the last 100 days of data\n",
    "    \n",
    "    train = daily[:-100]\n",
    "    test = daily[-100:]\n",
    "    \n",
    "    X_train = train.drop(columns='Total')\n",
    "    y_train = train.Total\n",
    "\n",
    "    X_test  = test.drop(columns='Total')\n",
    "    y_test  = test.Total\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def jake_wrangle(X):  \n",
    "    X = X.copy()\n",
    "\n",
    "    # patterns of use generally vary from day to day; \n",
    "    # let's add binary columns that indicate the day of the week:\n",
    "    days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "    for i, day in enumerate(days):\n",
    "        X[day] = (X.index.dayofweek == i).astype(float)\n",
    "\n",
    "\n",
    "    # we might expect riders to behave differently on holidays; \n",
    "    # let's add an indicator of this as well:\n",
    "    from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "    cal = USFederalHolidayCalendar()\n",
    "    holidays = cal.holidays('2012', '2016')\n",
    "    X = X.join(pd.Series(1, index=holidays, name='holiday'))\n",
    "    X['holiday'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "    # We also might suspect that the hours of daylight would affect \n",
    "    # how many people ride; let's use the standard astronomical calculation \n",
    "    # to add this information:\n",
    "    def hours_of_daylight(date, axis=23.44, latitude=47.61):\n",
    "        \"\"\"Compute the hours of daylight for the given date\"\"\"\n",
    "        days = (date - pd.datetime(2000, 12, 21)).days\n",
    "        m = (1. - np.tan(np.radians(latitude))\n",
    "             * np.tan(np.radians(axis) * np.cos(days * 2 * np.pi / 365.25)))\n",
    "        return 24. * np.degrees(np.arccos(1 - np.clip(m, 0, 2))) / 180.\n",
    "\n",
    "    X['daylight_hrs'] = list(map(hours_of_daylight, X.index))\n",
    "\n",
    "\n",
    "    # temperatures are in 1/10 deg C; convert to C\n",
    "    X['TMIN'] /= 10\n",
    "    X['TMAX'] /= 10\n",
    "\n",
    "    # We can also calcuate the average temperature.\n",
    "    X['Temp (C)'] = 0.5 * (X['TMIN'] + X['TMAX'])\n",
    "\n",
    "\n",
    "    # precip is in 1/10 mm; convert to inches\n",
    "    X['PRCP'] /= 254\n",
    "\n",
    "    # In addition to the inches of precipitation, let's add a flag that \n",
    "    # indicates whether a day is dry (has zero precipitation):\n",
    "    X['dry day'] = (X['PRCP'] == 0).astype(int)\n",
    "\n",
    "\n",
    "    # Let's add a counter that increases from day 1, and measures how many \n",
    "    # years have passed. This will let us measure any observed annual increase \n",
    "    # or decrease in daily crossings:\n",
    "    X['annual'] = (X.index - X.index[0]).days / 365.\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def wrangle(X):\n",
    "    # From Daniel H (DS1 KotH)\n",
    "    X = X.copy()\n",
    "    X = X.replace(-9999, 0)\n",
    "    X = jake_wrangle(X)\n",
    "    \n",
    "    X['PRCP_yest'] = X.PRCP.shift(1).fillna(X.PRCP.mean())\n",
    "    X['Windchill'] = (((X['Temp (C)'] * (9/5) + 32) * .6215) + 34.74) - (35.75 * (X['AWND']** .16)) + (.4275 * (X['Temp (C)'])) * (X['AWND'] ** .16)\n",
    "    X['Rl_Cold'] = (((X['Temp (C)'] * (9/5) + 32) - X['Windchill']) -32) * (5/9)\n",
    "    X['TMIN_ln'] = X['TMIN'] **2\n",
    "    \n",
    "    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    for i, month in enumerate(months):\n",
    "        X[month] = (X.index.month == i+1).astype(float)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vQN2O9PCAkBn"
   },
   "outputs": [],
   "source": [
    "# Download and join data into a dataframe\n",
    "data = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJrNph8IFyOM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 102 candidates, totalling 306 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Score: 297.14146030845234\n",
      "\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "       with_scaling=True)), ('selectkbest', SelectKBest(k=30, score_func=<function f_regression at 0x00000256183E3950>)), ('ridge', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001))])\n",
      "\n",
      "Wall time: 3.44 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    3.2s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Split data into train and test\n",
    "X_train, X_test, y_train, y_test = split(data)\n",
    "\n",
    "# Do the same wrangling to X_train and X_test\n",
    "X_train = wrangle(X_train)\n",
    "X_test  = wrangle(X_test)\n",
    "\n",
    "# Define an estimator and param_grid\n",
    "pipe = make_pipeline(\n",
    "    RobustScaler(), \n",
    "    SelectKBest(f_regression), \n",
    "    Ridge())\n",
    "\n",
    "param_grid = {\n",
    "    'selectkbest__k': range(1, len(X_train.columns)), \n",
    "    'ridge__alpha': [0.1, 1.0, 10.]\n",
    "}\n",
    "\n",
    "# Fit on the train set, with grid search cross-validation\n",
    "gs = GridSearchCV(pipe, param_grid=param_grid, cv=3, \n",
    "                  scoring='neg_mean_absolute_error', \n",
    "                  verbose=1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "validation_score = gs.best_score_\n",
    "print()\n",
    "print('Cross-Validation Score:', -validation_score)\n",
    "print()\n",
    "print('Best estimator:', gs.best_estimator_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AR4bo95ZJFwj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 321.98359011482904\n"
     ]
    }
   ],
   "source": [
    "# Predict with X_test features\n",
    "y_pred = gs.predict(X_test)\n",
    "\n",
    "# Compare predictions to y_test labels\n",
    "test_score = mean_absolute_error(y_test, y_pred)\n",
    "print('Test Score:', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MQYtnmxV159"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 321.98359011482904\n"
     ]
    }
   ],
   "source": [
    "# Or use the grid search's score method, \n",
    "# which combines these steps\n",
    "test_score = gs.score(X_test, y_test)\n",
    "print('Test Score:', -test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7qeb9ed8bIAE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected:\n",
      "PRCP\n",
      "TMAX\n",
      "TMIN\n",
      "AWND\n",
      "Total_yesterday\n",
      "Mon\n",
      "Tue\n",
      "Wed\n",
      "Thu\n",
      "Sat\n",
      "Sun\n",
      "holiday\n",
      "daylight_hrs\n",
      "Temp (C)\n",
      "dry day\n",
      "annual\n",
      "PRCP_yest\n",
      "Windchill\n",
      "Rl_Cold\n",
      "TMIN_ln\n",
      "Jan\n",
      "Feb\n",
      "Mar\n",
      "May\n",
      "Jun\n",
      "Jul\n",
      "Aug\n",
      "Sep\n",
      "Nov\n",
      "Dec\n",
      "\n",
      "Features not selected:\n",
      "SNOW\n",
      "SNWD\n",
      "Fri\n",
      "Apr\n",
      "Oct\n"
     ]
    }
   ],
   "source": [
    "# Which features were selected?\n",
    "selector = gs.best_estimator_.named_steps['selectkbest']\n",
    "all_names = X_train.columns\n",
    "selected_mask = selector.get_support()\n",
    "selected_names = all_names[selected_mask]\n",
    "unselected_names = all_names[~selected_mask]\n",
    "\n",
    "print('Features selected:')\n",
    "for name in selected_names:\n",
    "    print(name)\n",
    "\n",
    "print()\n",
    "print('Features not selected:')\n",
    "for name in unselected_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "urdgBk_Vp6ZN"
   },
   "source": [
    "## BONUS: Recursive Feature Elimination!\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEvISfuimpQV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected:\n",
      "PRCP\n",
      "TMAX\n",
      "TMIN\n",
      "AWND\n",
      "Total_yesterday\n",
      "Mon\n",
      "Tue\n",
      "Wed\n",
      "Thu\n",
      "Fri\n",
      "Sat\n",
      "Sun\n",
      "holiday\n",
      "daylight_hrs\n",
      "Temp (C)\n",
      "dry day\n",
      "Windchill\n",
      "Rl_Cold\n",
      "TMIN_ln\n",
      "Mar\n",
      "May\n",
      "Jun\n",
      "Oct\n",
      "Dec\n",
      "\n",
      "Features not selected:\n",
      "SNOW\n",
      "SNWD\n",
      "annual\n",
      "PRCP_yest\n",
      "Jan\n",
      "Feb\n",
      "Apr\n",
      "Jul\n",
      "Aug\n",
      "Sep\n",
      "Nov\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "X_train_scaled = RobustScaler().fit_transform(X_train)\n",
    "rfe = RFECV(Ridge(alpha=1.0), scoring='neg_mean_absolute_error', cv=3)\n",
    "X_train_subset = rfe.fit_transform(X_train_scaled, y_train)\n",
    "\n",
    "all_names = X_train.columns\n",
    "selected_mask = rfe.support_\n",
    "selected_names = all_names[selected_mask]\n",
    "unselected_names = all_names[~selected_mask]\n",
    "\n",
    "print('Features selected:')\n",
    "for name in selected_names:\n",
    "    print(name)\n",
    "\n",
    "print()\n",
    "print('Features not selected:')\n",
    "for name in unselected_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hoCUHkuGpjvX"
   },
   "outputs": [],
   "source": [
    "X_train_subset = pd.DataFrame(X_train_subset, columns=selected_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZKoH475ppag"
   },
   "outputs": [],
   "source": [
    "X_test_subset = rfe.transform(X_test)\n",
    "X_test_subset = pd.DataFrame(X_test_subset, columns=selected_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mhcS0n8ApuUx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(963, 35) (963, 24) (100, 35) (100, 24)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_train_subset.shape, X_test.shape, X_test_subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_OpHu92Yto88"
   },
   "source": [
    "# RFE again, but with polynomial features and interaction terms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ArgRECEUtyH4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(963, 35) (963, 666)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_polynomial = poly.fit_transform(X_train)\n",
    "\n",
    "print(X_train.shape, X_train_polynomial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TWVHh35wsdE7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 666 features.\n",
      "Fitting estimator with 656 features.\n",
      "Fitting estimator with 646 features.\n",
      "Fitting estimator with 636 features.\n",
      "Fitting estimator with 626 features.\n",
      "Fitting estimator with 616 features.\n",
      "Fitting estimator with 606 features.\n",
      "Fitting estimator with 596 features.\n",
      "Fitting estimator with 586 features.\n",
      "Fitting estimator with 576 features.\n",
      "Fitting estimator with 566 features.\n",
      "Fitting estimator with 556 features.\n",
      "Fitting estimator with 546 features.\n",
      "Fitting estimator with 536 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 666 features.\n",
      "Fitting estimator with 656 features.\n",
      "Fitting estimator with 646 features.\n",
      "Fitting estimator with 636 features.\n",
      "Fitting estimator with 626 features.\n",
      "Fitting estimator with 616 features.\n",
      "Fitting estimator with 606 features.\n",
      "Fitting estimator with 596 features.\n",
      "Fitting estimator with 586 features.\n",
      "Fitting estimator with 576 features.\n",
      "Fitting estimator with 566 features.\n",
      "Fitting estimator with 556 features.\n",
      "Fitting estimator with 546 features.\n",
      "Fitting estimator with 536 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 666 features.\n",
      "Fitting estimator with 656 features.\n",
      "Fitting estimator with 646 features.\n",
      "Fitting estimator with 636 features.\n",
      "Fitting estimator with 626 features.\n",
      "Fitting estimator with 616 features.\n",
      "Fitting estimator with 606 features.\n",
      "Fitting estimator with 596 features.\n",
      "Fitting estimator with 586 features.\n",
      "Fitting estimator with 576 features.\n",
      "Fitting estimator with 566 features.\n",
      "Fitting estimator with 556 features.\n",
      "Fitting estimator with 546 features.\n",
      "Fitting estimator with 536 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 666 features.\n",
      "Fitting estimator with 656 features.\n",
      "Fitting estimator with 646 features.\n",
      "Fitting estimator with 636 features.\n",
      "Fitting estimator with 626 features.\n",
      "Fitting estimator with 616 features.\n",
      "Fitting estimator with 606 features.\n",
      "Fitting estimator with 596 features.\n",
      "Fitting estimator with 586 features.\n",
      "Fitting estimator with 576 features.\n",
      "Fitting estimator with 566 features.\n",
      "Fitting estimator with 556 features.\n",
      "Fitting estimator with 546 features.\n",
      "Fitting estimator with 536 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 416 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 166 features.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_polynomial)\n",
    "\n",
    "rfe = RFECV(Ridge(alpha=1.0), scoring='neg_mean_absolute_error', \n",
    "            step=10, cv=3, verbose=1)\n",
    "\n",
    "X_train_subset = rfe.fit_transform(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TrMRGvezuDD7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 Features selected:\n",
      "PRCP\n",
      "TMAX\n",
      "Sun\n",
      "holiday\n",
      "daylight_hrs\n",
      "Temp (C)\n",
      "annual\n",
      "Mar\n",
      "May\n",
      "Nov\n",
      "PRCP Tue\n",
      "PRCP Fri\n",
      "PRCP Sat\n",
      "PRCP Sun\n",
      "PRCP holiday\n",
      "PRCP daylight_hrs\n",
      "PRCP Jan\n",
      "PRCP Feb\n",
      "PRCP Mar\n",
      "PRCP Apr\n",
      "PRCP May\n",
      "PRCP Jun\n",
      "PRCP Jul\n",
      "PRCP Aug\n",
      "PRCP Sep\n",
      "PRCP Nov\n",
      "PRCP Dec\n",
      "TMAX^2\n",
      "TMAX TMIN\n",
      "TMAX Rl_Cold\n",
      "TMIN AWND\n",
      "TMIN Total_yesterday\n",
      "TMIN Windchill\n",
      "AWND^2\n",
      "AWND Total_yesterday\n",
      "AWND daylight_hrs\n",
      "AWND Temp (C)\n",
      "AWND dry day\n",
      "AWND annual\n",
      "AWND Windchill\n",
      "AWND Rl_Cold\n",
      "AWND TMIN_ln\n",
      "Total_yesterday^2\n",
      "Total_yesterday daylight_hrs\n",
      "Total_yesterday dry day\n",
      "Total_yesterday annual\n",
      "Total_yesterday Rl_Cold\n",
      "Mon holiday\n",
      "Mon daylight_hrs\n",
      "Mon annual\n",
      "Mon Jan\n",
      "Mon Feb\n",
      "Mon Mar\n",
      "Mon May\n",
      "Mon Jun\n",
      "Mon Oct\n",
      "Mon Nov\n",
      "Tue daylight_hrs\n",
      "Tue dry day\n",
      "Tue annual\n",
      "Tue Mar\n",
      "Tue Apr\n",
      "Tue May\n",
      "Tue Aug\n",
      "Tue Sep\n",
      "Tue Dec\n",
      "Wed holiday\n",
      "Wed daylight_hrs\n",
      "Wed PRCP_yest\n",
      "Wed Jan\n",
      "Wed Mar\n",
      "Wed Apr\n",
      "Wed Sep\n",
      "Wed Oct\n",
      "Thu holiday\n",
      "Thu daylight_hrs\n",
      "Thu dry day\n",
      "Thu annual\n",
      "Thu PRCP_yest\n",
      "Thu Jan\n",
      "Thu Feb\n",
      "Thu Mar\n",
      "Thu Apr\n",
      "Thu May\n",
      "Thu Jun\n",
      "Thu Sep\n",
      "Thu Oct\n",
      "Thu Nov\n",
      "Thu Dec\n",
      "Fri daylight_hrs\n",
      "Fri Jan\n",
      "Fri Mar\n",
      "Fri Apr\n",
      "Fri May\n",
      "Fri Jun\n",
      "Fri Jul\n",
      "Fri Aug\n",
      "Sat dry day\n",
      "Sat PRCP_yest\n",
      "Sat Jan\n",
      "Sat Mar\n",
      "Sat Apr\n",
      "Sat May\n",
      "Sat Jun\n",
      "Sat Jul\n",
      "Sat Oct\n",
      "Sat Nov\n",
      "Sun^2\n",
      "Sun annual\n",
      "Sun PRCP_yest\n",
      "Sun Mar\n",
      "Sun Apr\n",
      "Sun May\n",
      "Sun Jun\n",
      "Sun Jul\n",
      "Sun Sep\n",
      "Sun Oct\n",
      "Sun Nov\n",
      "holiday^2\n",
      "holiday daylight_hrs\n",
      "holiday May\n",
      "holiday Jul\n",
      "holiday Sep\n",
      "holiday Oct\n",
      "holiday Nov\n",
      "holiday Dec\n",
      "daylight_hrs^2\n",
      "daylight_hrs Rl_Cold\n",
      "daylight_hrs TMIN_ln\n",
      "daylight_hrs Nov\n",
      "Temp (C) annual\n",
      "Temp (C) Rl_Cold\n",
      "dry day annual\n",
      "dry day Rl_Cold\n",
      "dry day Apr\n",
      "dry day May\n",
      "dry day Dec\n",
      "annual^2\n",
      "annual Windchill\n",
      "annual Rl_Cold\n",
      "annual Jan\n",
      "annual May\n",
      "annual Jun\n",
      "annual Dec\n",
      "PRCP_yest Jan\n",
      "PRCP_yest Feb\n",
      "PRCP_yest Mar\n",
      "PRCP_yest May\n",
      "PRCP_yest Jun\n",
      "PRCP_yest Jul\n",
      "PRCP_yest Aug\n",
      "PRCP_yest Dec\n",
      "Windchill Rl_Cold\n",
      "Mar^2\n",
      "May^2\n",
      "Nov^2\n"
     ]
    }
   ],
   "source": [
    "all_names = poly.get_feature_names(X_train.columns)\n",
    "selected_mask = rfe.support_\n",
    "selected_names = [name for name, selected in zip(all_names, selected_mask) if selected]\n",
    "\n",
    "print(f'{rfe.n_features_} Features selected:')\n",
    "for name in selected_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pku8KixHv3CF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "\n",
      "Cross-Validation Score: 247.80985367683795\n",
      "\n",
      "Best estimator: Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Define an estimator and param_grid\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 1.0, 10.]\n",
    "}\n",
    "\n",
    "# Fit on the train set, with grid search cross-validation\n",
    "gs = GridSearchCV(ridge, param_grid=param_grid, cv=3, \n",
    "                  scoring='neg_mean_absolute_error', \n",
    "                  verbose=1)\n",
    "\n",
    "gs.fit(X_train_subset, y_train)\n",
    "validation_score = gs.best_score_\n",
    "print()\n",
    "print('Cross-Validation Score:', -validation_score)\n",
    "print()\n",
    "print('Best estimator:', gs.best_estimator_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NnpbyDLSwPIH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 328.57066776770523\n"
     ]
    }
   ],
   "source": [
    "# Do the same transformations to X_test\n",
    "X_test_polynomial = poly.transform(X_test)\n",
    "X_test_scaled = scaler.transform(X_test_polynomial)\n",
    "X_test_subset = rfe.transform(X_test_scaled)\n",
    "\n",
    "# Use the grid search's score method with X_test_subset\n",
    "test_score = gs.score(X_test_subset, y_test)\n",
    "print('Test Score:', -test_score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_24_Cross-Validation-AND-Feature-Selection.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
